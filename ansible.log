2025-07-07 08:48:09,202 p=46657 u=gpadmin n=ansible | Starting galaxy collection install process
2025-07-07 08:48:09,378 p=46657 u=gpadmin n=ansible | Nothing to do. All requested collections are already installed. If you want to reinstall them, consider using `--force`.
2025-07-07 08:48:14,045 p=46713 u=gpadmin n=ansible | playbook: site.yml
2025-07-07 08:48:26,723 p=46816 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 08:48:26,733 p=46816 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 08:48:26,978 p=46816 u=gpadmin n=ansible | [WARNING]: Unhandled error in Python interpreter discovery for host MASTER: Failed to
connect to the host via ssh: ssh: connect to host 192.168.40.240 port 22: Connection
refused

2025-07-07 08:48:26,995 p=46816 u=gpadmin n=ansible | fatal: [MASTER]: UNREACHABLE! => {"changed": false, "msg": "Data could not be sent to remote host \"192.168.40.240\". Make sure this host can be reached over ssh: ssh: connect to host 192.168.40.240 port 22: Connection refused\r\n", "unreachable": true}
2025-07-07 08:48:27,139 p=46816 u=gpadmin n=ansible | [WARNING]: Unhandled error in Python interpreter discovery for host G-244: Failed to
connect to the host via ssh: Warning: Permanently added '192.168.40.244' (ED25519) to the
list of known hosts.  gpadmin@192.168.40.244: Permission denied (publickey,password).

2025-07-07 08:48:27,143 p=46816 u=gpadmin n=ansible | [WARNING]: Unhandled error in Python interpreter discovery for host G-243: Failed to
connect to the host via ssh: Warning: Permanently added '192.168.40.243' (ED25519) to the
list of known hosts.  gpadmin@192.168.40.243: Permission denied (publickey,password).

2025-07-07 08:48:27,216 p=46816 u=gpadmin n=ansible | [WARNING]: Unhandled error in Python interpreter discovery for host G-242: Failed to
connect to the host via ssh: Warning: Permanently added '192.168.40.242' (ED25519) to the
list of known hosts.  gpadmin@192.168.40.242: Permission denied (publickey,password).

2025-07-07 08:48:27,243 p=46816 u=gpadmin n=ansible | [WARNING]: Unhandled error in Python interpreter discovery for host G-241: Failed to
connect to the host via ssh: gpadmin@192.168.40.241: Permission denied
(publickey,password).

2025-07-07 08:48:27,337 p=46816 u=gpadmin n=ansible | fatal: [G-243]: UNREACHABLE! => {"changed": false, "msg": "Data could not be sent to remote host \"192.168.40.243\". Make sure this host can be reached over ssh: gpadmin@192.168.40.243: Permission denied (publickey,password).\r\n", "unreachable": true}
2025-07-07 08:48:27,343 p=46816 u=gpadmin n=ansible | fatal: [G-244]: UNREACHABLE! => {"changed": false, "msg": "Data could not be sent to remote host \"192.168.40.244\". Make sure this host can be reached over ssh: gpadmin@192.168.40.244: Permission denied (publickey,password).\r\n", "unreachable": true}
2025-07-07 08:48:27,431 p=46816 u=gpadmin n=ansible | fatal: [G-242]: UNREACHABLE! => {"changed": false, "msg": "Data could not be sent to remote host \"192.168.40.242\". Make sure this host can be reached over ssh: gpadmin@192.168.40.242: Permission denied (publickey,password).\r\n", "unreachable": true}
2025-07-07 08:48:27,501 p=46816 u=gpadmin n=ansible | fatal: [G-241]: UNREACHABLE! => {"changed": false, "msg": "Data could not be sent to remote host \"192.168.40.241\". Make sure this host can be reached over ssh: gpadmin@192.168.40.241: Permission denied (publickey,password).\r\n", "unreachable": true}
2025-07-07 08:48:27,502 p=46816 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 08:48:27,502 p=46816 u=gpadmin n=ansible | G-241                      : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 08:48:27,502 p=46816 u=gpadmin n=ansible | G-242                      : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 08:48:27,502 p=46816 u=gpadmin n=ansible | G-243                      : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 08:48:27,502 p=46816 u=gpadmin n=ansible | G-244                      : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 08:48:27,503 p=46816 u=gpadmin n=ansible | MASTER                     : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 08:55:42,404 p=51216 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 08:55:42,412 p=51216 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 08:55:42,648 p=51216 u=gpadmin n=ansible | [WARNING]: Unhandled error in Python interpreter discovery for host MASTER: Failed to
connect to the host via ssh: ssh: connect to host 192.168.40.240 port 22: Connection
refused

2025-07-07 08:55:42,667 p=51216 u=gpadmin n=ansible | fatal: [MASTER]: UNREACHABLE! => {"changed": false, "msg": "Data could not be sent to remote host \"192.168.40.240\". Make sure this host can be reached over ssh: ssh: connect to host 192.168.40.240 port 22: Connection refused\r\n", "unreachable": true}
2025-07-07 08:55:43,110 p=51216 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"msg": "Missing sudo password"}
2025-07-07 08:55:43,120 p=51216 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"msg": "Missing sudo password"}
2025-07-07 08:55:43,135 p=51216 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"msg": "Missing sudo password"}
2025-07-07 08:55:43,156 p=51216 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"msg": "Missing sudo password"}
2025-07-07 08:55:43,157 p=51216 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 08:55:43,157 p=51216 u=gpadmin n=ansible | G-241                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 08:55:43,157 p=51216 u=gpadmin n=ansible | G-242                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 08:55:43,157 p=51216 u=gpadmin n=ansible | G-243                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 08:55:43,157 p=51216 u=gpadmin n=ansible | G-244                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 08:55:43,158 p=51216 u=gpadmin n=ansible | MASTER                     : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 08:56:32,275 p=51714 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 08:56:32,284 p=51714 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 08:56:33,365 p=51714 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:56:33,377 p=51714 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:56:33,387 p=51714 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:56:33,458 p=51714 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:56:33,753 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:56:33,829 p=51714 u=gpadmin n=ansible | TASK [common : Update apt cache] **********************************************************
2025-07-07 08:56:34,314 p=51714 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:56:34,681 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:56:34,963 p=51714 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 08:56:36,696 p=51714 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 08:56:37,293 p=51714 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 08:56:37,305 p=51714 u=gpadmin n=ansible | TASK [common : Install common packages] ***************************************************
2025-07-07 08:56:39,356 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:56:57,131 p=51714 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 08:56:58,058 p=51714 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 08:57:01,280 p=51714 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 08:57:01,939 p=51714 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 08:57:01,952 p=51714 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] ********************************************
2025-07-07 08:57:02,241 p=51714 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 08:57:02,251 p=51714 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 08:57:02,251 p=51714 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 08:57:02,256 p=51714 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 08:57:02,363 p=51714 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 08:57:02,377 p=51714 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] *********************************************
2025-07-07 08:57:02,670 p=51714 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:57:02,676 p=51714 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:57:02,685 p=51714 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:57:02,687 p=51714 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:57:02,773 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:57:02,826 p=51714 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed] **********************************************
2025-07-07 08:57:03,273 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:57:03,484 p=51714 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:57:03,486 p=51714 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:57:03,540 p=51714 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:57:03,548 p=51714 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:57:03,561 p=51714 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] ********************************************************
2025-07-07 08:57:03,589 p=51714 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 08:57:03,607 p=51714 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 08:57:03,621 p=51714 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 08:57:03,636 p=51714 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 08:57:03,648 p=51714 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 08:57:03,657 p=51714 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] *************************************************
2025-07-07 08:57:03,676 p=51714 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 08:57:03,704 p=51714 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 08:57:03,718 p=51714 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 08:57:03,719 p=51714 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 08:57:03,732 p=51714 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 08:57:03,740 p=51714 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] *****************************************************
2025-07-07 08:57:03,763 p=51714 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 08:57:03,793 p=51714 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 08:57:03,807 p=51714 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 08:57:03,808 p=51714 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 08:57:03,816 p=51714 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 08:57:03,825 p=51714 u=gpadmin n=ansible | TASK [docker : Ensure Docker service is running and enabled] ******************************
2025-07-07 08:57:04,305 p=51714 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "msg": "Could not find the requested service docker: host"}
2025-07-07 08:57:04,306 p=51714 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "msg": "Could not find the requested service docker: host"}
2025-07-07 08:57:04,309 p=51714 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "msg": "Could not find the requested service docker: host"}
2025-07-07 08:57:04,317 p=51714 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "msg": "Could not find the requested service docker: host"}
2025-07-07 08:57:04,501 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:57:04,508 p=51714 u=gpadmin n=ansible | TASK [docker : Add user to docker group] **************************************************
2025-07-07 08:57:04,526 p=51714 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 08:57:04,534 p=51714 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] *****************************************************
2025-07-07 08:57:43,513 p=51714 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 08:57:43,566 p=51714 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] ************************************************************
2025-07-07 08:57:43,580 p=51714 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 08:57:45,768 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:57:45,804 p=51714 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] **********************
2025-07-07 08:57:46,153 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:57:46,170 p=51714 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] ***************
2025-07-07 08:57:47,028 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:57:47,041 p=51714 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] **************************
2025-07-07 08:57:47,363 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:57:47,378 p=51714 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] *********************************
2025-07-07 08:57:48,251 p=51714 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 08:57:48,268 p=51714 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] ************************************************
2025-07-07 08:57:50,548 p=51714 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 08:57:50,563 p=51714 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] ***************************************
2025-07-07 08:57:50,896 p=51714 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:57:50,910 p=51714 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] *****************************************
2025-07-07 08:57:50,930 p=51714 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS                  PORTS     NAMES\n6ce6c8435670   rayproject/ray:2.9.0   \"ray start --head --…\"   2 seconds ago   Up Less than a second             ray_head"
}
2025-07-07 08:57:50,944 p=51714 u=gpadmin n=ansible | TASK [ray_head : Wait for Ray head to be ready] *******************************************
2025-07-07 08:58:51,407 p=51714 u=gpadmin n=ansible | fatal: [MASTER -> localhost]: FAILED! => {"changed": false, "elapsed": 60, "msg": "Timeout when waiting for 192.168.40.240:6379"}
2025-07-07 08:58:51,409 p=51714 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 08:58:51,409 p=51714 u=gpadmin n=ansible | G-241                      : ok=6    changed=2    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-07-07 08:58:51,409 p=51714 u=gpadmin n=ansible | G-242                      : ok=6    changed=3    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-07-07 08:58:51,409 p=51714 u=gpadmin n=ansible | G-243                      : ok=6    changed=3    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-07-07 08:58:51,409 p=51714 u=gpadmin n=ansible | G-244                      : ok=6    changed=3    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-07-07 08:58:51,409 p=51714 u=gpadmin n=ansible | MASTER                     : ok=16   changed=4    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-07-07 08:59:37,330 p=56844 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 08:59:37,339 p=56844 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 08:59:38,878 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:38,911 p=56844 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:59:39,014 p=56844 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:59:39,023 p=56844 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:59:39,053 p=56844 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:59:39,125 p=56844 u=gpadmin n=ansible | TASK [common : Update apt cache] **********************************************************
2025-07-07 08:59:39,608 p=56844 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:59:39,621 p=56844 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:59:39,631 p=56844 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:59:39,640 p=56844 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:59:40,014 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:40,026 p=56844 u=gpadmin n=ansible | TASK [common : Install common packages] ***************************************************
2025-07-07 08:59:40,487 p=56844 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:59:40,507 p=56844 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:59:40,515 p=56844 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:59:40,515 p=56844 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:59:41,088 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:41,100 p=56844 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] ********************************************
2025-07-07 08:59:41,378 p=56844 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:59:41,380 p=56844 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:59:41,386 p=56844 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:59:41,390 p=56844 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:59:41,502 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:41,514 p=56844 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] *********************************************
2025-07-07 08:59:41,786 p=56844 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:59:41,788 p=56844 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:59:41,796 p=56844 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:59:41,800 p=56844 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:59:41,899 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:41,952 p=56844 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed] **********************************************
2025-07-07 08:59:42,230 p=56844 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 08:59:42,231 p=56844 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 08:59:42,238 p=56844 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 08:59:42,247 p=56844 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 08:59:42,331 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:42,344 p=56844 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] ********************************************************
2025-07-07 08:59:42,371 p=56844 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 08:59:42,391 p=56844 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 08:59:42,420 p=56844 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 08:59:42,422 p=56844 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 08:59:42,432 p=56844 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 08:59:42,441 p=56844 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] *************************************************
2025-07-07 08:59:42,459 p=56844 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 08:59:42,487 p=56844 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 08:59:42,502 p=56844 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 08:59:42,502 p=56844 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 08:59:42,513 p=56844 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 08:59:42,521 p=56844 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] *****************************************************
2025-07-07 08:59:42,553 p=56844 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 08:59:42,567 p=56844 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 08:59:42,587 p=56844 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 08:59:42,587 p=56844 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 08:59:42,595 p=56844 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 08:59:42,604 p=56844 u=gpadmin n=ansible | TASK [docker : Ensure Docker service is running and enabled] ******************************
2025-07-07 08:59:43,108 p=56844 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "msg": "Could not find the requested service docker: host"}
2025-07-07 08:59:43,110 p=56844 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "msg": "Could not find the requested service docker: host"}
2025-07-07 08:59:43,114 p=56844 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "msg": "Could not find the requested service docker: host"}
2025-07-07 08:59:43,115 p=56844 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "msg": "Could not find the requested service docker: host"}
2025-07-07 08:59:43,301 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:43,315 p=56844 u=gpadmin n=ansible | TASK [docker : Add user to docker group] **************************************************
2025-07-07 08:59:43,336 p=56844 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 08:59:43,351 p=56844 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] *****************************************************
2025-07-07 08:59:44,491 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:44,548 p=56844 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] ************************************************************
2025-07-07 08:59:44,558 p=56844 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 08:59:45,794 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:45,827 p=56844 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] **********************
2025-07-07 08:59:46,127 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:46,141 p=56844 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] ***************
2025-07-07 08:59:46,899 p=56844 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 08:59:46,912 p=56844 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] **************************
2025-07-07 08:59:47,205 p=56844 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 08:59:47,214 p=56844 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] *********************************
2025-07-07 08:59:47,922 p=56844 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 08:59:47,939 p=56844 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] ************************************************
2025-07-07 08:59:48,462 p=56844 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 08:59:48,477 p=56844 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] ***************************************
2025-07-07 08:59:48,794 p=56844 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 08:59:48,809 p=56844 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] *****************************************
2025-07-07 08:59:48,829 p=56844 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n33ddd73d4c21   rayproject/ray:2.9.0   \"ray start --head --…\"   Less than a second ago   Up Less than a second             ray_head"
}
2025-07-07 08:59:48,843 p=56844 u=gpadmin n=ansible | TASK [ray_head : Wait for Ray head to be ready] *******************************************
2025-07-07 09:00:49,279 p=56844 u=gpadmin n=ansible | fatal: [MASTER -> localhost]: FAILED! => {"changed": false, "elapsed": 60, "msg": "Timeout when waiting for 127.0.0.1:6379"}
2025-07-07 09:00:49,280 p=56844 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:00:49,280 p=56844 u=gpadmin n=ansible | G-241                      : ok=6    changed=0    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-07-07 09:00:49,280 p=56844 u=gpadmin n=ansible | G-242                      : ok=6    changed=0    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-07-07 09:00:49,281 p=56844 u=gpadmin n=ansible | G-243                      : ok=6    changed=0    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-07-07 09:00:49,281 p=56844 u=gpadmin n=ansible | G-244                      : ok=6    changed=0    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-07-07 09:00:49,281 p=56844 u=gpadmin n=ansible | MASTER                     : ok=16   changed=4    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-07-07 09:05:06,272 p=61439 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 09:05:06,281 p=61439 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:05:07,795 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:05:07,949 p=61439 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:05:07,978 p=61439 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:05:08,009 p=61439 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:05:08,059 p=61439 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:05:08,132 p=61439 u=gpadmin n=ansible | TASK [common : Update apt cache] **********************************************************
2025-07-07 09:05:08,608 p=61439 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:05:08,611 p=61439 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:05:08,612 p=61439 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:05:08,620 p=61439 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:05:09,000 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:05:09,013 p=61439 u=gpadmin n=ansible | TASK [common : Install common packages] ***************************************************
2025-07-07 09:05:09,468 p=61439 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:05:09,493 p=61439 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:05:09,504 p=61439 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:05:09,509 p=61439 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:05:10,066 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:05:10,079 p=61439 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] ********************************************
2025-07-07 09:05:10,365 p=61439 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:05:10,370 p=61439 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:05:10,374 p=61439 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:05:10,381 p=61439 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:05:10,477 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:05:10,489 p=61439 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] *********************************************
2025-07-07 09:05:10,761 p=61439 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:05:10,769 p=61439 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:05:10,771 p=61439 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:05:10,776 p=61439 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:05:10,879 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:05:10,934 p=61439 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] ********************************
2025-07-07 09:05:11,216 p=61439 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:05:11,217 p=61439 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:05:11,217 p=61439 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:05:11,225 p=61439 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:05:11,311 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:05:11,324 p=61439 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] ********************************************************
2025-07-07 09:05:11,353 p=61439 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:05:11,374 p=61439 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:05:11,389 p=61439 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:05:11,405 p=61439 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:05:11,417 p=61439 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:05:11,425 p=61439 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] *************************************************
2025-07-07 09:05:11,457 p=61439 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:05:11,472 p=61439 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:05:11,486 p=61439 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:05:11,488 p=61439 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:05:11,499 p=61439 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:05:11,508 p=61439 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] *****************************************************
2025-07-07 09:05:11,542 p=61439 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:05:11,556 p=61439 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:05:11,573 p=61439 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:05:11,574 p=61439 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:05:11,587 p=61439 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:05:11,595 p=61439 u=gpadmin n=ansible | TASK [docker : Check Docker service status] ***********************************************
2025-07-07 09:05:11,772 p=61439 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003157", "end": "2025-07-07 13:05:11.758015", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:05:11.754858", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:05:11,772 p=61439 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:05:11,783 p=61439 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003422", "end": "2025-07-07 13:05:11.771204", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:05:11.767782", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:05:11,784 p=61439 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:05:11,794 p=61439 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003259", "end": "2025-07-07 13:05:11.776628", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:05:11.773369", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:05:11,794 p=61439 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:05:11,805 p=61439 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003257", "end": "2025-07-07 13:05:11.792004", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:05:11.788747", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:05:11,806 p=61439 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:05:11,892 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:05:11,905 p=61439 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] ********************************************
2025-07-07 09:05:11,946 p=61439 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:05:11,976 p=61439 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:05:11,976 p=61439 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:05:11,984 p=61439 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:05:12,618 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:05:12,629 p=61439 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ***********************************************
2025-07-07 09:05:12,650 p=61439 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:05:12,956 p=61439 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:05:46,018 p=61439 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:05:46,022 p=61439 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:05:46,025 p=61439 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:05:46,039 p=61439 u=gpadmin n=ansible | TASK [docker : Add user to docker group] **************************************************
2025-07-07 09:05:46,067 p=61439 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:05:46,085 p=61439 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:05:46,113 p=61439 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:05:46,115 p=61439 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:05:46,126 p=61439 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:05:46,135 p=61439 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] *****************************************************
2025-07-07 09:05:48,098 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:06:14,047 p=61439 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:06:17,859 p=61439 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:06:22,577 p=61439 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:06:23,605 p=61439 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:06:23,782 p=61439 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] ************************************************************
2025-07-07 09:06:23,792 p=61439 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:06:24,988 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:06:25,025 p=61439 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] **********************
2025-07-07 09:06:25,336 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:06:25,349 p=61439 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] ***************
2025-07-07 09:06:26,059 p=61439 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:06:26,074 p=61439 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] **************************
2025-07-07 09:06:26,378 p=61439 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:06:26,393 p=61439 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] *********************************
2025-07-07 09:06:27,044 p=61439 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:06:27,059 p=61439 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] ************************************************
2025-07-07 09:06:27,620 p=61439 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:06:27,635 p=61439 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] ***************************************
2025-07-07 09:06:27,955 p=61439 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:06:27,970 p=61439 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] *****************************************
2025-07-07 09:06:27,995 p=61439 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n0ee491cff313   rayproject/ray:2.9.0   \"ray start --head --…\"   Less than a second ago   Up Less than a second             ray_head"
}
2025-07-07 09:06:28,009 p=61439 u=gpadmin n=ansible | TASK [ray_head : Wait for Ray head to be ready] *******************************************
2025-07-07 09:07:28,446 p=61439 u=gpadmin n=ansible | fatal: [MASTER -> localhost]: FAILED! => {"changed": false, "elapsed": 60, "msg": "Timeout when waiting for 127.0.0.1:6379"}
2025-07-07 09:07:28,448 p=61439 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:07:28,448 p=61439 u=gpadmin n=ansible | G-241                      : ok=9    changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=1   
2025-07-07 09:07:28,448 p=61439 u=gpadmin n=ansible | G-242                      : ok=9    changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=1   
2025-07-07 09:07:28,448 p=61439 u=gpadmin n=ansible | G-243                      : ok=9    changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=1   
2025-07-07 09:07:28,448 p=61439 u=gpadmin n=ansible | G-244                      : ok=9    changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=1   
2025-07-07 09:07:28,448 p=61439 u=gpadmin n=ansible | MASTER                     : ok=17   changed=4    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-07 09:09:28,126 p=65214 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 09:09:28,136 p=65214 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:09:29,611 p=65214 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:29,733 p=65214 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:29,822 p=65214 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:29,856 p=65214 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:29,872 p=65214 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:29,951 p=65214 u=gpadmin n=ansible | TASK [common : Update apt cache] **********************************************************
2025-07-07 09:09:30,429 p=65214 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:30,435 p=65214 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:30,445 p=65214 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:30,815 p=65214 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:31,114 p=65214 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:09:31,127 p=65214 u=gpadmin n=ansible | TASK [common : Install common packages] ***************************************************
2025-07-07 09:09:31,594 p=65214 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:31,613 p=65214 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:31,617 p=65214 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:31,631 p=65214 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:32,176 p=65214 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:32,189 p=65214 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] ********************************************
2025-07-07 09:09:32,488 p=65214 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:32,489 p=65214 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:32,491 p=65214 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:32,505 p=65214 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:32,607 p=65214 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:32,620 p=65214 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] *********************************************
2025-07-07 09:09:32,889 p=65214 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:32,897 p=65214 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:32,901 p=65214 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:32,907 p=65214 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:33,001 p=65214 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:33,056 p=65214 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] ********************************
2025-07-07 09:09:33,329 p=65214 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:33,335 p=65214 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:33,336 p=65214 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:33,336 p=65214 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:33,435 p=65214 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:33,448 p=65214 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] ********************************************************
2025-07-07 09:09:33,475 p=65214 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:09:33,494 p=65214 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:09:33,510 p=65214 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:09:33,526 p=65214 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:09:33,537 p=65214 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:09:33,547 p=65214 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] *************************************************
2025-07-07 09:09:33,580 p=65214 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:09:33,596 p=65214 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:09:33,610 p=65214 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:09:33,612 p=65214 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:09:33,623 p=65214 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:09:33,632 p=65214 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] *****************************************************
2025-07-07 09:09:33,652 p=65214 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:09:33,666 p=65214 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:09:33,698 p=65214 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:09:33,699 p=65214 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:09:33,707 p=65214 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:09:33,716 p=65214 u=gpadmin n=ansible | TASK [docker : Check Docker service status] ***********************************************
2025-07-07 09:09:33,898 p=65214 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003172", "end": "2025-07-07 13:09:33.882852", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:09:33.879680", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:09:33,898 p=65214 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:09:33,901 p=65214 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003379", "end": "2025-07-07 13:09:33.890313", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:09:33.886934", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:09:33,901 p=65214 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:09:33,918 p=65214 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003199", "end": "2025-07-07 13:09:33.906143", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:09:33.902944", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:09:33,918 p=65214 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:09:33,925 p=65214 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003170", "end": "2025-07-07 13:09:33.912312", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:09:33.909142", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:09:33,925 p=65214 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:09:34,006 p=65214 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:34,018 p=65214 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] ********************************************
2025-07-07 09:09:34,061 p=65214 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:09:34,089 p=65214 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:09:34,089 p=65214 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:09:34,098 p=65214 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:09:34,717 p=65214 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:34,728 p=65214 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ***********************************************
2025-07-07 09:09:34,762 p=65214 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:09:35,062 p=65214 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:09:41,907 p=65214 u=gpadmin n=ansible |  [ERROR]: User interrupted execution

2025-07-07 09:09:54,756 p=66114 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] ***************************************
2025-07-07 09:09:54,765 p=66114 u=gpadmin n=ansible | TASK [Gathering Facts] *********************************************************
2025-07-07 09:09:55,867 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:55,878 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:55,907 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:55,947 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:56,192 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:56,266 p=66114 u=gpadmin n=ansible | TASK [common : Update apt cache] ***********************************************
2025-07-07 09:09:56,740 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:56,745 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:56,747 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:56,759 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:57,107 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:57,119 p=66114 u=gpadmin n=ansible | TASK [common : Install common packages] ****************************************
2025-07-07 09:09:57,586 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:57,605 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:57,614 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:57,623 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:58,144 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:58,156 p=66114 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] *********************************
2025-07-07 09:09:58,437 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:58,439 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:58,442 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:58,443 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:58,549 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:58,558 p=66114 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] **********************************
2025-07-07 09:09:58,833 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:58,836 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:58,848 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:58,864 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:58,948 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:59,002 p=66114 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] *********************
2025-07-07 09:09:59,267 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:09:59,289 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:09:59,293 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:09:59,305 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:09:59,374 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:59,387 p=66114 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] *********************************************
2025-07-07 09:09:59,413 p=66114 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:09:59,435 p=66114 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:09:59,465 p=66114 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:09:59,467 p=66114 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:09:59,473 p=66114 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:09:59,482 p=66114 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] **************************************
2025-07-07 09:09:59,502 p=66114 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:09:59,532 p=66114 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:09:59,547 p=66114 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:09:59,547 p=66114 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:09:59,560 p=66114 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:09:59,569 p=66114 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] ******************************************
2025-07-07 09:09:59,603 p=66114 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:09:59,618 p=66114 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:09:59,635 p=66114 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:09:59,636 p=66114 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:09:59,644 p=66114 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:09:59,653 p=66114 u=gpadmin n=ansible | TASK [docker : Check Docker service status] ************************************
2025-07-07 09:09:59,829 p=66114 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003132", "end": "2025-07-07 13:09:59.814100", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:09:59.810968", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:09:59,829 p=66114 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:09:59,839 p=66114 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003154", "end": "2025-07-07 13:09:59.826830", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:09:59.823676", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:09:59,839 p=66114 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:09:59,841 p=66114 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003319", "end": "2025-07-07 13:09:59.830186", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:09:59.826867", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:09:59,841 p=66114 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:09:59,856 p=66114 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003114", "end": "2025-07-07 13:09:59.843885", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:09:59.840771", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:09:59,856 p=66114 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:09:59,963 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:09:59,976 p=66114 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] *********************************
2025-07-07 09:10:00,032 p=66114 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:10:00,046 p=66114 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:10:00,047 p=66114 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:10:00,059 p=66114 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:10:00,707 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:10:00,723 p=66114 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ************************************
2025-07-07 09:10:00,751 p=66114 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:10:00,941 p=66114 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:00.014617", "end": "2025-07-07 13:10:00.928435", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:10:00.913818", "stderr": "error: snap \"docker\" has \"service-control\" change in progress", "stderr_lines": ["error: snap \"docker\" has \"service-control\" change in progress"], "stdout": "", "stdout_lines": []}
2025-07-07 09:10:00,941 p=66114 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:10:00,947 p=66114 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:00.014064", "end": "2025-07-07 13:10:00.935432", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:10:00.921368", "stderr": "error: snap \"docker\" has \"service-control\" change in progress", "stderr_lines": ["error: snap \"docker\" has \"service-control\" change in progress"], "stdout": "", "stdout_lines": []}
2025-07-07 09:10:00,947 p=66114 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:10:00,958 p=66114 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:00.014316", "end": "2025-07-07 13:10:00.944552", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:10:00.930236", "stderr": "error: snap \"docker\" has \"service-control\" change in progress", "stderr_lines": ["error: snap \"docker\" has \"service-control\" change in progress"], "stdout": "", "stdout_lines": []}
2025-07-07 09:10:00,958 p=66114 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:10:01,052 p=66114 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:10:01,066 p=66114 u=gpadmin n=ansible | TASK [docker : Add user to docker group] ***************************************
2025-07-07 09:10:01,093 p=66114 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:10:01,110 p=66114 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:10:01,138 p=66114 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:10:01,140 p=66114 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:10:01,148 p=66114 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:10:01,157 p=66114 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] ******************************************
2025-07-07 09:10:02,185 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:10:02,200 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:10:02,222 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:10:02,230 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:10:02,321 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:10:02,493 p=66114 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] *************************************************
2025-07-07 09:10:02,503 p=66114 u=gpadmin n=ansible | TASK [Gathering Facts] *********************************************************
2025-07-07 09:10:03,689 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:10:03,727 p=66114 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] ***********
2025-07-07 09:10:04,023 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:10:04,036 p=66114 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] ****
2025-07-07 09:10:04,756 p=66114 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:10:04,769 p=66114 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] ***************
2025-07-07 09:10:05,058 p=66114 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:10:05,072 p=66114 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] **********************
2025-07-07 09:10:05,706 p=66114 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:10:05,723 p=66114 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] *************************************
2025-07-07 09:10:06,237 p=66114 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:10:06,252 p=66114 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] ****************************
2025-07-07 09:10:06,570 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:10:06,585 p=66114 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] ******************************
2025-07-07 09:10:06,604 p=66114 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\nff80b8e8e272   rayproject/ray:2.9.0   \"ray start --head --…\"   Less than a second ago   Up Less than a second             ray_head"
}
2025-07-07 09:10:06,619 p=66114 u=gpadmin n=ansible | TASK [ray_head : Wait for a moment to let Ray head node initialize] ************
2025-07-07 09:10:06,633 p=66114 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:10:06,634 p=66114 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:10:16,638 p=66114 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:10:16,653 p=66114 u=gpadmin n=ansible | TASK [ray_head : Check Ray head node status] ***********************************
2025-07-07 09:10:16,977 p=66114 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_head", "ray", "status"], "delta": "0:00:00.032873", "end": "2025-07-07 09:10:16.934555", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:10:16.901682", "stderr": "Error response from daemon: container ff80b8e8e272fc6a976b3cdf9e7a9a29a72059465f98367ad3fa7a39420df3a7 is not running", "stderr_lines": ["Error response from daemon: container ff80b8e8e272fc6a976b3cdf9e7a9a29a72059465f98367ad3fa7a39420df3a7 is not running"], "stdout": "", "stdout_lines": []}
2025-07-07 09:10:16,977 p=66114 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:10:16,987 p=66114 u=gpadmin n=ansible | TASK [ray_head : Print Ray head node status] ***********************************
2025-07-07 09:10:17,024 p=66114 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": []
}
2025-07-07 09:10:17,080 p=66114 u=gpadmin n=ansible | PLAY [Configure Ray Worker Nodes] **********************************************
2025-07-07 09:10:17,088 p=66114 u=gpadmin n=ansible | TASK [Gathering Facts] *********************************************************
2025-07-07 09:10:17,799 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:10:17,946 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:10:17,977 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:10:17,982 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:10:18,045 p=66114 u=gpadmin n=ansible | TASK [ray_worker : Ensure Ray temporary directory exists on worker node] *******
2025-07-07 09:10:18,219 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:10:18,236 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:10:18,252 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:10:18,259 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:10:18,271 p=66114 u=gpadmin n=ansible | TASK [ray_worker : Stop and remove existing Ray worker container (idempotency)] ***
2025-07-07 09:10:18,556 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:10:18,562 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:10:18,579 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:10:18,596 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:10:18,608 p=66114 u=gpadmin n=ansible | TASK [ray_worker : Remove old Ray worker start script (idempotency)] ***********
2025-07-07 09:10:18,788 p=66114 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:10:18,808 p=66114 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:10:18,808 p=66114 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:10:18,825 p=66114 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:10:18,836 p=66114 u=gpadmin n=ansible | TASK [ray_worker : Copy Ray worker start script to worker node] ****************
2025-07-07 09:10:18,940 p=66114 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined
2025-07-07 09:10:18,941 p=66114 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "msg": "AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined"}
2025-07-07 09:10:18,967 p=66114 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined
2025-07-07 09:10:18,967 p=66114 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "msg": "AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined"}
2025-07-07 09:10:18,990 p=66114 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined
2025-07-07 09:10:18,990 p=66114 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "msg": "AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined"}
2025-07-07 09:10:19,004 p=66114 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined
2025-07-07 09:10:19,005 p=66114 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "msg": "AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined"}
2025-07-07 09:10:19,006 p=66114 u=gpadmin n=ansible | PLAY RECAP *********************************************************************
2025-07-07 09:10:19,006 p=66114 u=gpadmin n=ansible | G-241                      : ok=13   changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=1   
2025-07-07 09:10:19,006 p=66114 u=gpadmin n=ansible | G-242                      : ok=13   changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=2   
2025-07-07 09:10:19,006 p=66114 u=gpadmin n=ansible | G-243                      : ok=13   changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=2   
2025-07-07 09:10:19,006 p=66114 u=gpadmin n=ansible | G-244                      : ok=13   changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=2   
2025-07-07 09:10:19,006 p=66114 u=gpadmin n=ansible | MASTER                     : ok=20   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=1   
2025-07-07 09:11:50,222 p=68406 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] ***************************************
2025-07-07 09:11:50,231 p=68406 u=gpadmin n=ansible | TASK [Gathering Facts] *********************************************************
2025-07-07 09:11:51,720 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:11:51,922 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:11:51,938 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:11:52,003 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:11:52,018 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:11:52,090 p=68406 u=gpadmin n=ansible | TASK [common : Update apt cache] ***********************************************
2025-07-07 09:11:52,572 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:11:52,573 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:11:52,575 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:11:52,577 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:11:52,945 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:11:52,958 p=68406 u=gpadmin n=ansible | TASK [common : Install common packages] ****************************************
2025-07-07 09:11:53,418 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:11:53,443 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:11:53,450 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:11:53,452 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:11:53,990 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:11:54,003 p=68406 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] *********************************
2025-07-07 09:11:54,287 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:11:54,292 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:11:54,299 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:11:54,308 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:11:54,396 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:11:54,410 p=68406 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] **********************************
2025-07-07 09:11:54,694 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:11:54,709 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:11:54,709 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:11:54,710 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:11:54,790 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:11:54,841 p=68406 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] *********************
2025-07-07 09:11:55,124 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:11:55,124 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:11:55,125 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:11:55,135 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:11:55,213 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:11:55,227 p=68406 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] *********************************************
2025-07-07 09:11:55,259 p=68406 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:11:55,276 p=68406 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:11:55,305 p=68406 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:11:55,306 p=68406 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:11:55,314 p=68406 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:11:55,323 p=68406 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] **************************************
2025-07-07 09:11:55,355 p=68406 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:11:55,370 p=68406 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:11:55,384 p=68406 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:11:55,385 p=68406 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:11:55,393 p=68406 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:11:55,401 p=68406 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] ******************************************
2025-07-07 09:11:55,433 p=68406 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:11:55,452 p=68406 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:11:55,466 p=68406 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:11:55,468 p=68406 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:11:55,476 p=68406 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:11:55,484 p=68406 u=gpadmin n=ansible | TASK [docker : Check Docker service status] ************************************
2025-07-07 09:11:55,649 p=68406 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003107", "end": "2025-07-07 13:11:55.634834", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:11:55.631727", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:11:55,649 p=68406 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:11:55,665 p=68406 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003457", "end": "2025-07-07 13:11:55.654285", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:11:55.650828", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:11:55,666 p=68406 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:11:55,692 p=68406 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003135", "end": "2025-07-07 13:11:55.675633", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:11:55.672498", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:11:55,692 p=68406 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:11:55,697 p=68406 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003216", "end": "2025-07-07 13:11:55.683102", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:11:55.679886", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:11:55,697 p=68406 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:11:55,788 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:11:55,801 p=68406 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] *********************************
2025-07-07 09:11:55,844 p=68406 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:11:55,872 p=68406 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:11:55,874 p=68406 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:11:55,881 p=68406 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:11:56,495 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:11:56,512 p=68406 u=gpadmin n=ansible | TASK [docker : Wait for any in-progress snap operations to complete] ***********
2025-07-07 09:11:56,540 p=68406 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:11:56,724 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:11:56,729 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:11:56,741 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:11:56,757 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:11:56,770 p=68406 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ************************************
2025-07-07 09:11:56,797 p=68406 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:11:57,135 p=68406 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:12:30,160 p=68406 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:12:30,186 p=68406 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:12:30,190 p=68406 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:12:30,203 p=68406 u=gpadmin n=ansible | TASK [docker : Add user to docker group] ***************************************
2025-07-07 09:12:30,235 p=68406 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:12:30,253 p=68406 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:12:30,282 p=68406 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:12:30,283 p=68406 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:12:30,291 p=68406 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:12:30,300 p=68406 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] ******************************************
2025-07-07 09:12:31,256 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:12:31,269 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:12:31,286 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:12:31,296 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:12:31,442 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:12:31,615 p=68406 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] *************************************************
2025-07-07 09:12:31,625 p=68406 u=gpadmin n=ansible | TASK [Gathering Facts] *********************************************************
2025-07-07 09:12:32,852 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:12:32,885 p=68406 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] ***********
2025-07-07 09:12:33,188 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:12:33,202 p=68406 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] ****
2025-07-07 09:12:33,902 p=68406 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:12:33,916 p=68406 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] ***************
2025-07-07 09:12:34,205 p=68406 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:12:34,219 p=68406 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] **********************
2025-07-07 09:12:34,866 p=68406 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:12:34,882 p=68406 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] *************************************
2025-07-07 09:12:35,430 p=68406 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:12:35,444 p=68406 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] ****************************
2025-07-07 09:12:35,765 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:12:35,780 p=68406 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] ******************************
2025-07-07 09:12:35,805 p=68406 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n06fe8891c68a   rayproject/ray:2.9.0   \"ray start --head --…\"   Less than a second ago   Up Less than a second             ray_head"
}
2025-07-07 09:12:35,819 p=68406 u=gpadmin n=ansible | TASK [ray_head : Wait for a moment to let Ray head node initialize] ************
2025-07-07 09:12:35,838 p=68406 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:12:35,839 p=68406 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:12:45,843 p=68406 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:12:45,857 p=68406 u=gpadmin n=ansible | TASK [ray_head : Check Ray head node status] ***********************************
2025-07-07 09:12:46,187 p=68406 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_head", "ray", "status"], "delta": "0:00:00.031145", "end": "2025-07-07 09:12:46.148218", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:12:46.117073", "stderr": "Error response from daemon: container 06fe8891c68a4b5175d92237309f2e2c86d23e332863704a5c165b3a1090a4b7 is not running", "stderr_lines": ["Error response from daemon: container 06fe8891c68a4b5175d92237309f2e2c86d23e332863704a5c165b3a1090a4b7 is not running"], "stdout": "", "stdout_lines": []}
2025-07-07 09:12:46,188 p=68406 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:12:46,201 p=68406 u=gpadmin n=ansible | TASK [ray_head : Print Ray head node status] ***********************************
2025-07-07 09:12:46,238 p=68406 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": []
}
2025-07-07 09:12:46,294 p=68406 u=gpadmin n=ansible | PLAY [Configure Ray Worker Nodes] **********************************************
2025-07-07 09:12:46,302 p=68406 u=gpadmin n=ansible | TASK [Gathering Facts] *********************************************************
2025-07-07 09:12:47,116 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:12:47,126 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:12:47,129 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:12:47,227 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:12:47,290 p=68406 u=gpadmin n=ansible | TASK [ray_worker : Ensure Ray temporary directory exists on worker node] *******
2025-07-07 09:12:47,462 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:12:47,471 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:12:47,486 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:12:47,510 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:12:47,521 p=68406 u=gpadmin n=ansible | TASK [ray_worker : Stop and remove existing Ray worker container (idempotency)] ***
2025-07-07 09:12:47,798 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:12:47,819 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:12:47,838 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:12:47,840 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:12:47,851 p=68406 u=gpadmin n=ansible | TASK [ray_worker : Remove old Ray worker start script (idempotency)] ***********
2025-07-07 09:12:48,016 p=68406 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:12:48,047 p=68406 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:12:48,048 p=68406 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:12:48,071 p=68406 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:12:48,084 p=68406 u=gpadmin n=ansible | TASK [ray_worker : Copy Ray worker start script to worker node] ****************
2025-07-07 09:12:48,201 p=68406 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined
2025-07-07 09:12:48,201 p=68406 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "msg": "AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined"}
2025-07-07 09:12:48,213 p=68406 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined
2025-07-07 09:12:48,213 p=68406 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "msg": "AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined"}
2025-07-07 09:12:48,230 p=68406 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined
2025-07-07 09:12:48,230 p=68406 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "msg": "AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined"}
2025-07-07 09:12:48,245 p=68406 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined
2025-07-07 09:12:48,245 p=68406 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "msg": "AnsibleUndefinedVariable: 'ray_head_ip' is undefined. 'ray_head_ip' is undefined"}
2025-07-07 09:12:48,246 p=68406 u=gpadmin n=ansible | PLAY RECAP *********************************************************************
2025-07-07 09:12:48,246 p=68406 u=gpadmin n=ansible | G-241                      : ok=14   changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=1   
2025-07-07 09:12:48,247 p=68406 u=gpadmin n=ansible | G-242                      : ok=14   changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=1   
2025-07-07 09:12:48,247 p=68406 u=gpadmin n=ansible | G-243                      : ok=14   changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=1   
2025-07-07 09:12:48,247 p=68406 u=gpadmin n=ansible | G-244                      : ok=14   changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=1   
2025-07-07 09:12:48,247 p=68406 u=gpadmin n=ansible | MASTER                     : ok=20   changed=4    unreachable=0    failed=0    skipped=6    rescued=0    ignored=1   
2025-07-07 09:14:51,045 p=71281 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 09:14:51,055 p=71281 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:14:52,519 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:14:52,712 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:14:52,755 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:14:52,772 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:14:52,808 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:14:52,887 p=71281 u=gpadmin n=ansible | TASK [common : Update apt cache] **********************************************************
2025-07-07 09:14:53,374 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:14:53,374 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:14:53,391 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:14:53,393 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:14:53,786 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:14:53,799 p=71281 u=gpadmin n=ansible | TASK [common : Install common packages] ***************************************************
2025-07-07 09:14:54,254 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:14:54,283 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:14:54,288 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:14:54,297 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:14:54,839 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:14:54,851 p=71281 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] ********************************************
2025-07-07 09:14:55,128 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:14:55,132 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:14:55,148 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:14:55,153 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:14:55,243 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:14:55,256 p=71281 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] *********************************************
2025-07-07 09:14:55,534 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:14:55,538 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:14:55,544 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:14:55,557 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:14:55,644 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:14:55,699 p=71281 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] ********************************
2025-07-07 09:14:55,967 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:14:55,975 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:14:55,979 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:14:55,982 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:14:56,084 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:14:56,101 p=71281 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] ********************************************************
2025-07-07 09:14:56,129 p=71281 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:14:56,145 p=71281 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:14:56,160 p=71281 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:14:56,174 p=71281 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:14:56,183 p=71281 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:14:56,191 p=71281 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] *************************************************
2025-07-07 09:14:56,225 p=71281 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:14:56,241 p=71281 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:14:56,254 p=71281 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:14:56,256 p=71281 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:14:56,263 p=71281 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:14:56,272 p=71281 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] *****************************************************
2025-07-07 09:14:56,308 p=71281 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:14:56,324 p=71281 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:14:56,339 p=71281 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:14:56,339 p=71281 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:14:56,350 p=71281 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:14:56,360 p=71281 u=gpadmin n=ansible | TASK [docker : Check Docker service status] ***********************************************
2025-07-07 09:14:56,536 p=71281 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003172", "end": "2025-07-07 13:14:56.517265", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:14:56.514093", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:14:56,537 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:14:56,563 p=71281 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003256", "end": "2025-07-07 13:14:56.547619", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:14:56.544363", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:14:56,563 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:14:56,567 p=71281 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003293", "end": "2025-07-07 13:14:56.550626", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:14:56.547333", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:14:56,567 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:14:56,578 p=71281 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003237", "end": "2025-07-07 13:14:56.560669", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:14:56.557432", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:14:56,578 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:14:56,661 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:14:56,675 p=71281 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] ********************************************
2025-07-07 09:14:56,732 p=71281 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:14:56,752 p=71281 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:14:56,752 p=71281 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:14:56,765 p=71281 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:14:57,375 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:14:57,388 p=71281 u=gpadmin n=ansible | TASK [docker : Wait for any in-progress snap operations to complete] **********************
2025-07-07 09:14:57,416 p=71281 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:14:57,586 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:14:57,604 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:14:57,620 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:14:57,627 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:14:57,641 p=71281 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ***********************************************
2025-07-07 09:14:57,666 p=71281 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:14:57,993 p=71281 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:15:31,052 p=71281 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:15:31,059 p=71281 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:15:31,073 p=71281 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:15:31,090 p=71281 u=gpadmin n=ansible | TASK [docker : Add user to docker group] **************************************************
2025-07-07 09:15:31,120 p=71281 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:15:31,138 p=71281 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:15:31,153 p=71281 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:15:31,168 p=71281 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:15:31,177 p=71281 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:15:31,186 p=71281 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] *****************************************************
2025-07-07 09:15:32,139 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:15:32,141 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:15:32,165 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:15:32,252 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:15:32,316 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:15:32,481 p=71281 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] ************************************************************
2025-07-07 09:15:32,491 p=71281 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:15:33,696 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:15:33,731 p=71281 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] **********************
2025-07-07 09:15:34,038 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:15:34,056 p=71281 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] ***************
2025-07-07 09:15:34,784 p=71281 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:15:34,798 p=71281 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] **************************
2025-07-07 09:15:35,090 p=71281 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:15:35,108 p=71281 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] *********************************
2025-07-07 09:15:35,771 p=71281 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:15:35,786 p=71281 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] ************************************************
2025-07-07 09:15:36,316 p=71281 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:15:36,332 p=71281 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] ***************************************
2025-07-07 09:15:36,641 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:15:36,656 p=71281 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] *****************************************
2025-07-07 09:15:36,676 p=71281 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n0c24e7a16b22   rayproject/ray:2.9.0   \"ray start --head --…\"   Less than a second ago   Up Less than a second             ray_head"
}
2025-07-07 09:15:36,691 p=71281 u=gpadmin n=ansible | TASK [ray_head : Wait for a moment to let Ray head node initialize] ***********************
2025-07-07 09:15:36,712 p=71281 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:15:36,713 p=71281 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:15:46,717 p=71281 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:15:46,731 p=71281 u=gpadmin n=ansible | TASK [ray_head : Check Ray head node status] **********************************************
2025-07-07 09:15:47,044 p=71281 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_head", "ray", "status"], "delta": "0:00:00.027208", "end": "2025-07-07 09:15:47.002038", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:15:46.974830", "stderr": "Error response from daemon: Container 0c24e7a16b227a4af7face02a67d1045352cf57d73e047da562abdc2c867f0f5 is restarting, wait until the container is running", "stderr_lines": ["Error response from daemon: Container 0c24e7a16b227a4af7face02a67d1045352cf57d73e047da562abdc2c867f0f5 is restarting, wait until the container is running"], "stdout": "", "stdout_lines": []}
2025-07-07 09:15:47,045 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:15:47,058 p=71281 u=gpadmin n=ansible | TASK [ray_head : Print Ray head node status] **********************************************
2025-07-07 09:15:47,101 p=71281 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": []
}
2025-07-07 09:15:47,156 p=71281 u=gpadmin n=ansible | PLAY [Configure Ray Worker Nodes] *********************************************************
2025-07-07 09:15:47,164 p=71281 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:15:47,983 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:15:48,022 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:15:48,031 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:15:48,034 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:15:48,104 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Ensure Ray temporary directory exists on worker node] ******************
2025-07-07 09:15:48,284 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:15:48,294 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:15:48,302 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:15:48,342 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:15:48,354 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Stop and remove existing Ray worker container (idempotency)] ***********
2025-07-07 09:15:48,640 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:15:48,654 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:15:48,669 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:15:48,692 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:15:48,706 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Remove old Ray worker start script (idempotency)] **********************
2025-07-07 09:15:48,865 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:15:48,895 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:15:48,908 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:15:48,937 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:15:48,950 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Copy Ray worker start script to worker node] ***************************
2025-07-07 09:15:49,424 p=71281 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:15:49,451 p=71281 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:15:49,460 p=71281 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:15:49,496 p=71281 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:15:49,509 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Start Ray worker container] ********************************************
2025-07-07 09:15:50,303 p=71281 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:15:50,314 p=71281 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:15:50,352 p=71281 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:15:50,359 p=71281 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:15:50,372 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Display Ray worker container status] ***********************************
2025-07-07 09:15:50,556 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:15:50,582 p=71281 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:15:50,584 p=71281 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:15:50,604 p=71281 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:15:50,620 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Print Ray worker container status] *************************************
2025-07-07 09:15:50,670 p=71281 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS                  PORTS     NAMES\nbbb255787f69   rayproject/ray:2.9.0   \"ray start --address…\"   1 second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:15:50,685 p=71281 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS                  PORTS     NAMES\n8bf31be322c8   rayproject/ray:2.9.0   \"ray start --address…\"   1 second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:15:50,687 p=71281 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS                  PORTS     NAMES\na70c0b2f3a47   rayproject/ray:2.9.0   \"ray start --address…\"   1 second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:15:50,703 p=71281 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS                  PORTS     NAMES\ncc12a5974174   rayproject/ray:2.9.0   \"ray start --address…\"   1 second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:15:50,711 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Wait for a moment to let Ray worker node initialize] *******************
2025-07-07 09:15:50,726 p=71281 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:15:50,727 p=71281 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:16:00,731 p=71281 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:16:00,744 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Check Ray worker node status] ******************************************
2025-07-07 09:16:00,952 p=71281 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.040181", "end": "2025-07-07 13:16:00.936726", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:16:00.896545", "stderr": "Error response from daemon: Container bbb255787f69ba53c66eb315c721cb0c4fd52c904381d597622f94d9a9ca5760 is restarting, wait until the container is running", "stderr_lines": ["Error response from daemon: Container bbb255787f69ba53c66eb315c721cb0c4fd52c904381d597622f94d9a9ca5760 is restarting, wait until the container is running"], "stdout": "", "stdout_lines": []}
2025-07-07 09:16:00,953 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:16:00,960 p=71281 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.038623", "end": "2025-07-07 13:16:00.947397", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:16:00.908774", "stderr": "Error response from daemon: Container 8bf31be322c82a0ccc0e651878c1834e8007624499622fcf81b35eb327995584 is restarting, wait until the container is running", "stderr_lines": ["Error response from daemon: Container 8bf31be322c82a0ccc0e651878c1834e8007624499622fcf81b35eb327995584 is restarting, wait until the container is running"], "stdout": "", "stdout_lines": []}
2025-07-07 09:16:00,960 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:16:00,986 p=71281 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.030878", "end": "2025-07-07 13:16:00.973172", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:16:00.942294", "stderr": "Error response from daemon: Container cc12a5974174be3941007e7849578c32ec5f375c1480483168966f3d4f4d1f51 is restarting, wait until the container is running", "stderr_lines": ["Error response from daemon: Container cc12a5974174be3941007e7849578c32ec5f375c1480483168966f3d4f4d1f51 is restarting, wait until the container is running"], "stdout": "", "stdout_lines": []}
2025-07-07 09:16:00,987 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:16:00,988 p=71281 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.040949", "end": "2025-07-07 13:16:00.975052", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:16:00.934103", "stderr": "Error response from daemon: Container a70c0b2f3a47d37428a9ae96cb13261c03637d5ccfd46895c7cf75b89251aaad is restarting, wait until the container is running", "stderr_lines": ["Error response from daemon: Container a70c0b2f3a47d37428a9ae96cb13261c03637d5ccfd46895c7cf75b89251aaad is restarting, wait until the container is running"], "stdout": "", "stdout_lines": []}
2025-07-07 09:16:00,989 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:16:01,004 p=71281 u=gpadmin n=ansible | TASK [ray_worker : Print Ray worker node status] ******************************************
2025-07-07 09:16:01,076 p=71281 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": []
}
2025-07-07 09:16:01,079 p=71281 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": []
}
2025-07-07 09:16:01,093 p=71281 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": []
}
2025-07-07 09:16:01,106 p=71281 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": []
}
2025-07-07 09:16:01,214 p=71281 u=gpadmin n=ansible | PLAY [Verify Ray Cluster Deployment] ******************************************************
2025-07-07 09:16:01,234 p=71281 u=gpadmin n=ansible | TASK [Check Ray head node status] *********************************************************
2025-07-07 09:16:01,573 p=71281 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_head", "ray", "status"], "delta": "0:00:00.031375", "end": "2025-07-07 09:16:01.534976", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:16:01.503601", "stderr": "Error response from daemon: Container 0c24e7a16b227a4af7face02a67d1045352cf57d73e047da562abdc2c867f0f5 is restarting, wait until the container is running", "stderr_lines": ["Error response from daemon: Container 0c24e7a16b227a4af7face02a67d1045352cf57d73e047da562abdc2c867f0f5 is restarting, wait until the container is running"], "stdout": "", "stdout_lines": []}
2025-07-07 09:16:01,573 p=71281 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:16:01,589 p=71281 u=gpadmin n=ansible | TASK [Display Ray cluster status] *********************************************************
2025-07-07 09:16:01,610 p=71281 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:16:01,662 p=71281 u=gpadmin n=ansible | TASK [Display Ray cluster error] **********************************************************
2025-07-07 09:16:01,687 p=71281 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "Ray cluster status check failed: Error response from daemon: Container 0c24e7a16b227a4af7face02a67d1045352cf57d73e047da562abdc2c867f0f5 is restarting, wait until the container is running"
}
2025-07-07 09:16:01,714 p=71281 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:16:01,714 p=71281 u=gpadmin n=ansible | G-241                      : ok=21   changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=2   
2025-07-07 09:16:01,714 p=71281 u=gpadmin n=ansible | G-242                      : ok=20   changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=2   
2025-07-07 09:16:01,714 p=71281 u=gpadmin n=ansible | G-243                      : ok=20   changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=2   
2025-07-07 09:16:01,714 p=71281 u=gpadmin n=ansible | G-244                      : ok=20   changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=2   
2025-07-07 09:16:01,715 p=71281 u=gpadmin n=ansible | MASTER                     : ok=22   changed=4    unreachable=0    failed=0    skipped=7    rescued=0    ignored=2   
2025-07-07 09:20:53,565 p=77484 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 09:20:53,574 p=77484 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:20:55,092 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:20:55,254 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:20:55,285 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:20:55,302 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:20:55,307 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:20:55,379 p=77484 u=gpadmin n=ansible | TASK [common : Update apt cache] **********************************************************
2025-07-07 09:20:55,853 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:20:55,854 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:20:55,854 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:20:55,859 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:20:56,244 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:20:56,257 p=77484 u=gpadmin n=ansible | TASK [common : Install common packages] ***************************************************
2025-07-07 09:20:56,710 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:20:56,739 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:20:56,749 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:20:56,774 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:20:57,306 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:20:57,319 p=77484 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] ********************************************
2025-07-07 09:20:57,597 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:20:57,604 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:20:57,612 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:20:57,615 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:20:57,704 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:20:57,717 p=77484 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] *********************************************
2025-07-07 09:20:58,005 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:20:58,006 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:20:58,008 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:20:58,016 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:20:58,102 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:20:58,156 p=77484 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] ********************************
2025-07-07 09:20:58,418 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:20:58,419 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:20:58,432 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:20:58,452 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:20:58,538 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:20:58,548 p=77484 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] ********************************************************
2025-07-07 09:20:58,584 p=77484 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:20:58,599 p=77484 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:20:58,614 p=77484 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:20:58,615 p=77484 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:20:58,623 p=77484 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:20:58,631 p=77484 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] *************************************************
2025-07-07 09:20:58,663 p=77484 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:20:58,678 p=77484 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:20:58,691 p=77484 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:20:58,693 p=77484 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:20:58,704 p=77484 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:20:58,712 p=77484 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] *****************************************************
2025-07-07 09:20:58,747 p=77484 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:20:58,761 p=77484 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:20:58,775 p=77484 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:20:58,777 p=77484 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:20:58,787 p=77484 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:20:58,796 p=77484 u=gpadmin n=ansible | TASK [docker : Check Docker service status] ***********************************************
2025-07-07 09:20:58,965 p=77484 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003077", "end": "2025-07-07 13:20:58.950336", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:20:58.947259", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:20:58,966 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:20:58,978 p=77484 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003439", "end": "2025-07-07 13:20:58.966517", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:20:58.963078", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:20:58,978 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:20:58,984 p=77484 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003195", "end": "2025-07-07 13:20:58.972358", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:20:58.969163", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:20:58,984 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:20:58,996 p=77484 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003210", "end": "2025-07-07 13:20:58.983028", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:20:58.979818", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:20:58,996 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:20:59,092 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:20:59,105 p=77484 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] ********************************************
2025-07-07 09:20:59,149 p=77484 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:20:59,164 p=77484 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:20:59,183 p=77484 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:20:59,192 p=77484 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:20:59,782 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:20:59,795 p=77484 u=gpadmin n=ansible | TASK [docker : Wait for any in-progress snap operations to complete] **********************
2025-07-07 09:20:59,823 p=77484 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:21:00,001 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:21:00,008 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:21:00,019 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:21:00,032 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:21:00,046 p=77484 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ***********************************************
2025-07-07 09:21:00,074 p=77484 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:21:00,419 p=77484 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:21:33,446 p=77484 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:21:33,470 p=77484 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:21:33,587 p=77484 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:21:33,604 p=77484 u=gpadmin n=ansible | TASK [docker : Add user to docker group] **************************************************
2025-07-07 09:21:33,633 p=77484 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:21:33,651 p=77484 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:21:33,666 p=77484 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:21:33,681 p=77484 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:21:33,688 p=77484 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:21:33,697 p=77484 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] *****************************************************
2025-07-07 09:21:34,698 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:21:34,709 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:21:34,723 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:21:34,730 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:21:34,855 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:21:35,020 p=77484 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] ************************************************************
2025-07-07 09:21:35,031 p=77484 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:21:36,238 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:21:36,273 p=77484 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] **********************
2025-07-07 09:21:36,579 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:21:36,593 p=77484 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] ***************
2025-07-07 09:21:37,331 p=77484 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:21:37,345 p=77484 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] **************************
2025-07-07 09:21:37,631 p=77484 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:21:37,647 p=77484 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] *********************************
2025-07-07 09:21:38,323 p=77484 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:21:38,337 p=77484 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] ************************************************
2025-07-07 09:21:38,873 p=77484 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:21:38,888 p=77484 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] ***************************************
2025-07-07 09:21:39,220 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:21:39,235 p=77484 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] *****************************************
2025-07-07 09:21:39,260 p=77484 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS                  PORTS     NAMES\nc5fce4a320ba   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   1 second ago   Up Less than a second             ray_head"
}
2025-07-07 09:21:39,274 p=77484 u=gpadmin n=ansible | TASK [ray_head : Wait for a moment to let Ray head node initialize] ***********************
2025-07-07 09:21:39,295 p=77484 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:21:39,295 p=77484 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:21:49,300 p=77484 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:21:49,313 p=77484 u=gpadmin n=ansible | TASK [ray_head : Check Ray head node status] **********************************************
2025-07-07 09:21:51,341 p=77484 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_head", "ray", "status"], "delta": "0:00:01.742450", "end": "2025-07-07 09:21:51.301048", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:21:49.558598", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:21:51,341 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:21:51,356 p=77484 u=gpadmin n=ansible | TASK [ray_head : Print Ray head node status] **********************************************
2025-07-07 09:21:51,398 p=77484 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": []
}
2025-07-07 09:21:51,453 p=77484 u=gpadmin n=ansible | PLAY [Configure Ray Worker Nodes] *********************************************************
2025-07-07 09:21:51,461 p=77484 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:21:52,270 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:21:52,273 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:21:52,297 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:21:52,342 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:21:52,403 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Ensure Ray temporary directory exists on worker node] ******************
2025-07-07 09:21:52,580 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:21:52,585 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:21:52,608 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:21:52,631 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:21:52,644 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Stop and remove existing Ray worker container (idempotency)] ***********
2025-07-07 09:21:52,998 p=77484 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:21:53,025 p=77484 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:21:53,033 p=77484 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:21:53,049 p=77484 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:21:53,062 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Remove old Ray worker start script (idempotency)] **********************
2025-07-07 09:21:53,235 p=77484 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:21:53,252 p=77484 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:21:53,266 p=77484 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:21:53,310 p=77484 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:21:53,326 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Copy Ray worker start script to worker node] ***************************
2025-07-07 09:21:53,793 p=77484 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:21:53,798 p=77484 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:21:53,816 p=77484 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:21:53,836 p=77484 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:21:53,847 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Start Ray worker container] ********************************************
2025-07-07 09:21:54,378 p=77484 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:21:54,398 p=77484 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:21:54,407 p=77484 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:21:54,410 p=77484 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:21:54,422 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Display Ray worker container status] ***********************************
2025-07-07 09:21:54,607 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:21:54,629 p=77484 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:21:54,630 p=77484 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:21:54,657 p=77484 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:21:54,673 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Print Ray worker container status] *************************************
2025-07-07 09:21:54,703 p=77484 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n5cf4ece49ed0   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:21:54,735 p=77484 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n0ca8007acb7c   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:21:54,738 p=77484 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n8e955edacf6d   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:21:54,753 p=77484 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\ne7ae4bbe8e02   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:21:54,761 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Wait for a moment to let Ray worker node initialize] *******************
2025-07-07 09:21:54,782 p=77484 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:21:54,782 p=77484 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:22:04,787 p=77484 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:22:04,799 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Check Ray worker node status] ******************************************
2025-07-07 09:22:05,867 p=77484 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.894081", "end": "2025-07-07 13:22:05.850604", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:22:04.956523", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:22:05,867 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:22:05,884 p=77484 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.891351", "end": "2025-07-07 13:22:05.869934", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:22:04.978583", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:22:05,884 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:22:05,906 p=77484 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.924160", "end": "2025-07-07 13:22:05.893251", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:22:04.969091", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:22:05,906 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:22:05,914 p=77484 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.896672", "end": "2025-07-07 13:22:05.900375", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:22:05.003703", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:22:05,914 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:22:05,927 p=77484 u=gpadmin n=ansible | TASK [ray_worker : Print Ray worker node status] ******************************************
2025-07-07 09:22:05,975 p=77484 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": []
}
2025-07-07 09:22:05,999 p=77484 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": []
}
2025-07-07 09:22:06,007 p=77484 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": []
}
2025-07-07 09:22:06,034 p=77484 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": []
}
2025-07-07 09:22:06,153 p=77484 u=gpadmin n=ansible | PLAY [Verify Ray Cluster Deployment] ******************************************************
2025-07-07 09:22:06,173 p=77484 u=gpadmin n=ansible | TASK [Check Ray head node status] *********************************************************
2025-07-07 09:22:08,210 p=77484 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_head", "ray", "status"], "delta": "0:00:01.742913", "end": "2025-07-07 09:22:08.168884", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:22:06.425971", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:22:08,211 p=77484 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:22:08,226 p=77484 u=gpadmin n=ansible | TASK [Display Ray cluster status] *********************************************************
2025-07-07 09:22:08,248 p=77484 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:22:08,300 p=77484 u=gpadmin n=ansible | TASK [Display Ray cluster error] **********************************************************
2025-07-07 09:22:08,327 p=77484 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "Ray cluster status check failed: Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."
}
2025-07-07 09:22:08,354 p=77484 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:22:08,354 p=77484 u=gpadmin n=ansible | G-241                      : ok=21   changed=5    unreachable=0    failed=0    skipped=5    rescued=0    ignored=2   
2025-07-07 09:22:08,354 p=77484 u=gpadmin n=ansible | G-242                      : ok=20   changed=5    unreachable=0    failed=0    skipped=5    rescued=0    ignored=2   
2025-07-07 09:22:08,354 p=77484 u=gpadmin n=ansible | G-243                      : ok=20   changed=5    unreachable=0    failed=0    skipped=5    rescued=0    ignored=2   
2025-07-07 09:22:08,355 p=77484 u=gpadmin n=ansible | G-244                      : ok=20   changed=5    unreachable=0    failed=0    skipped=5    rescued=0    ignored=2   
2025-07-07 09:22:08,355 p=77484 u=gpadmin n=ansible | MASTER                     : ok=22   changed=4    unreachable=0    failed=0    skipped=7    rescued=0    ignored=2   
2025-07-07 09:30:35,488 p=83788 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 09:30:35,497 p=83788 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:30:37,007 p=83788 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:37,125 p=83788 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:37,151 p=83788 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:37,262 p=83788 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:37,291 p=83788 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:37,541 p=83788 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] ************************************************************
2025-07-07 09:30:37,551 p=83788 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:30:38,763 p=83788 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:38,832 p=83788 u=gpadmin n=ansible | PLAY [Configure Ray Worker Nodes] *********************************************************
2025-07-07 09:30:38,841 p=83788 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:30:39,694 p=83788 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:39,703 p=83788 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:39,706 p=83788 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:39,711 p=83788 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:39,904 p=83788 u=gpadmin n=ansible | PLAY [Verify Ray Cluster Deployment] ******************************************************
2025-07-07 09:30:39,944 p=83788 u=gpadmin n=ansible | PLAY [Deploy Monitoring Stack] ************************************************************
2025-07-07 09:30:39,954 p=83788 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:30:40,776 p=83788 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:40,818 p=83788 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:40,832 p=83788 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:40,862 p=83788 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:41,151 p=83788 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:41,354 p=83788 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:30:41,354 p=83788 u=gpadmin n=ansible | G-241                      : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 09:30:41,354 p=83788 u=gpadmin n=ansible | G-242                      : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 09:30:41,354 p=83788 u=gpadmin n=ansible | G-243                      : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 09:30:41,354 p=83788 u=gpadmin n=ansible | G-244                      : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 09:30:41,354 p=83788 u=gpadmin n=ansible | MASTER                     : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 09:30:51,240 p=84582 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] *********************************************************
2025-07-07 09:30:51,250 p=84582 u=gpadmin n=ansible | TASK [Gathering Facts] ***************************************************************************
2025-07-07 09:30:52,354 p=84582 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:52,369 p=84582 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:52,372 p=84582 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:52,419 p=84582 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:52,747 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:52,827 p=84582 u=gpadmin n=ansible | TASK [common : Update apt cache] *****************************************************************
2025-07-07 09:30:53,313 p=84582 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:53,320 p=84582 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:53,322 p=84582 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:53,322 p=84582 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:53,728 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:53,741 p=84582 u=gpadmin n=ansible | TASK [common : Install common packages] **********************************************************
2025-07-07 09:30:54,189 p=84582 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:54,214 p=84582 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:54,233 p=84582 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:54,236 p=84582 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:54,784 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:54,797 p=84582 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] ***************************************************
2025-07-07 09:30:55,107 p=84582 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:55,108 p=84582 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:55,108 p=84582 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:55,114 p=84582 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:55,217 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:55,230 p=84582 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] ****************************************************
2025-07-07 09:30:55,505 p=84582 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:55,513 p=84582 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:55,517 p=84582 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:55,517 p=84582 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:55,621 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:55,677 p=84582 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] ***************************************
2025-07-07 09:30:55,963 p=84582 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:55,964 p=84582 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:55,966 p=84582 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:55,967 p=84582 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:56,062 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:56,075 p=84582 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] ***************************************************************
2025-07-07 09:30:56,104 p=84582 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:30:56,122 p=84582 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:30:56,151 p=84582 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:30:56,154 p=84582 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:30:56,161 p=84582 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:30:56,170 p=84582 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] ********************************************************
2025-07-07 09:30:56,209 p=84582 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:30:56,223 p=84582 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:30:56,239 p=84582 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:30:56,239 p=84582 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:30:56,247 p=84582 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:30:56,256 p=84582 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] ************************************************************
2025-07-07 09:30:56,275 p=84582 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:30:56,303 p=84582 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:30:56,319 p=84582 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:30:56,321 p=84582 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:30:56,332 p=84582 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:30:56,341 p=84582 u=gpadmin n=ansible | TASK [docker : Check Docker service status] ******************************************************
2025-07-07 09:30:56,522 p=84582 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003171", "end": "2025-07-07 13:30:56.507222", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:30:56.504051", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:30:56,522 p=84582 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:30:56,532 p=84582 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003326", "end": "2025-07-07 13:30:56.520210", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:30:56.516884", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:30:56,532 p=84582 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:30:56,537 p=84582 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003092", "end": "2025-07-07 13:30:56.527361", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:30:56.524269", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:30:56,537 p=84582 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:30:56,558 p=84582 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003139", "end": "2025-07-07 13:30:56.545576", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:30:56.542437", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:30:56,558 p=84582 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:30:56,644 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:56,658 p=84582 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] ***************************************************
2025-07-07 09:30:56,702 p=84582 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:30:56,717 p=84582 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:30:56,733 p=84582 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:30:56,744 p=84582 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:30:57,368 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:30:57,382 p=84582 u=gpadmin n=ansible | TASK [docker : Wait for any in-progress snap operations to complete] *****************************
2025-07-07 09:30:57,410 p=84582 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:30:57,578 p=84582 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:30:57,605 p=84582 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:30:57,608 p=84582 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:30:57,627 p=84582 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:30:57,644 p=84582 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ******************************************************
2025-07-07 09:30:57,679 p=84582 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:30:58,007 p=84582 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:31:31,070 p=84582 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:31:31,078 p=84582 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:31:31,083 p=84582 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:31:31,097 p=84582 u=gpadmin n=ansible | TASK [docker : Add user to docker group] *********************************************************
2025-07-07 09:31:31,124 p=84582 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:31:31,141 p=84582 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:31:31,170 p=84582 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:31:31,172 p=84582 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:31:31,183 p=84582 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:31:31,192 p=84582 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] ************************************************************
2025-07-07 09:31:32,179 p=84582 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:31:32,186 p=84582 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:31:32,202 p=84582 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:31:32,250 p=84582 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:31:32,315 p=84582 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:31:32,403 p=84582 u=gpadmin n=ansible |  [ERROR]: User interrupted execution

2025-07-07 09:33:40,769 p=86688 u=gpadmin n=ansible | Using /home/gpadmin/cursor-projects/02-Ray-Deploy/ansible.cfg as config file
2025-07-07 09:33:41,061 p=86688 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 09:33:41,070 p=86688 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:33:42,600 p=86688 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:33:42,621 p=86688 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:33:42,733 p=86688 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:33:42,786 p=86688 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:33:43,790 p=86688 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:33:43,868 p=86688 u=gpadmin n=ansible | TASK [common : Update apt cache] **********************************************************
2025-07-07 09:33:44,350 p=86688 u=gpadmin n=ansible | ok: [G-241] => {"cache_update_time": 1751893770, "cache_updated": false, "changed": false}
2025-07-07 09:33:44,355 p=86688 u=gpadmin n=ansible | ok: [G-244] => {"cache_update_time": 1751892994, "cache_updated": false, "changed": false}
2025-07-07 09:33:44,359 p=86688 u=gpadmin n=ansible | ok: [G-243] => {"cache_update_time": 1751892994, "cache_updated": false, "changed": false}
2025-07-07 09:33:44,363 p=86688 u=gpadmin n=ansible | ok: [G-242] => {"cache_update_time": 1751892995, "cache_updated": false, "changed": false}
2025-07-07 09:33:44,748 p=86688 u=gpadmin n=ansible | ok: [MASTER] => {"cache_update_time": 1751892911, "cache_updated": false, "changed": false}
2025-07-07 09:33:44,761 p=86688 u=gpadmin n=ansible | TASK [common : Install common packages] ***************************************************
2025-07-07 09:33:45,230 p=86688 u=gpadmin n=ansible | ok: [G-241] => {"cache_update_time": 1751893770, "cache_updated": false, "changed": false}
2025-07-07 09:33:45,243 p=86688 u=gpadmin n=ansible | ok: [G-243] => {"cache_update_time": 1751892994, "cache_updated": false, "changed": false}
2025-07-07 09:33:45,255 p=86688 u=gpadmin n=ansible | ok: [G-242] => {"cache_update_time": 1751892995, "cache_updated": false, "changed": false}
2025-07-07 09:33:45,263 p=86688 u=gpadmin n=ansible | ok: [G-244] => {"cache_update_time": 1751892994, "cache_updated": false, "changed": false}
2025-07-07 09:33:45,819 p=86688 u=gpadmin n=ansible | ok: [MASTER] => {"cache_update_time": 1751892911, "cache_updated": false, "changed": false}
2025-07-07 09:33:45,832 p=86688 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] ********************************************
2025-07-07 09:33:46,131 p=86688 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:33:46,133 p=86688 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:33:46,133 p=86688 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:33:46,150 p=86688 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:33:46,247 p=86688 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:33:46,260 p=86688 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] *********************************************
2025-07-07 09:33:46,550 p=86688 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "stat": {"atime": 1751893510.3693118, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 8, "charset": "binary", "ctime": 1751894514.102447, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 16384017, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894514.102447, "nlink": 2, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "1435149338", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:33:46,555 p=86688 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "stat": {"atime": 1751893510.3611715, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 8, "charset": "binary", "ctime": 1751894514.1356137, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 39059468, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894514.1356137, "nlink": 2, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "1105510836", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:33:46,565 p=86688 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "stat": {"atime": 1751893510.357805, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 8, "charset": "binary", "ctime": 1751894514.1358685, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 9699340, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894514.1358685, "nlink": 2, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "3381391995", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:33:46,569 p=86688 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "stat": {"atime": 1751893510.3523293, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 8, "charset": "binary", "ctime": 1751894514.1077826, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 118226955, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894514.1077826, "nlink": 2, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "2833573626", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:33:46,672 p=86688 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "stat": {"atime": 1751894238.2056296, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 16, "charset": "binary", "ctime": 1751894498.643538, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 37618228, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894498.643538, "nlink": 6, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "3803985524", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:33:46,727 p=86688 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] ********************************
2025-07-07 09:33:47,003 p=86688 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.001786", "end": "2025-07-07 13:33:46.987913", "msg": "", "rc": 0, "start": "2025-07-07 13:33:46.986127", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:33:47,004 p=86688 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.001856", "end": "2025-07-07 13:33:46.991923", "msg": "", "rc": 0, "start": "2025-07-07 13:33:46.990067", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:33:47,011 p=86688 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.001872", "end": "2025-07-07 13:33:46.999001", "msg": "", "rc": 0, "start": "2025-07-07 13:33:46.997129", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:33:47,018 p=86688 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.001757", "end": "2025-07-07 13:33:47.008366", "msg": "", "rc": 0, "start": "2025-07-07 13:33:47.006609", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:33:47,120 p=86688 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.006987", "end": "2025-07-07 09:33:47.077831", "msg": "", "rc": 0, "start": "2025-07-07 09:33:47.070844", "stderr": "", "stderr_lines": [], "stdout": "/usr/local/bin/docker", "stdout_lines": ["/usr/local/bin/docker"]}
2025-07-07 09:33:47,133 p=86688 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] ********************************************************
2025-07-07 09:33:47,160 p=86688 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,177 p=86688 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,206 p=86688 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,208 p=86688 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,218 p=86688 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,227 p=86688 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] *************************************************
2025-07-07 09:33:47,249 p=86688 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,279 p=86688 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,294 p=86688 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,296 p=86688 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,306 p=86688 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,315 p=86688 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] *****************************************************
2025-07-07 09:33:47,348 p=86688 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,363 p=86688 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,377 p=86688 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,379 p=86688 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,390 p=86688 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,399 p=86688 u=gpadmin n=ansible | TASK [docker : Check Docker service status] ***********************************************
2025-07-07 09:33:47,579 p=86688 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003126", "end": "2025-07-07 13:33:47.563558", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:33:47.560432", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:33:47,579 p=86688 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:33:47,584 p=86688 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003403", "end": "2025-07-07 13:33:47.572818", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:33:47.569415", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:33:47,584 p=86688 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:33:47,596 p=86688 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003271", "end": "2025-07-07 13:33:47.585402", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:33:47.582131", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:33:47,596 p=86688 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:33:47,614 p=86688 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003289", "end": "2025-07-07 13:33:47.601134", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:33:47.597845", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:33:47,615 p=86688 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:33:47,733 p=86688 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.012575", "end": "2025-07-07 09:33:47.689663", "msg": "", "rc": 0, "start": "2025-07-07 09:33:47.677088", "stderr": "", "stderr_lines": [], "stdout": "active", "stdout_lines": ["active"]}
2025-07-07 09:33:47,746 p=86688 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] ********************************************
2025-07-07 09:33:47,790 p=86688 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_service_status.rc == 0", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,821 p=86688 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_service_status.rc == 0", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,822 p=86688 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_service_status.rc == 0", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:47,832 p=86688 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_service_status.rc == 0", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:48,492 p=86688 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "enabled": true, "name": "docker", "state": "started", "status": {"ActiveEnterTimestamp": "Sat 2025-07-05 12:10:24 EDT", "ActiveEnterTimestampMonotonic": "14500501", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "time-set.target network-online.target system.slice basic.target nss-lookup.target docker.socket firewalld.service systemd-journald.socket containerd.service sysinit.target", "AllowIsolate": "no", "AssertResult": "yes", "AssertTimestamp": "Sat 2025-07-05 12:10:23 EDT", "AssertTimestampMonotonic": "13516583", "Before": "shutdown.target multi-user.target", "BlockIOAccounting": "no", "BlockIOWeight": "[not set]", "CPUAccounting": "yes", "CPUAffinityFromNUMA": "no", "CPUQuotaPerSecUSec": "infinity", "CPUQuotaPeriodUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "[not set]", "CPUUsageNSec": "92402717000", "CPUWeight": "[not set]", "CacheDirectoryMode": "0755", "CanFreeze": "yes", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore", "CleanResult": "success", "CollectMode": "inactive", "ConditionResult": "yes", "ConditionTimestamp": "Sat 2025-07-05 12:10:23 EDT", "ConditionTimestampMonotonic": "13516581", "ConfigurationDirectoryMode": "0755", "Conflicts": "shutdown.target", "ControlGroup": "/system.slice/docker.service", "ControlGroupId": "7651", "ControlPID": "0", "CoredumpFilter": "0x33", "CoredumpReceive": "no", "DefaultDependencies": "yes", "DefaultMemoryLow": "0", "DefaultMemoryMin": "0", "DefaultStartupMemoryLow": "0", "Delegate": "yes", "DelegateControllers": "cpu cpuset io memory pids", "Description": "Docker Application Container Engine", "DevicePolicy": "auto", "Documentation": "https://docs.docker.com", "DynamicUser": "no", "EffectiveCPUs": "0-31", "EffectiveMemoryNodes": "0", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "2018", "ExecMainStartTimestamp": "Sat 2025-07-05 12:10:23 EDT", "ExecMainStartTimestampMonotonic": "13518391", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecReloadEx": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/bin/dockerd ; argv[]=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStartEx": "{ path=/usr/bin/dockerd ; argv[]=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExitType": "main", "ExtensionImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FileDescriptorStorePreserve": "restart", "FinalKillSignal": "9", "FragmentPath": "/usr/lib/systemd/system/docker.service", "FreezerState": "running", "GID": "[not set]", "GuessMainPID": "yes", "IOAccounting": "no", "IOReadBytes": "[not set]", "IOReadOperations": "[not set]", "IOSchedulingClass": "2", "IOSchedulingPriority": "4", "IOWeight": "[not set]", "IOWriteBytes": "[not set]", "IOWriteOperations": "[not set]", "IPAccounting": "no", "IPEgressBytes": "[no data]", "IPEgressPackets": "[no data]", "IPIngressBytes": "[no data]", "IPIngressPackets": "[no data]", "Id": "docker.service", "IgnoreOnIsolate": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Sat 2025-07-05 12:10:23 EDT", "InactiveExitTimestampMonotonic": "13518558", "InvocationID": "efe8e95911d1408482a24e5be07cc2d7", "JobRunningTimeoutUSec": "infinity", "JobTimeoutAction": "none", "JobTimeoutUSec": "infinity", "KeyringMode": "private", "KillMode": "process", "KillSignal": "15", "LimitAS": "infinity", "LimitASSoft": "infinity", "LimitCORE": "infinity", "LimitCORESoft": "infinity", "LimitCPU": "infinity", "LimitCPUSoft": "infinity", "LimitDATA": "infinity", "LimitDATASoft": "infinity", "LimitFSIZE": "infinity", "LimitFSIZESoft": "infinity", "LimitLOCKS": "infinity", "LimitLOCKSSoft": "infinity", "LimitMEMLOCK": "8388608", "LimitMEMLOCKSoft": "8388608", "LimitMSGQUEUE": "819200", "LimitMSGQUEUESoft": "819200", "LimitNICE": "0", "LimitNICESoft": "0", "LimitNOFILE": "524288", "LimitNOFILESoft": "1024", "LimitNPROC": "infinity", "LimitNPROCSoft": "infinity", "LimitRSS": "infinity", "LimitRSSSoft": "infinity", "LimitRTPRIO": "0", "LimitRTPRIOSoft": "0", "LimitRTTIME": "infinity", "LimitRTTIMESoft": "infinity", "LimitSIGPENDING": "514099", "LimitSIGPENDINGSoft": "514099", "LimitSTACK": "infinity", "LimitSTACKSoft": "8388608", "LoadState": "loaded", "LockPersonality": "no", "LogLevelMax": "-1", "LogRateLimitBurst": "0", "LogRateLimitIntervalUSec": "0", "LogsDirectoryMode": "0755", "MainPID": "2018", "ManagedOOMMemoryPressure": "auto", "ManagedOOMMemoryPressureLimit": "0", "ManagedOOMPreference": "none", "ManagedOOMSwap": "auto", "MemoryAccounting": "yes", "MemoryAvailable": "126046736384", "MemoryCurrent": "2735316992", "MemoryDenyWriteExecute": "no", "MemoryHigh": "infinity", "MemoryKSM": "no", "MemoryLimit": "infinity", "MemoryLow": "0", "MemoryMax": "infinity", "MemoryMin": "0", "MemoryPeak": "3042648064", "MemoryPressureThresholdUSec": "200ms", "MemoryPressureWatch": "auto", "MemorySwapCurrent": "0", "MemorySwapMax": "infinity", "MemorySwapPeak": "0", "MemoryZSwapCurrent": "0", "MemoryZSwapMax": "infinity", "MountAPIVFS": "no", "MountImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "NFileDescriptorStore": "0", "NRestarts": "0", "NUMAPolicy": "n/a", "Names": "docker.service", "NeedDaemonReload": "yes", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMPolicy": "continue", "OOMScoreAdjust": "-500", "OnFailureJobMode": "replace", "OnSuccessJobMode": "fail", "Perpetual": "no", "PrivateDevices": "no", "PrivateIPC": "no", "PrivateMounts": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "PrivateUsers": "no", "ProcSubset": "all", "ProtectClock": "no", "ProtectControlGroups": "no", "ProtectHome": "no", "ProtectHostname": "no", "ProtectKernelLogs": "no", "ProtectKernelModules": "no", "ProtectKernelTunables": "no", "ProtectProc": "default", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "ReloadResult": "success", "ReloadSignal": "1", "RemainAfterExit": "no", "RemoveIPC": "no", "Requires": "sysinit.target docker.socket system.slice", "Restart": "always", "RestartKillSignal": "15", "RestartMaxDelayUSec": "infinity", "RestartMode": "normal", "RestartSteps": "0", "RestartUSec": "2s", "RestartUSecNext": "2s", "RestrictNamespaces": "no", "RestrictRealtime": "no", "RestrictSUIDSGID": "no", "Result": "success", "RootDirectoryStartOnly": "no", "RootEphemeral": "no", "RootImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "RuntimeDirectoryMode": "0755", "RuntimeDirectoryPreserve": "no", "RuntimeMaxUSec": "infinity", "RuntimeRandomizedExtraUSec": "0", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "SetLoginEnvironment": "no", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "3", "StartLimitIntervalUSec": "1min", "StartupBlockIOWeight": "[not set]", "StartupCPUShares": "[not set]", "StartupCPUWeight": "[not set]", "StartupIOWeight": "[not set]", "StartupMemoryHigh": "infinity", "StartupMemoryLow": "0", "StartupMemoryMax": "infinity", "StartupMemorySwapMax": "infinity", "StartupMemoryZSwapMax": "infinity", "StateChangeTimestamp": "Sat 2025-07-05 12:10:24 EDT", "StateChangeTimestampMonotonic": "14500501", "StateDirectoryMode": "0755", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SuccessAction": "none", "SurviveFinalKillSignal": "no", "SyslogFacility": "3", "SyslogLevel": "6", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "2147483646", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "yes", "TasksCurrent": "34", "TasksMax": "infinity", "TimeoutAbortUSec": "1min 30s", "TimeoutCleanUSec": "infinity", "TimeoutStartFailureMode": "terminate", "TimeoutStartUSec": "infinity", "TimeoutStopFailureMode": "terminate", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "TriggeredBy": "docker.socket", "Type": "notify", "UID": "[not set]", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "UtmpMode": "init", "WantedBy": "multi-user.target", "Wants": "containerd.service network-online.target", "WatchdogSignal": "6", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2025-07-07 09:33:48,506 p=86688 u=gpadmin n=ansible | TASK [docker : Wait for any in-progress snap operations to complete] **********************
2025-07-07 09:33:48,533 p=86688 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_service_status.rc != 0 and docker_check.stdout != \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:48,698 p=86688 u=gpadmin n=ansible | ok: [G-241] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.013680", "end": "2025-07-07 13:33:48.680625", "msg": "", "rc": 0, "start": "2025-07-07 13:33:48.666945", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:33:48,710 p=86688 u=gpadmin n=ansible | ok: [G-242] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.014289", "end": "2025-07-07 13:33:48.695857", "msg": "", "rc": 0, "start": "2025-07-07 13:33:48.681568", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:33:48,726 p=86688 u=gpadmin n=ansible | ok: [G-243] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.013947", "end": "2025-07-07 13:33:48.709936", "msg": "", "rc": 0, "start": "2025-07-07 13:33:48.695989", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:33:48,745 p=86688 u=gpadmin n=ansible | ok: [G-244] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.014116", "end": "2025-07-07 13:33:48.730609", "msg": "", "rc": 0, "start": "2025-07-07 13:33:48.716493", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:33:48,760 p=86688 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ***********************************************
2025-07-07 09:33:48,789 p=86688 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_service_status.rc != 0 and docker_check.stdout != \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:33:49,114 p=86688 u=gpadmin n=ansible | changed: [G-241] => {"attempts": 1, "changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:00.152368", "end": "2025-07-07 13:33:49.091400", "msg": "", "rc": 0, "start": "2025-07-07 13:33:48.939032", "stderr": "", "stderr_lines": [], "stdout": "Started.", "stdout_lines": ["Started."]}
2025-07-07 09:33:59,030 p=86688 u=gpadmin n=ansible |  [ERROR]: User interrupted execution

2025-07-07 09:34:16,651 p=87684 u=gpadmin n=ansible | Using /home/gpadmin/cursor-projects/02-Ray-Deploy/ansible.cfg as config file
2025-07-07 09:34:16,938 p=87684 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] ****************************************************
2025-07-07 09:34:16,946 p=87684 u=gpadmin n=ansible | TASK [Gathering Facts] **********************************************************************
2025-07-07 09:34:17,964 p=87684 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:34:18,021 p=87684 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:34:18,053 p=87684 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:34:18,092 p=87684 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:34:18,365 p=87684 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:34:18,448 p=87684 u=gpadmin n=ansible | TASK [common : Update apt cache] ************************************************************
2025-07-07 09:34:18,923 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"cache_update_time": 1751893770, "cache_updated": false, "changed": false}
2025-07-07 09:34:18,925 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"cache_update_time": 1751892994, "cache_updated": false, "changed": false}
2025-07-07 09:34:18,938 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"cache_update_time": 1751892994, "cache_updated": false, "changed": false}
2025-07-07 09:34:18,945 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"cache_update_time": 1751892995, "cache_updated": false, "changed": false}
2025-07-07 09:34:19,316 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"cache_update_time": 1751892911, "cache_updated": false, "changed": false}
2025-07-07 09:34:19,329 p=87684 u=gpadmin n=ansible | TASK [common : Install common packages] *****************************************************
2025-07-07 09:34:19,786 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"cache_update_time": 1751893770, "cache_updated": false, "changed": false}
2025-07-07 09:34:19,816 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"cache_update_time": 1751892994, "cache_updated": false, "changed": false}
2025-07-07 09:34:19,835 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"cache_update_time": 1751892994, "cache_updated": false, "changed": false}
2025-07-07 09:34:19,844 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"cache_update_time": 1751892995, "cache_updated": false, "changed": false}
2025-07-07 09:34:20,374 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"cache_update_time": 1751892911, "cache_updated": false, "changed": false}
2025-07-07 09:34:20,387 p=87684 u=gpadmin n=ansible | TASK [common : Create Ray temporary directory] **********************************************
2025-07-07 09:34:20,666 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:34:20,674 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:34:20,675 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:34:20,675 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:34:20,780 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:34:20,793 p=87684 u=gpadmin n=ansible | TASK [common : Check if Ray directory exists] ***********************************************
2025-07-07 09:34:21,074 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "stat": {"atime": 1751893510.3693118, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 8, "charset": "binary", "ctime": 1751894514.102447, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 16384017, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894514.102447, "nlink": 2, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "1435149338", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:34:21,076 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "stat": {"atime": 1751893510.3611715, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 8, "charset": "binary", "ctime": 1751894514.1356137, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 39059468, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894514.1356137, "nlink": 2, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "1105510836", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:34:21,080 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "stat": {"atime": 1751893510.357805, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 8, "charset": "binary", "ctime": 1751894514.1358685, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 9699340, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894514.1358685, "nlink": 2, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "3381391995", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:34:21,088 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "stat": {"atime": 1751893510.3523293, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 8, "charset": "binary", "ctime": 1751894514.1077826, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 118226955, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894514.1077826, "nlink": 2, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "2833573626", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:34:21,192 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "stat": {"atime": 1751894238.2056296, "attr_flags": "e", "attributes": ["extents"], "block_size": 4096, "blocks": 16, "charset": "binary", "ctime": 1751894498.643538, "dev": 64512, "device_type": 0, "executable": true, "exists": true, "gid": 1000, "gr_name": "gpadmin", "inode": 37618228, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0777", "mtime": 1751894498.643538, "nlink": 6, "path": "/home/gpadmin/ray_temp", "pw_name": "gpadmin", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 4096, "uid": 1000, "version": "3803985524", "wgrp": true, "woth": true, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2025-07-07 09:34:21,249 p=87684 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed (apt or snap)] **********************************
2025-07-07 09:34:21,519 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.001807", "end": "2025-07-07 13:34:21.508027", "msg": "", "rc": 0, "start": "2025-07-07 13:34:21.506220", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:34:21,521 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.001828", "end": "2025-07-07 13:34:21.508977", "msg": "", "rc": 0, "start": "2025-07-07 13:34:21.507149", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:34:21,528 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.001850", "end": "2025-07-07 13:34:21.517188", "msg": "", "rc": 0, "start": "2025-07-07 13:34:21.515338", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:34:21,529 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.001826", "end": "2025-07-07 13:34:21.513725", "msg": "", "rc": 0, "start": "2025-07-07 13:34:21.511899", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:34:21,632 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": "which docker || echo \"not_installed\"", "delta": "0:00:00.007764", "end": "2025-07-07 09:34:21.590292", "msg": "", "rc": 0, "start": "2025-07-07 09:34:21.582528", "stderr": "", "stderr_lines": [], "stdout": "/usr/local/bin/docker", "stdout_lines": ["/usr/local/bin/docker"]}
2025-07-07 09:34:21,646 p=87684 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] **********************************************************
2025-07-07 09:34:21,674 p=87684 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,692 p=87684 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,721 p=87684 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,722 p=87684 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,729 p=87684 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,738 p=87684 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] ***************************************************
2025-07-07 09:34:21,762 p=87684 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,777 p=87684 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,807 p=87684 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,809 p=87684 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,815 p=87684 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,824 p=87684 u=gpadmin n=ansible | TASK [docker : Install Docker Engine] *******************************************************
2025-07-07 09:34:21,843 p=87684 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,872 p=87684 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,887 p=87684 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,888 p=87684 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,901 p=87684 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:21,910 p=87684 u=gpadmin n=ansible | TASK [docker : Check Docker service status] *************************************************
2025-07-07 09:34:22,091 p=87684 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003038", "end": "2025-07-07 13:34:22.076001", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:34:22.072963", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:34:22,091 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:34:22,105 p=87684 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003236", "end": "2025-07-07 13:34:22.095728", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:34:22.092492", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:34:22,105 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:34:22,110 p=87684 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003973", "end": "2025-07-07 13:34:22.098368", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:34:22.094395", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:34:22,110 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:34:22,135 p=87684 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003086", "end": "2025-07-07 13:34:22.123910", "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:34:22.120824", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:34:22,136 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:34:22,202 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.011478", "end": "2025-07-07 09:34:22.159183", "msg": "", "rc": 0, "start": "2025-07-07 09:34:22.147705", "stderr": "", "stderr_lines": [], "stdout": "active", "stdout_lines": ["active"]}
2025-07-07 09:34:22,216 p=87684 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] **********************************************
2025-07-07 09:34:22,261 p=87684 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_service_status.rc == 0", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:22,290 p=87684 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_service_status.rc == 0", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:22,292 p=87684 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_service_status.rc == 0", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:22,303 p=87684 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_service_status.rc == 0", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:22,917 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "enabled": true, "name": "docker", "state": "started", "status": {"ActiveEnterTimestamp": "Sat 2025-07-05 12:10:24 EDT", "ActiveEnterTimestampMonotonic": "14500501", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "time-set.target network-online.target system.slice basic.target nss-lookup.target docker.socket firewalld.service systemd-journald.socket containerd.service sysinit.target", "AllowIsolate": "no", "AssertResult": "yes", "AssertTimestamp": "Sat 2025-07-05 12:10:23 EDT", "AssertTimestampMonotonic": "13516583", "Before": "shutdown.target multi-user.target", "BlockIOAccounting": "no", "BlockIOWeight": "[not set]", "CPUAccounting": "yes", "CPUAffinityFromNUMA": "no", "CPUQuotaPerSecUSec": "infinity", "CPUQuotaPeriodUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "[not set]", "CPUUsageNSec": "92404653000", "CPUWeight": "[not set]", "CacheDirectoryMode": "0755", "CanFreeze": "yes", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore", "CleanResult": "success", "CollectMode": "inactive", "ConditionResult": "yes", "ConditionTimestamp": "Sat 2025-07-05 12:10:23 EDT", "ConditionTimestampMonotonic": "13516581", "ConfigurationDirectoryMode": "0755", "Conflicts": "shutdown.target", "ControlGroup": "/system.slice/docker.service", "ControlGroupId": "7651", "ControlPID": "0", "CoredumpFilter": "0x33", "CoredumpReceive": "no", "DefaultDependencies": "yes", "DefaultMemoryLow": "0", "DefaultMemoryMin": "0", "DefaultStartupMemoryLow": "0", "Delegate": "yes", "DelegateControllers": "cpu cpuset io memory pids", "Description": "Docker Application Container Engine", "DevicePolicy": "auto", "Documentation": "https://docs.docker.com", "DynamicUser": "no", "EffectiveCPUs": "0-31", "EffectiveMemoryNodes": "0", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "2018", "ExecMainStartTimestamp": "Sat 2025-07-05 12:10:23 EDT", "ExecMainStartTimestampMonotonic": "13518391", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecReloadEx": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/bin/dockerd ; argv[]=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStartEx": "{ path=/usr/bin/dockerd ; argv[]=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExitType": "main", "ExtensionImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FileDescriptorStorePreserve": "restart", "FinalKillSignal": "9", "FragmentPath": "/usr/lib/systemd/system/docker.service", "FreezerState": "running", "GID": "[not set]", "GuessMainPID": "yes", "IOAccounting": "no", "IOReadBytes": "[not set]", "IOReadOperations": "[not set]", "IOSchedulingClass": "2", "IOSchedulingPriority": "4", "IOWeight": "[not set]", "IOWriteBytes": "[not set]", "IOWriteOperations": "[not set]", "IPAccounting": "no", "IPEgressBytes": "[no data]", "IPEgressPackets": "[no data]", "IPIngressBytes": "[no data]", "IPIngressPackets": "[no data]", "Id": "docker.service", "IgnoreOnIsolate": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Sat 2025-07-05 12:10:23 EDT", "InactiveExitTimestampMonotonic": "13518558", "InvocationID": "efe8e95911d1408482a24e5be07cc2d7", "JobRunningTimeoutUSec": "infinity", "JobTimeoutAction": "none", "JobTimeoutUSec": "infinity", "KeyringMode": "private", "KillMode": "process", "KillSignal": "15", "LimitAS": "infinity", "LimitASSoft": "infinity", "LimitCORE": "infinity", "LimitCORESoft": "infinity", "LimitCPU": "infinity", "LimitCPUSoft": "infinity", "LimitDATA": "infinity", "LimitDATASoft": "infinity", "LimitFSIZE": "infinity", "LimitFSIZESoft": "infinity", "LimitLOCKS": "infinity", "LimitLOCKSSoft": "infinity", "LimitMEMLOCK": "8388608", "LimitMEMLOCKSoft": "8388608", "LimitMSGQUEUE": "819200", "LimitMSGQUEUESoft": "819200", "LimitNICE": "0", "LimitNICESoft": "0", "LimitNOFILE": "524288", "LimitNOFILESoft": "1024", "LimitNPROC": "infinity", "LimitNPROCSoft": "infinity", "LimitRSS": "infinity", "LimitRSSSoft": "infinity", "LimitRTPRIO": "0", "LimitRTPRIOSoft": "0", "LimitRTTIME": "infinity", "LimitRTTIMESoft": "infinity", "LimitSIGPENDING": "514099", "LimitSIGPENDINGSoft": "514099", "LimitSTACK": "infinity", "LimitSTACKSoft": "8388608", "LoadState": "loaded", "LockPersonality": "no", "LogLevelMax": "-1", "LogRateLimitBurst": "0", "LogRateLimitIntervalUSec": "0", "LogsDirectoryMode": "0755", "MainPID": "2018", "ManagedOOMMemoryPressure": "auto", "ManagedOOMMemoryPressureLimit": "0", "ManagedOOMPreference": "none", "ManagedOOMSwap": "auto", "MemoryAccounting": "yes", "MemoryAvailable": "125988040704", "MemoryCurrent": "2734592000", "MemoryDenyWriteExecute": "no", "MemoryHigh": "infinity", "MemoryKSM": "no", "MemoryLimit": "infinity", "MemoryLow": "0", "MemoryMax": "infinity", "MemoryMin": "0", "MemoryPeak": "3042648064", "MemoryPressureThresholdUSec": "200ms", "MemoryPressureWatch": "auto", "MemorySwapCurrent": "0", "MemorySwapMax": "infinity", "MemorySwapPeak": "0", "MemoryZSwapCurrent": "0", "MemoryZSwapMax": "infinity", "MountAPIVFS": "no", "MountImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "NFileDescriptorStore": "0", "NRestarts": "0", "NUMAPolicy": "n/a", "Names": "docker.service", "NeedDaemonReload": "yes", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMPolicy": "continue", "OOMScoreAdjust": "-500", "OnFailureJobMode": "replace", "OnSuccessJobMode": "fail", "Perpetual": "no", "PrivateDevices": "no", "PrivateIPC": "no", "PrivateMounts": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "PrivateUsers": "no", "ProcSubset": "all", "ProtectClock": "no", "ProtectControlGroups": "no", "ProtectHome": "no", "ProtectHostname": "no", "ProtectKernelLogs": "no", "ProtectKernelModules": "no", "ProtectKernelTunables": "no", "ProtectProc": "default", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "ReloadResult": "success", "ReloadSignal": "1", "RemainAfterExit": "no", "RemoveIPC": "no", "Requires": "sysinit.target docker.socket system.slice", "Restart": "always", "RestartKillSignal": "15", "RestartMaxDelayUSec": "infinity", "RestartMode": "normal", "RestartSteps": "0", "RestartUSec": "2s", "RestartUSecNext": "2s", "RestrictNamespaces": "no", "RestrictRealtime": "no", "RestrictSUIDSGID": "no", "Result": "success", "RootDirectoryStartOnly": "no", "RootEphemeral": "no", "RootImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "RuntimeDirectoryMode": "0755", "RuntimeDirectoryPreserve": "no", "RuntimeMaxUSec": "infinity", "RuntimeRandomizedExtraUSec": "0", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "SetLoginEnvironment": "no", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "3", "StartLimitIntervalUSec": "1min", "StartupBlockIOWeight": "[not set]", "StartupCPUShares": "[not set]", "StartupCPUWeight": "[not set]", "StartupIOWeight": "[not set]", "StartupMemoryHigh": "infinity", "StartupMemoryLow": "0", "StartupMemoryMax": "infinity", "StartupMemorySwapMax": "infinity", "StartupMemoryZSwapMax": "infinity", "StateChangeTimestamp": "Sat 2025-07-05 12:10:24 EDT", "StateChangeTimestampMonotonic": "14500501", "StateDirectoryMode": "0755", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SuccessAction": "none", "SurviveFinalKillSignal": "no", "SyslogFacility": "3", "SyslogLevel": "6", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "2147483646", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "yes", "TasksCurrent": "34", "TasksMax": "infinity", "TimeoutAbortUSec": "1min 30s", "TimeoutCleanUSec": "infinity", "TimeoutStartFailureMode": "terminate", "TimeoutStartUSec": "infinity", "TimeoutStopFailureMode": "terminate", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "TriggeredBy": "docker.socket", "Type": "notify", "UID": "[not set]", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "UtmpMode": "init", "WantedBy": "multi-user.target", "Wants": "containerd.service network-online.target", "WatchdogSignal": "6", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2025-07-07 09:34:22,930 p=87684 u=gpadmin n=ansible | TASK [docker : Wait for any in-progress snap operations to complete] ************************
2025-07-07 09:34:22,957 p=87684 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_service_status.rc != 0 and docker_check.stdout != \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:23,131 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.013995", "end": "2025-07-07 13:34:23.111257", "msg": "", "rc": 0, "start": "2025-07-07 13:34:23.097262", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:34:23,160 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.014292", "end": "2025-07-07 13:34:23.145445", "msg": "", "rc": 0, "start": "2025-07-07 13:34:23.131153", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:34:23,173 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.013857", "end": "2025-07-07 13:34:23.156179", "msg": "", "rc": 0, "start": "2025-07-07 13:34:23.142322", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:34:23,191 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.014142", "end": "2025-07-07 13:34:23.175992", "msg": "", "rc": 0, "start": "2025-07-07 13:34:23.161850", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:34:23,206 p=87684 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] *************************************************
2025-07-07 09:34:23,235 p=87684 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_service_status.rc != 0 and docker_check.stdout != \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:23,583 p=87684 u=gpadmin n=ansible | changed: [G-241] => {"attempts": 1, "changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:00.155799", "end": "2025-07-07 13:34:23.556089", "msg": "", "rc": 0, "start": "2025-07-07 13:34:23.400290", "stderr": "", "stderr_lines": [], "stdout": "Started.", "stdout_lines": ["Started."]}
2025-07-07 09:34:56,615 p=87684 u=gpadmin n=ansible | changed: [G-243] => {"attempts": 1, "changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:33.174522", "end": "2025-07-07 13:34:56.595777", "msg": "", "rc": 0, "start": "2025-07-07 13:34:23.421255", "stderr": "", "stderr_lines": [], "stdout": "Started.", "stdout_lines": ["Started."]}
2025-07-07 09:34:56,619 p=87684 u=gpadmin n=ansible | changed: [G-242] => {"attempts": 1, "changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:33.190890", "end": "2025-07-07 13:34:56.581436", "msg": "", "rc": 0, "start": "2025-07-07 13:34:23.390546", "stderr": "", "stderr_lines": [], "stdout": "Started.", "stdout_lines": ["Started."]}
2025-07-07 09:34:56,635 p=87684 u=gpadmin n=ansible | changed: [G-244] => {"attempts": 1, "changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:33.184395", "end": "2025-07-07 13:34:56.615170", "msg": "", "rc": 0, "start": "2025-07-07 13:34:23.430775", "stderr": "", "stderr_lines": [], "stdout": "Started.", "stdout_lines": ["Started."]}
2025-07-07 09:34:56,649 p=87684 u=gpadmin n=ansible | TASK [docker : Add user to docker group] ****************************************************
2025-07-07 09:34:56,678 p=87684 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:56,695 p=87684 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:56,710 p=87684 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:56,725 p=87684 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:56,734 p=87684 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_check.stdout == \"not_installed\"", "skip_reason": "Conditional result was False"}
2025-07-07 09:34:56,744 p=87684 u=gpadmin n=ansible | TASK [docker : Pull Ray Docker image] *******************************************************
2025-07-07 09:34:57,707 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"actions": ["Pulled image rayproject/ray:2.9.0"], "attempts": 1, "changed": false, "image": {"Architecture": "amd64", "Author": "", "Comment": "buildkit.dockerfile.v0", "Config": {"AttachStderr": false, "AttachStdin": false, "AttachStdout": false, "Cmd": ["/bin/bash"], "Domainname": "", "Entrypoint": null, "Env": ["PATH=/home/ray/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "TZ=America/Los_Angeles", "LC_ALL=C.UTF-8", "LANG=C.UTF-8", "HOME=/home/ray"], "Hostname": "", "Image": "", "Labels": {"org.opencontainers.image.ref.name": "ubuntu", "org.opencontainers.image.version": "20.04"}, "OnBuild": null, "OpenStdin": false, "Shell": ["/bin/bash", "-c"], "StdinOnce": false, "Tty": false, "User": "1000", "Volumes": null, "WorkingDir": "/home/ray"}, "Created": "2023-12-18T23:18:11.720022433Z", "DockerVersion": "", "GraphDriver": {"Data": {"LowerDir": "/var/snap/docker/common/var-lib-docker/overlay2/a157404022c301bf1042d1e62800e03f8f4fe2b7be93c7c862c4e6eaae6df90d/diff:/var/snap/docker/common/var-lib-docker/overlay2/7c8ec995834d750508107df22fcd821c183169d30dc35bf7f25768aafcec562f/diff:/var/snap/docker/common/var-lib-docker/overlay2/cf10812da96d74f053a2e4968cfc6941e3d96eceba026c544287965b76b11e57/diff:/var/snap/docker/common/var-lib-docker/overlay2/f4dcfcf3dd1b2b040b7cb7b267f240f3686975fd8d6fac33709856daabb41b42/diff:/var/snap/docker/common/var-lib-docker/overlay2/7cf6f6e71e3a19a458ebc8cf88afa29c77dc9892a871de388cbfaf5964d96cbf/diff:/var/snap/docker/common/var-lib-docker/overlay2/1d577dbe5e25f3d389369f6e2e824ffcbb2a0107e0627d268ab88ca6390b5f86/diff:/var/snap/docker/common/var-lib-docker/overlay2/9d67b08f2f1954424e8abfb97648daa554b1b21bb6417ef6376bf124e3a12ad6/diff:/var/snap/docker/common/var-lib-docker/overlay2/0450e96ef997832d69ec77b754d4a5b215a634b6e6b5e35778800f2c825680ed/diff", "MergedDir": "/var/snap/docker/common/var-lib-docker/overlay2/e4664178e075ff8052b24dbedd1573538a1750df5588b99a0ea53180d91ddc58/merged", "UpperDir": "/var/snap/docker/common/var-lib-docker/overlay2/e4664178e075ff8052b24dbedd1573538a1750df5588b99a0ea53180d91ddc58/diff", "WorkDir": "/var/snap/docker/common/var-lib-docker/overlay2/e4664178e075ff8052b24dbedd1573538a1750df5588b99a0ea53180d91ddc58/work"}, "Name": "overlay2"}, "Id": "sha256:ee1c865e02572031f5c68be4184f21d929d5cd233289c83b2a10b9ce455eb75f", "Metadata": {"LastTagTime": "0001-01-01T00:00:00Z"}, "Os": "linux", "Parent": "", "RepoDigests": ["rayproject/ray@sha256:e64546fb5c3233bb0f33608e186e285c52cdd7440cae1af18f7fcde1c04e49f2"], "RepoTags": ["rayproject/ray:2.9.0"], "RootFS": {"Layers": ["sha256:3a03f09d212915b240e9d216069aba5652ed4765c7e4b098c65e71860d47b8e1", "sha256:db6680cb129d39fad6405b4fc83b612de4a228c95b437893af46d8b781ddd0f6", "sha256:81cb020e881ca3c7a87233ac403feea44f8964fbc18340a87a7f559591d90e94", "sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef", "sha256:180b33c2b848ae705b9f079c279f3b62207be4e6501dc80b2be118c7e140589c", "sha256:9e011b19e2eba55cf9b938fe9206e8c5af911843bc393ebf86f279514657df0e", "sha256:0575f54a9aec6019d39c0e95722f3a2062f95a28c3b1501918e0053c0696e7e8", "sha256:a7f9e2973cd370320020a1e5642e5665c2dff4da3384c3d0b5357ff48a25f84c", "sha256:4b4d53180b9fe6e2ae8a264f4a35d2b589415cf9cdff556f84e3b313ed4ec543"], "Type": "layers"}, "Size": 2195262629}}
2025-07-07 09:34:57,708 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"actions": ["Pulled image rayproject/ray:2.9.0"], "attempts": 1, "changed": false, "image": {"Architecture": "amd64", "Author": "", "Comment": "buildkit.dockerfile.v0", "Config": {"AttachStderr": false, "AttachStdin": false, "AttachStdout": false, "Cmd": ["/bin/bash"], "Domainname": "", "Entrypoint": null, "Env": ["PATH=/home/ray/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "TZ=America/Los_Angeles", "LC_ALL=C.UTF-8", "LANG=C.UTF-8", "HOME=/home/ray"], "Hostname": "", "Image": "", "Labels": {"org.opencontainers.image.ref.name": "ubuntu", "org.opencontainers.image.version": "20.04"}, "OnBuild": null, "OpenStdin": false, "Shell": ["/bin/bash", "-c"], "StdinOnce": false, "Tty": false, "User": "1000", "Volumes": null, "WorkingDir": "/home/ray"}, "Created": "2023-12-18T23:18:11.720022433Z", "DockerVersion": "", "GraphDriver": {"Data": {"LowerDir": "/var/snap/docker/common/var-lib-docker/overlay2/83ab8d49727201f55d28753df43040f5b5f80afbd50448e0f730a7cc9e6cef6b/diff:/var/snap/docker/common/var-lib-docker/overlay2/86a1ad8b41ca5c50cff5227ed2b93f763e32259dacc7c8c43abd9e8733955fa9/diff:/var/snap/docker/common/var-lib-docker/overlay2/18794a87c087bde4f81f0be07fae9a3e2bc1112dbc45fd5c59966a31ad6da92a/diff:/var/snap/docker/common/var-lib-docker/overlay2/179f19b0d34b4d66c6f06ee3fbd18cd5414c8422c55b0d21d858fd51bca0c69f/diff:/var/snap/docker/common/var-lib-docker/overlay2/95bb925deb61bfee37b6af42db4274c24f0ba7eed1221c9e448e04a657d1f8bd/diff:/var/snap/docker/common/var-lib-docker/overlay2/8123ea3e8528655b66c9223be3bb829d6e6628e06bfa7a89e1857af270a9cf91/diff:/var/snap/docker/common/var-lib-docker/overlay2/f04a8078e2b2fb1c54ae6dc183b41a650c38e9aa8a7b3dbb4b7938d4f887d9a6/diff:/var/snap/docker/common/var-lib-docker/overlay2/137872994a15cf7c56954519ad0c88a5e80bf50a84d08860ac49c96d08c6c246/diff", "MergedDir": "/var/snap/docker/common/var-lib-docker/overlay2/b7900a8360f36ee96300c7bcac26f9c13169a6dc4c3da86026bc4c6d9495037f/merged", "UpperDir": "/var/snap/docker/common/var-lib-docker/overlay2/b7900a8360f36ee96300c7bcac26f9c13169a6dc4c3da86026bc4c6d9495037f/diff", "WorkDir": "/var/snap/docker/common/var-lib-docker/overlay2/b7900a8360f36ee96300c7bcac26f9c13169a6dc4c3da86026bc4c6d9495037f/work"}, "Name": "overlay2"}, "Id": "sha256:ee1c865e02572031f5c68be4184f21d929d5cd233289c83b2a10b9ce455eb75f", "Metadata": {"LastTagTime": "0001-01-01T00:00:00Z"}, "Os": "linux", "Parent": "", "RepoDigests": ["rayproject/ray@sha256:e64546fb5c3233bb0f33608e186e285c52cdd7440cae1af18f7fcde1c04e49f2"], "RepoTags": ["rayproject/ray:2.9.0"], "RootFS": {"Layers": ["sha256:3a03f09d212915b240e9d216069aba5652ed4765c7e4b098c65e71860d47b8e1", "sha256:db6680cb129d39fad6405b4fc83b612de4a228c95b437893af46d8b781ddd0f6", "sha256:81cb020e881ca3c7a87233ac403feea44f8964fbc18340a87a7f559591d90e94", "sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef", "sha256:180b33c2b848ae705b9f079c279f3b62207be4e6501dc80b2be118c7e140589c", "sha256:9e011b19e2eba55cf9b938fe9206e8c5af911843bc393ebf86f279514657df0e", "sha256:0575f54a9aec6019d39c0e95722f3a2062f95a28c3b1501918e0053c0696e7e8", "sha256:a7f9e2973cd370320020a1e5642e5665c2dff4da3384c3d0b5357ff48a25f84c", "sha256:4b4d53180b9fe6e2ae8a264f4a35d2b589415cf9cdff556f84e3b313ed4ec543"], "Type": "layers"}, "Size": 2195262629}}
2025-07-07 09:34:57,723 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"actions": ["Pulled image rayproject/ray:2.9.0"], "attempts": 1, "changed": false, "image": {"Architecture": "amd64", "Author": "", "Comment": "buildkit.dockerfile.v0", "Config": {"AttachStderr": false, "AttachStdin": false, "AttachStdout": false, "Cmd": ["/bin/bash"], "Domainname": "", "Entrypoint": null, "Env": ["PATH=/home/ray/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "TZ=America/Los_Angeles", "LC_ALL=C.UTF-8", "LANG=C.UTF-8", "HOME=/home/ray"], "Hostname": "", "Image": "", "Labels": {"org.opencontainers.image.ref.name": "ubuntu", "org.opencontainers.image.version": "20.04"}, "OnBuild": null, "OpenStdin": false, "Shell": ["/bin/bash", "-c"], "StdinOnce": false, "Tty": false, "User": "1000", "Volumes": null, "WorkingDir": "/home/ray"}, "Created": "2023-12-18T23:18:11.720022433Z", "DockerVersion": "", "GraphDriver": {"Data": {"LowerDir": "/var/snap/docker/common/var-lib-docker/overlay2/51c6945fa243fe4afb8781ed4cf8a974ab741edff2463266ccde49d493ac59b2/diff:/var/snap/docker/common/var-lib-docker/overlay2/220ce155cfbbd587ddbbef284424840ad51450d90e447d267e0650cd1ebc3efd/diff:/var/snap/docker/common/var-lib-docker/overlay2/a23d5b0cc83f963124cccafedaf8ad7db7aab7f691000e575a82f5a4d97d3f95/diff:/var/snap/docker/common/var-lib-docker/overlay2/5e7b90cbce2921bb714b7e8c93d30100a7e48ba706ab2d9184e18bc5b66ed545/diff:/var/snap/docker/common/var-lib-docker/overlay2/0857cd0675c79aaabea4fea2de757915ab17fd3739aa7804b799cf009fa73e36/diff:/var/snap/docker/common/var-lib-docker/overlay2/0880726b515e9ca1dc75c25f956416ff11b885b5cbde9c93e30497f660d522f1/diff:/var/snap/docker/common/var-lib-docker/overlay2/70718f46cfee6a7dd2eb66971e726bdcc450be29f9c28cbe87c8c06da656087f/diff:/var/snap/docker/common/var-lib-docker/overlay2/f835350146ddd5cb9fbcd21726d0a862f10d1bc87ec9e9b21812e96b9e98bbf4/diff", "MergedDir": "/var/snap/docker/common/var-lib-docker/overlay2/ceabb4d43431ed05a1692b89bbe7360636907f35bd95a68d808c180698040d4d/merged", "UpperDir": "/var/snap/docker/common/var-lib-docker/overlay2/ceabb4d43431ed05a1692b89bbe7360636907f35bd95a68d808c180698040d4d/diff", "WorkDir": "/var/snap/docker/common/var-lib-docker/overlay2/ceabb4d43431ed05a1692b89bbe7360636907f35bd95a68d808c180698040d4d/work"}, "Name": "overlay2"}, "Id": "sha256:ee1c865e02572031f5c68be4184f21d929d5cd233289c83b2a10b9ce455eb75f", "Metadata": {"LastTagTime": "0001-01-01T00:00:00Z"}, "Os": "linux", "Parent": "", "RepoDigests": ["rayproject/ray@sha256:e64546fb5c3233bb0f33608e186e285c52cdd7440cae1af18f7fcde1c04e49f2"], "RepoTags": ["rayproject/ray:2.9.0"], "RootFS": {"Layers": ["sha256:3a03f09d212915b240e9d216069aba5652ed4765c7e4b098c65e71860d47b8e1", "sha256:db6680cb129d39fad6405b4fc83b612de4a228c95b437893af46d8b781ddd0f6", "sha256:81cb020e881ca3c7a87233ac403feea44f8964fbc18340a87a7f559591d90e94", "sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef", "sha256:180b33c2b848ae705b9f079c279f3b62207be4e6501dc80b2be118c7e140589c", "sha256:9e011b19e2eba55cf9b938fe9206e8c5af911843bc393ebf86f279514657df0e", "sha256:0575f54a9aec6019d39c0e95722f3a2062f95a28c3b1501918e0053c0696e7e8", "sha256:a7f9e2973cd370320020a1e5642e5665c2dff4da3384c3d0b5357ff48a25f84c", "sha256:4b4d53180b9fe6e2ae8a264f4a35d2b589415cf9cdff556f84e3b313ed4ec543"], "Type": "layers"}, "Size": 2195262629}}
2025-07-07 09:34:57,726 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"actions": ["Pulled image rayproject/ray:2.9.0"], "attempts": 1, "changed": false, "image": {"Architecture": "amd64", "Author": "", "Comment": "buildkit.dockerfile.v0", "Config": {"AttachStderr": false, "AttachStdin": false, "AttachStdout": false, "Cmd": ["/bin/bash"], "Domainname": "", "Entrypoint": null, "Env": ["PATH=/home/ray/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "TZ=America/Los_Angeles", "LC_ALL=C.UTF-8", "LANG=C.UTF-8", "HOME=/home/ray"], "Hostname": "", "Image": "", "Labels": {"org.opencontainers.image.ref.name": "ubuntu", "org.opencontainers.image.version": "20.04"}, "OnBuild": null, "OpenStdin": false, "Shell": ["/bin/bash", "-c"], "StdinOnce": false, "Tty": false, "User": "1000", "Volumes": null, "WorkingDir": "/home/ray"}, "Created": "2023-12-18T23:18:11.720022433Z", "DockerVersion": "", "GraphDriver": {"Data": {"LowerDir": "/var/snap/docker/common/var-lib-docker/overlay2/699fda5df898f39cfe340f8d3c343ad747654042e3c2c5f4a09379b739d1bbc9/diff:/var/snap/docker/common/var-lib-docker/overlay2/c9be3c70783e31b8c59f7bb2aeae4f16445682c22222015a35cda1dfe927ac55/diff:/var/snap/docker/common/var-lib-docker/overlay2/e417d88b93425d325d88e0dd601dd7aec1f28b1c41516cdbedea17d8a1a0d6f4/diff:/var/snap/docker/common/var-lib-docker/overlay2/ae90c1cfde15a414a7954d1c9af848d114bdf4a13c6b41c1a722dd7a42f111fd/diff:/var/snap/docker/common/var-lib-docker/overlay2/2ea9f814f6d17b6a78ecaf08ea7a835ae577fcf7a3d8b5939164608506c04162/diff:/var/snap/docker/common/var-lib-docker/overlay2/7d732d9d8fa84509cc83b26a4d58af7f69116250f77165dabd2ae448b0c8f389/diff:/var/snap/docker/common/var-lib-docker/overlay2/d3e6e93c55f1da69c78d66e8ad77c435231f9a135b05898f49a8df7ef41745ef/diff:/var/snap/docker/common/var-lib-docker/overlay2/468e81afa16128b04dcbd884af0a97776e3bf443f0371abc4ac46883dbf6e582/diff", "MergedDir": "/var/snap/docker/common/var-lib-docker/overlay2/c75df0f8f9d4156800e9120320a1dffb62f702dfcbca236400792a85903922d1/merged", "UpperDir": "/var/snap/docker/common/var-lib-docker/overlay2/c75df0f8f9d4156800e9120320a1dffb62f702dfcbca236400792a85903922d1/diff", "WorkDir": "/var/snap/docker/common/var-lib-docker/overlay2/c75df0f8f9d4156800e9120320a1dffb62f702dfcbca236400792a85903922d1/work"}, "Name": "overlay2"}, "Id": "sha256:ee1c865e02572031f5c68be4184f21d929d5cd233289c83b2a10b9ce455eb75f", "Metadata": {"LastTagTime": "0001-01-01T00:00:00Z"}, "Os": "linux", "Parent": "", "RepoDigests": ["rayproject/ray@sha256:e64546fb5c3233bb0f33608e186e285c52cdd7440cae1af18f7fcde1c04e49f2"], "RepoTags": ["rayproject/ray:2.9.0"], "RootFS": {"Layers": ["sha256:3a03f09d212915b240e9d216069aba5652ed4765c7e4b098c65e71860d47b8e1", "sha256:db6680cb129d39fad6405b4fc83b612de4a228c95b437893af46d8b781ddd0f6", "sha256:81cb020e881ca3c7a87233ac403feea44f8964fbc18340a87a7f559591d90e94", "sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef", "sha256:180b33c2b848ae705b9f079c279f3b62207be4e6501dc80b2be118c7e140589c", "sha256:9e011b19e2eba55cf9b938fe9206e8c5af911843bc393ebf86f279514657df0e", "sha256:0575f54a9aec6019d39c0e95722f3a2062f95a28c3b1501918e0053c0696e7e8", "sha256:a7f9e2973cd370320020a1e5642e5665c2dff4da3384c3d0b5357ff48a25f84c", "sha256:4b4d53180b9fe6e2ae8a264f4a35d2b589415cf9cdff556f84e3b313ed4ec543"], "Type": "layers"}, "Size": 2195262629}}
2025-07-07 09:34:57,887 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"actions": ["Pulled image rayproject/ray:2.9.0"], "attempts": 1, "changed": false, "image": {"Architecture": "amd64", "Author": "", "Comment": "buildkit.dockerfile.v0", "Config": {"Cmd": ["/bin/bash"], "Entrypoint": null, "Env": ["PATH=/home/ray/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "TZ=America/Los_Angeles", "LC_ALL=C.UTF-8", "LANG=C.UTF-8", "HOME=/home/ray"], "Labels": {"org.opencontainers.image.ref.name": "ubuntu", "org.opencontainers.image.version": "20.04"}, "OnBuild": null, "Shell": ["/bin/bash", "-c"], "User": "1000", "Volumes": null, "WorkingDir": "/home/ray"}, "Created": "2023-12-18T23:18:11.720022433Z", "DockerVersion": "", "GraphDriver": {"Data": {"LowerDir": "/var/lib/docker/overlay2/a7becb9ad73d236f3565797490417714dc391e6a543d1aeb6b4ca590de5aef83/diff:/var/lib/docker/overlay2/d6a40d2a2c0db8d0c92d82b8fda785bc5aed81d5dc73b3f2d7f3523d75f739b0/diff:/var/lib/docker/overlay2/3a90ebe7fb3b368e5be5144f83c481b230cdc4d5800793b334c1c1ecfc573638/diff:/var/lib/docker/overlay2/db17ccc5d8837ae58713b0bd273ab553abb70282291546b3bb5be42407dba64d/diff:/var/lib/docker/overlay2/917181e62e89e11f30e3acf992ab3c198b3656d2c9611f3437cc06ca35465e6b/diff:/var/lib/docker/overlay2/29016ef182caedb3568d015438765d46019a237c9f9c0c2e6c5500269d21709b/diff:/var/lib/docker/overlay2/6857c9a1337136341dfcd03fcc575d961b3616f689a9d455e3e4c8bd9b16ce80/diff:/var/lib/docker/overlay2/e3f017fd1cc3ec9e215f54f3ee32a27733eaee1bf47db1976a38cdf028ce7b80/diff", "MergedDir": "/var/lib/docker/overlay2/607d795adcbbebc6c403d28809e091210e7df04a3116d08e08ffd4311eb32026/merged", "UpperDir": "/var/lib/docker/overlay2/607d795adcbbebc6c403d28809e091210e7df04a3116d08e08ffd4311eb32026/diff", "WorkDir": "/var/lib/docker/overlay2/607d795adcbbebc6c403d28809e091210e7df04a3116d08e08ffd4311eb32026/work"}, "Name": "overlay2"}, "Id": "sha256:ee1c865e02572031f5c68be4184f21d929d5cd233289c83b2a10b9ce455eb75f", "Metadata": {"LastTagTime": "0001-01-01T00:00:00Z"}, "Os": "linux", "Parent": "", "RepoDigests": ["rayproject/ray@sha256:e64546fb5c3233bb0f33608e186e285c52cdd7440cae1af18f7fcde1c04e49f2"], "RepoTags": ["rayproject/ray:2.9.0"], "RootFS": {"Layers": ["sha256:3a03f09d212915b240e9d216069aba5652ed4765c7e4b098c65e71860d47b8e1", "sha256:db6680cb129d39fad6405b4fc83b612de4a228c95b437893af46d8b781ddd0f6", "sha256:81cb020e881ca3c7a87233ac403feea44f8964fbc18340a87a7f559591d90e94", "sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef", "sha256:180b33c2b848ae705b9f079c279f3b62207be4e6501dc80b2be118c7e140589c", "sha256:9e011b19e2eba55cf9b938fe9206e8c5af911843bc393ebf86f279514657df0e", "sha256:0575f54a9aec6019d39c0e95722f3a2062f95a28c3b1501918e0053c0696e7e8", "sha256:a7f9e2973cd370320020a1e5642e5665c2dff4da3384c3d0b5357ff48a25f84c", "sha256:4b4d53180b9fe6e2ae8a264f4a35d2b589415cf9cdff556f84e3b313ed4ec543"], "Type": "layers"}, "Size": 2195262629}}
2025-07-07 09:34:58,035 p=87684 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] **************************************************************
2025-07-07 09:34:58,045 p=87684 u=gpadmin n=ansible | TASK [Gathering Facts] **********************************************************************
2025-07-07 09:34:59,239 p=87684 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:34:59,274 p=87684 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] ************************
2025-07-07 09:34:59,574 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:34:59,588 p=87684 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] *****************
2025-07-07 09:35:00,357 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true}
2025-07-07 09:35:00,371 p=87684 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] ****************************
2025-07-07 09:35:00,666 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "path": "/usr/local/bin/start_ray_head.sh", "state": "absent"}
2025-07-07 09:35:00,680 p=87684 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] ***********************************
2025-07-07 09:35:01,328 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "checksum": "1b4c6c0e6819c87d86b4155afaa9bf1da31b80a3", "dest": "/usr/local/bin/start_ray_head.sh", "gid": 1000, "group": "gpadmin", "md5sum": "7e29ed567f4095bd1b9c4f0419e3a117", "mode": "0755", "owner": "gpadmin", "size": 1235, "src": "/home/gpadmin/.ansible/tmp/ansible-tmp-1751895300.714191-89025-10361752789290/source", "state": "file", "uid": 1000}
2025-07-07 09:35:01,343 p=87684 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] **************************************************
2025-07-07 09:35:01,884 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "cmd": ["/usr/local/bin/start_ray_head.sh"], "delta": "0:00:00.253993", "end": "2025-07-07 09:35:01.839324", "msg": "", "rc": 0, "start": "2025-07-07 09:35:01.585331", "stderr": "", "stderr_lines": [], "stdout": "a30361101b647a4844df2d1a43a87a38488c27b91102898bd4ed0d3a3a4ce25c\nRay head node started on G-K3S-Master with container name ray_head", "stdout_lines": ["a30361101b647a4844df2d1a43a87a38488c27b91102898bd4ed0d3a3a4ce25c", "Ray head node started on G-K3S-Master with container name ray_head"]}
2025-07-07 09:35:01,899 p=87684 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] *****************************************
2025-07-07 09:35:02,233 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": ["docker", "ps", "-f", "name=ray_head"], "delta": "0:00:00.030974", "end": "2025-07-07 09:35:02.186672", "msg": "", "rc": 0, "start": "2025-07-07 09:35:02.155698", "stderr": "", "stderr_lines": [], "stdout": "CONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS                  PORTS     NAMES\na30361101b64   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   1 second ago   Up Less than a second             ray_head", "stdout_lines": ["CONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS                  PORTS     NAMES", "a30361101b64   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   1 second ago   Up Less than a second             ray_head"]}
2025-07-07 09:35:02,248 p=87684 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] *******************************************
2025-07-07 09:35:02,273 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS                  PORTS     NAMES\na30361101b64   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   1 second ago   Up Less than a second             ray_head"
}
2025-07-07 09:35:02,291 p=87684 u=gpadmin n=ansible | TASK [ray_head : Wait for a moment to let Ray head node initialize] *************************
2025-07-07 09:35:02,311 p=87684 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:35:02,311 p=87684 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:35:12,316 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "delta": 10, "echo": true, "rc": 0, "start": "2025-07-07 09:35:02.310383", "stderr": "", "stdout": "Paused for 10.0 seconds", "stop": "2025-07-07 09:35:12.313752", "user_input": ""}
2025-07-07 09:35:12,332 p=87684 u=gpadmin n=ansible | TASK [ray_head : Check Ray head node status] ************************************************
2025-07-07 09:35:14,426 p=87684 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_head", "ray", "status"], "delta": "0:00:01.811723", "end": "2025-07-07 09:35:14.388145", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:35:12.576422", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:35:14,427 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:14,442 p=87684 u=gpadmin n=ansible | TASK [ray_head : Print Ray head node status] ************************************************
2025-07-07 09:35:14,486 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": []
}
2025-07-07 09:35:14,545 p=87684 u=gpadmin n=ansible | PLAY [Configure Ray Worker Nodes] ***********************************************************
2025-07-07 09:35:14,554 p=87684 u=gpadmin n=ansible | TASK [Gathering Facts] **********************************************************************
2025-07-07 09:35:15,324 p=87684 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:35:15,399 p=87684 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:35:15,426 p=87684 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:35:15,445 p=87684 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:35:15,511 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Ensure Ray temporary directory exists on worker node] ********************
2025-07-07 09:35:15,680 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:15,693 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:15,709 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:15,735 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "gid": 1000, "group": "gpadmin", "mode": "0777", "owner": "gpadmin", "path": "/home/gpadmin/ray_temp", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:15,748 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Stop and remove existing Ray worker container (idempotency)] *************
2025-07-07 09:35:16,134 p=87684 u=gpadmin n=ansible | changed: [G-241] => {"changed": true}
2025-07-07 09:35:16,151 p=87684 u=gpadmin n=ansible | changed: [G-243] => {"changed": true}
2025-07-07 09:35:16,170 p=87684 u=gpadmin n=ansible | changed: [G-242] => {"changed": true}
2025-07-07 09:35:16,206 p=87684 u=gpadmin n=ansible | changed: [G-244] => {"changed": true}
2025-07-07 09:35:16,220 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Remove old Ray worker start script (idempotency)] ************************
2025-07-07 09:35:16,378 p=87684 u=gpadmin n=ansible | changed: [G-241] => {"changed": true, "path": "/usr/local/bin/start_ray_worker.sh", "state": "absent"}
2025-07-07 09:35:16,404 p=87684 u=gpadmin n=ansible | changed: [G-242] => {"changed": true, "path": "/usr/local/bin/start_ray_worker.sh", "state": "absent"}
2025-07-07 09:35:16,420 p=87684 u=gpadmin n=ansible | changed: [G-243] => {"changed": true, "path": "/usr/local/bin/start_ray_worker.sh", "state": "absent"}
2025-07-07 09:35:16,446 p=87684 u=gpadmin n=ansible | changed: [G-244] => {"changed": true, "path": "/usr/local/bin/start_ray_worker.sh", "state": "absent"}
2025-07-07 09:35:16,459 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Copy Ray worker start script to worker node] *****************************
2025-07-07 09:35:16,924 p=87684 u=gpadmin n=ansible | changed: [G-242] => {"changed": true, "checksum": "92f939e5cfb91a9ce79a140e19f545977825c01d", "dest": "/usr/local/bin/start_ray_worker.sh", "gid": 1000, "group": "gpadmin", "md5sum": "d6ef0746d839e2dd5a82213555cc02b1", "mode": "0755", "owner": "gpadmin", "size": 1142, "src": "/home/gpadmin/.ansible/tmp/ansible-tmp-1751895316.5302498-89611-120317198854815/source", "state": "file", "uid": 1000}
2025-07-07 09:35:16,926 p=87684 u=gpadmin n=ansible | changed: [G-241] => {"changed": true, "checksum": "92f939e5cfb91a9ce79a140e19f545977825c01d", "dest": "/usr/local/bin/start_ray_worker.sh", "gid": 1000, "group": "gpadmin", "md5sum": "d6ef0746d839e2dd5a82213555cc02b1", "mode": "0755", "owner": "gpadmin", "size": 1142, "src": "/home/gpadmin/.ansible/tmp/ansible-tmp-1751895316.5140283-89609-170921904934792/source", "state": "file", "uid": 1000}
2025-07-07 09:35:16,959 p=87684 u=gpadmin n=ansible | changed: [G-243] => {"changed": true, "checksum": "92f939e5cfb91a9ce79a140e19f545977825c01d", "dest": "/usr/local/bin/start_ray_worker.sh", "gid": 1000, "group": "gpadmin", "md5sum": "d6ef0746d839e2dd5a82213555cc02b1", "mode": "0755", "owner": "gpadmin", "size": 1142, "src": "/home/gpadmin/.ansible/tmp/ansible-tmp-1751895316.5445998-89614-18444695550531/source", "state": "file", "uid": 1000}
2025-07-07 09:35:16,996 p=87684 u=gpadmin n=ansible | changed: [G-244] => {"changed": true, "checksum": "92f939e5cfb91a9ce79a140e19f545977825c01d", "dest": "/usr/local/bin/start_ray_worker.sh", "gid": 1000, "group": "gpadmin", "md5sum": "d6ef0746d839e2dd5a82213555cc02b1", "mode": "0755", "owner": "gpadmin", "size": 1142, "src": "/home/gpadmin/.ansible/tmp/ansible-tmp-1751895316.5635855-89620-150838151048334/source", "state": "file", "uid": 1000}
2025-07-07 09:35:17,009 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Start Ray worker container] **********************************************
2025-07-07 09:35:17,536 p=87684 u=gpadmin n=ansible | changed: [G-242] => {"changed": true, "cmd": ["/usr/local/bin/start_ray_worker.sh"], "delta": "0:00:00.336939", "end": "2025-07-07 13:35:17.522249", "msg": "", "rc": 0, "start": "2025-07-07 13:35:17.185310", "stderr": "", "stderr_lines": [], "stdout": "7fbaa9e64aadb24607a4f8224a8bedbfb5aff1e32f6c98b28a91177565464392\nRay worker node started on g-242 with container name ray_worker", "stdout_lines": ["7fbaa9e64aadb24607a4f8224a8bedbfb5aff1e32f6c98b28a91177565464392", "Ray worker node started on g-242 with container name ray_worker"]}
2025-07-07 09:35:17,538 p=87684 u=gpadmin n=ansible | changed: [G-241] => {"changed": true, "cmd": ["/usr/local/bin/start_ray_worker.sh"], "delta": "0:00:00.348471", "end": "2025-07-07 13:35:17.521956", "msg": "", "rc": 0, "start": "2025-07-07 13:35:17.173485", "stderr": "", "stderr_lines": [], "stdout": "ae21478cc53a1a6958f6260a9fe3bc5f0eff99a14e6e15d42201696da3a9e7dc\nRay worker node started on g-241 with container name ray_worker", "stdout_lines": ["ae21478cc53a1a6958f6260a9fe3bc5f0eff99a14e6e15d42201696da3a9e7dc", "Ray worker node started on g-241 with container name ray_worker"]}
2025-07-07 09:35:17,551 p=87684 u=gpadmin n=ansible | changed: [G-243] => {"changed": true, "cmd": ["/usr/local/bin/start_ray_worker.sh"], "delta": "0:00:00.336156", "end": "2025-07-07 13:35:17.541016", "msg": "", "rc": 0, "start": "2025-07-07 13:35:17.204860", "stderr": "", "stderr_lines": [], "stdout": "28d337ef57bdd2fda6c8b2ae80c42bcbae4915333511a2fd3bb336c0c3406bd6\nRay worker node started on g-243 with container name ray_worker", "stdout_lines": ["28d337ef57bdd2fda6c8b2ae80c42bcbae4915333511a2fd3bb336c0c3406bd6", "Ray worker node started on g-243 with container name ray_worker"]}
2025-07-07 09:35:17,601 p=87684 u=gpadmin n=ansible | changed: [G-244] => {"changed": true, "cmd": ["/usr/local/bin/start_ray_worker.sh"], "delta": "0:00:00.364115", "end": "2025-07-07 13:35:17.587382", "msg": "", "rc": 0, "start": "2025-07-07 13:35:17.223267", "stderr": "", "stderr_lines": [], "stdout": "56ce0f34b799c145f6d7cbea6f63e7201fccaf91624b5cff3bf9f368ff52b913\nRay worker node started on g-244 with container name ray_worker", "stdout_lines": ["56ce0f34b799c145f6d7cbea6f63e7201fccaf91624b5cff3bf9f368ff52b913", "Ray worker node started on g-244 with container name ray_worker"]}
2025-07-07 09:35:17,614 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Display Ray worker container status] *************************************
2025-07-07 09:35:17,799 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "cmd": ["docker", "ps", "-f", "name=ray_worker"], "delta": "0:00:00.036138", "end": "2025-07-07 13:35:17.782658", "msg": "", "rc": 0, "start": "2025-07-07 13:35:17.746520", "stderr": "", "stderr_lines": [], "stdout": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\nae21478cc53a   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker", "stdout_lines": ["CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES", "ae21478cc53a   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"]}
2025-07-07 09:35:17,823 p=87684 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "cmd": ["docker", "ps", "-f", "name=ray_worker"], "delta": "0:00:00.040622", "end": "2025-07-07 13:35:17.810808", "msg": "", "rc": 0, "start": "2025-07-07 13:35:17.770186", "stderr": "", "stderr_lines": [], "stdout": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n7fbaa9e64aad   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker", "stdout_lines": ["CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES", "7fbaa9e64aad   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"]}
2025-07-07 09:35:17,826 p=87684 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "cmd": ["docker", "ps", "-f", "name=ray_worker"], "delta": "0:00:00.035327", "end": "2025-07-07 13:35:17.815381", "msg": "", "rc": 0, "start": "2025-07-07 13:35:17.780054", "stderr": "", "stderr_lines": [], "stdout": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n28d337ef57bd   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker", "stdout_lines": ["CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES", "28d337ef57bd   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"]}
2025-07-07 09:35:17,854 p=87684 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "cmd": ["docker", "ps", "-f", "name=ray_worker"], "delta": "0:00:00.046146", "end": "2025-07-07 13:35:17.841359", "msg": "", "rc": 0, "start": "2025-07-07 13:35:17.795213", "stderr": "", "stderr_lines": [], "stdout": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n56ce0f34b799   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker", "stdout_lines": ["CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES", "56ce0f34b799   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"]}
2025-07-07 09:35:17,867 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Print Ray worker container status] ***************************************
2025-07-07 09:35:17,898 p=87684 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\nae21478cc53a   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:35:17,938 p=87684 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n7fbaa9e64aad   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:35:17,940 p=87684 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n28d337ef57bd   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:35:17,950 p=87684 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n56ce0f34b799   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:35:17,959 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Wait for a moment to let Ray worker node initialize] *********************
2025-07-07 09:35:17,974 p=87684 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:35:17,975 p=87684 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:35:27,980 p=87684 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "delta": 10, "echo": true, "rc": 0, "start": "2025-07-07 09:35:17.973855", "stderr": "", "stdout": "Paused for 10.0 seconds", "stop": "2025-07-07 09:35:27.977154", "user_input": ""}
2025-07-07 09:35:27,992 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Check Ray worker node status] ********************************************
2025-07-07 09:35:29,039 p=87684 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.881248", "end": "2025-07-07 13:35:29.022815", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:35:28.141567", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:35:29,039 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:29,062 p=87684 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.874895", "end": "2025-07-07 13:35:29.051077", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:35:28.176182", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:35:29,062 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:29,101 p=87684 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.920107", "end": "2025-07-07 13:35:29.088720", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:35:28.168613", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:35:29,101 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:29,124 p=87684 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_worker", "ray", "status"], "delta": "0:00:00.901185", "end": "2025-07-07 13:35:29.110648", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:35:28.209463", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:35:29,124 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:29,137 p=87684 u=gpadmin n=ansible | TASK [ray_worker : Print Ray worker node status] ********************************************
2025-07-07 09:35:29,198 p=87684 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": []
}
2025-07-07 09:35:29,201 p=87684 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": []
}
2025-07-07 09:35:29,222 p=87684 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": []
}
2025-07-07 09:35:29,238 p=87684 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": []
}
2025-07-07 09:35:29,397 p=87684 u=gpadmin n=ansible | PLAY [Verify Ray Cluster Deployment] ********************************************************
2025-07-07 09:35:29,418 p=87684 u=gpadmin n=ansible | TASK [Check Ray head node status] ***********************************************************
2025-07-07 09:35:31,457 p=87684 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "cmd": ["docker", "exec", "ray_head", "ray", "status"], "delta": "0:00:01.753728", "end": "2025-07-07 09:35:31.408412", "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:35:29.654684", "stderr": "Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.", "stderr_lines": ["Traceback (most recent call last):", "  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>", "    sys.exit(main())", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main", "    return cli()", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__", "    return self.main(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main", "    rv = self.invoke(ctx)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke", "    return _process_result(sub_ctx.command.invoke(sub_ctx))", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke", "    return ctx.invoke(self.callback, **ctx.params)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke", "    return __callback(*args, **kwargs)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status", "    address = services.canonicalize_bootstrap_address_or_die(address)", "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die", "    raise ConnectionError(", "ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."], "stdout": "", "stdout_lines": []}
2025-07-07 09:35:31,458 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:31,471 p=87684 u=gpadmin n=ansible | TASK [Display Ray cluster status] ***********************************************************
2025-07-07 09:35:31,492 p=87684 u=gpadmin n=ansible | skipping: [MASTER] => {"false_condition": "ray_status.rc == 0"}
2025-07-07 09:35:31,506 p=87684 u=gpadmin n=ansible | TASK [Display Ray cluster error] ************************************************************
2025-07-07 09:35:31,528 p=87684 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "Ray cluster status check failed: Traceback (most recent call last):\n  File \"/home/ray/anaconda3/bin/ray\", line 8, in <module>\n    sys.exit(main())\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2498, in main\n    return cli()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 1973, in status\n    address = services.canonicalize_bootstrap_address_or_die(address)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py\", line 566, in canonicalize_bootstrap_address_or_die\n    raise ConnectionError(\nConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable."
}
2025-07-07 09:35:31,572 p=87684 u=gpadmin n=ansible | PLAY [Deploy Monitoring Stack] **************************************************************
2025-07-07 09:35:31,583 p=87684 u=gpadmin n=ansible | TASK [Gathering Facts] **********************************************************************
2025-07-07 09:35:32,411 p=87684 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:35:32,415 p=87684 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:35:32,417 p=87684 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:35:32,460 p=87684 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:35:32,820 p=87684 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:35:32,896 p=87684 u=gpadmin n=ansible | TASK [monitoring : Create Prometheus data directory] ****************************************
2025-07-07 09:35:33,093 p=87684 u=gpadmin n=ansible | changed: [G-241] => {"changed": true, "gid": 1000, "group": "gpadmin", "mode": "0755", "owner": "gpadmin", "path": "/home/gpadmin/prometheus_data", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:33,102 p=87684 u=gpadmin n=ansible | changed: [G-242] => {"changed": true, "gid": 1000, "group": "gpadmin", "mode": "0755", "owner": "gpadmin", "path": "/home/gpadmin/prometheus_data", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:33,124 p=87684 u=gpadmin n=ansible | changed: [G-244] => {"changed": true, "gid": 1000, "group": "gpadmin", "mode": "0755", "owner": "gpadmin", "path": "/home/gpadmin/prometheus_data", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:33,124 p=87684 u=gpadmin n=ansible | changed: [G-243] => {"changed": true, "gid": 1000, "group": "gpadmin", "mode": "0755", "owner": "gpadmin", "path": "/home/gpadmin/prometheus_data", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:33,221 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "gid": 1000, "group": "gpadmin", "mode": "0755", "owner": "gpadmin", "path": "/home/gpadmin/prometheus_data", "size": 4096, "state": "directory", "uid": 1000}
2025-07-07 09:35:33,236 p=87684 u=gpadmin n=ansible | TASK [monitoring : Create Grafana data directory] *******************************************
2025-07-07 09:35:33,422 p=87684 u=gpadmin n=ansible | changed: [G-241] => {"changed": true, "gid": 472, "group": "472", "mode": "0755", "owner": "472", "path": "/home/gpadmin/grafana_data", "size": 4096, "state": "directory", "uid": 472}
2025-07-07 09:35:33,444 p=87684 u=gpadmin n=ansible | changed: [G-242] => {"changed": true, "gid": 472, "group": "472", "mode": "0755", "owner": "472", "path": "/home/gpadmin/grafana_data", "size": 4096, "state": "directory", "uid": 472}
2025-07-07 09:35:33,464 p=87684 u=gpadmin n=ansible | changed: [G-243] => {"changed": true, "gid": 472, "group": "472", "mode": "0755", "owner": "472", "path": "/home/gpadmin/grafana_data", "size": 4096, "state": "directory", "uid": 472}
2025-07-07 09:35:33,483 p=87684 u=gpadmin n=ansible | changed: [G-244] => {"changed": true, "gid": 472, "group": "472", "mode": "0755", "owner": "472", "path": "/home/gpadmin/grafana_data", "size": 4096, "state": "directory", "uid": 472}
2025-07-07 09:35:33,552 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "gid": 472, "group": "472", "mode": "0755", "owner": "472", "path": "/home/gpadmin/grafana_data", "size": 4096, "state": "directory", "uid": 472}
2025-07-07 09:35:33,566 p=87684 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Node Exporter container (idempotency)] **********
2025-07-07 09:35:33,856 p=87684 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:33,857 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:33,859 p=87684 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:33,859 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:33,868 p=87684 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:33,868 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:33,893 p=87684 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:33,893 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:34,070 p=87684 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:34,070 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:34,083 p=87684 u=gpadmin n=ansible | TASK [monitoring : Start Node Exporter container] *******************************************
2025-07-07 09:35:36,766 p=87684 u=gpadmin n=ansible | changed: [G-243] => {"changed": true, "container": {"AppArmorProfile": "docker-default", "Args": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Config": {"AttachStderr": true, "AttachStdin": false, "AttachStdout": true, "Cmd": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Domainname": "", "Entrypoint": ["/bin/node_exporter"], "Env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"], "ExposedPorts": {"9100/tcp": {}}, "Hostname": "g-243", "Image": "prom/node-exporter:v1.6.1", "Labels": {"maintainer": "The Prometheus Authors <prometheus-developers@googlegroups.com>"}, "OnBuild": null, "OpenStdin": false, "StdinOnce": false, "Tty": false, "User": "nobody", "Volumes": null, "WorkingDir": ""}, "Created": "2025-07-07T13:35:36.509308639Z", "Driver": "overlay2", "ExecIDs": null, "GraphDriver": {"Data": {"ID": "35590ea5ea6807263ad85053af5a180851692fdcec724b6a0a5cd131ead4976c", "LowerDir": "/var/snap/docker/common/var-lib-docker/overlay2/f9199a3874982070c75cae3fd5eb3f41d79efc8502b6c0fdef1d3a4fbc5f2d59-init/diff:/var/snap/docker/common/var-lib-docker/overlay2/dc66be33e737d27c3da253d552258f0c3a773c6905a61a7636d3736ba819f63b/diff:/var/snap/docker/common/var-lib-docker/overlay2/01c024c4f0e2c9d9172440726741617ee148bd0991459b285320d4c785cb9da2/diff:/var/snap/docker/common/var-lib-docker/overlay2/537976c2b43430401afd5671dba15a3e9140831bb1f56d8bab6d211303a1f6f2/diff", "MergedDir": "/var/snap/docker/common/var-lib-docker/overlay2/f9199a3874982070c75cae3fd5eb3f41d79efc8502b6c0fdef1d3a4fbc5f2d59/merged", "UpperDir": "/var/snap/docker/common/var-lib-docker/overlay2/f9199a3874982070c75cae3fd5eb3f41d79efc8502b6c0fdef1d3a4fbc5f2d59/diff", "WorkDir": "/var/snap/docker/common/var-lib-docker/overlay2/f9199a3874982070c75cae3fd5eb3f41d79efc8502b6c0fdef1d3a4fbc5f2d59/work"}, "Name": "overlay2"}, "HostConfig": {"AutoRemove": false, "Binds": ["/proc:/host/proc:ro", "/sys:/host/sys:ro", "/:/rootfs:ro"], "BlkioDeviceReadBps": null, "BlkioDeviceReadIOps": null, "BlkioDeviceWriteBps": null, "BlkioDeviceWriteIOps": null, "BlkioWeight": 0, "BlkioWeightDevice": null, "CapAdd": null, "CapDrop": null, "Cgroup": "", "CgroupParent": "", "CgroupnsMode": "private", "ConsoleSize": [0, 0], "ContainerIDFile": "", "CpuCount": 0, "CpuPercent": 0, "CpuPeriod": 0, "CpuQuota": 0, "CpuRealtimePeriod": 0, "CpuRealtimeRuntime": 0, "CpuShares": 0, "CpusetCpus": "", "CpusetMems": "", "DeviceCgroupRules": null, "DeviceRequests": null, "Devices": null, "Dns": null, "DnsOptions": null, "DnsSearch": null, "ExtraHosts": null, "GroupAdd": null, "IOMaximumBandwidth": 0, "IOMaximumIOps": 0, "IpcMode": "private", "Isolation": "", "Links": null, "LogConfig": {"Config": {}, "Type": "json-file"}, "MaskedPaths": ["/proc/asound", "/proc/acpi", "/proc/interrupts", "/proc/kcore", "/proc/keys", "/proc/latency_stats", "/proc/timer_list", "/proc/timer_stats", "/proc/sched_debug", "/proc/scsi", "/sys/firmware", "/sys/devices/virtual/powercap", "/sys/devices/system/cpu/cpu0/thermal_throttle", "/sys/devices/system/cpu/cpu1/thermal_throttle", "/sys/devices/system/cpu/cpu2/thermal_throttle", "/sys/devices/system/cpu/cpu3/thermal_throttle", "/sys/devices/system/cpu/cpu4/thermal_throttle", "/sys/devices/system/cpu/cpu5/thermal_throttle", "/sys/devices/system/cpu/cpu6/thermal_throttle", "/sys/devices/system/cpu/cpu7/thermal_throttle", "/sys/devices/system/cpu/cpu8/thermal_throttle", "/sys/devices/system/cpu/cpu9/thermal_throttle", "/sys/devices/system/cpu/cpu10/thermal_throttle", "/sys/devices/system/cpu/cpu11/thermal_throttle", "/sys/devices/system/cpu/cpu12/thermal_throttle", "/sys/devices/system/cpu/cpu13/thermal_throttle", "/sys/devices/system/cpu/cpu14/thermal_throttle", "/sys/devices/system/cpu/cpu15/thermal_throttle"], "Memory": 0, "MemoryReservation": 0, "MemorySwap": 0, "MemorySwappiness": null, "NanoCpus": 0, "NetworkMode": "host", "OomKillDisable": null, "OomScoreAdj": 0, "PidMode": "", "PidsLimit": null, "PortBindings": null, "Privileged": false, "PublishAllPorts": false, "ReadonlyPaths": ["/proc/bus", "/proc/fs", "/proc/irq", "/proc/sys", "/proc/sysrq-trigger"], "ReadonlyRootfs": false, "RestartPolicy": {"MaximumRetryCount": 0, "Name": "unless-stopped"}, "Runtime": "runc", "SecurityOpt": null, "ShmSize": 67108864, "UTSMode": "", "Ulimits": null, "UsernsMode": "", "VolumeDriver": "", "VolumesFrom": null}, "HostnamePath": "/var/snap/docker/common/var-lib-docker/containers/35590ea5ea6807263ad85053af5a180851692fdcec724b6a0a5cd131ead4976c/hostname", "HostsPath": "/var/snap/docker/common/var-lib-docker/containers/35590ea5ea6807263ad85053af5a180851692fdcec724b6a0a5cd131ead4976c/hosts", "Id": "35590ea5ea6807263ad85053af5a180851692fdcec724b6a0a5cd131ead4976c", "Image": "sha256:458e026e6aa62a8da4522cb09766da69d7365ebeb456d5a43a214fc6bd232a3c", "LogPath": "/var/snap/docker/common/var-lib-docker/containers/35590ea5ea6807263ad85053af5a180851692fdcec724b6a0a5cd131ead4976c/35590ea5ea6807263ad85053af5a180851692fdcec724b6a0a5cd131ead4976c-json.log", "MountLabel": "", "Mounts": [{"Destination": "/host/proc", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/proc", "Type": "bind"}, {"Destination": "/host/sys", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/sys", "Type": "bind"}, {"Destination": "/rootfs", "Mode": "ro", "Propagation": "rslave", "RW": false, "Source": "/", "Type": "bind"}], "Name": "/node-exporter", "NetworkSettings": {"Bridge": "", "EndpointID": "", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "HairpinMode": false, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "LinkLocalIPv6Address": "", "LinkLocalIPv6PrefixLen": 0, "MacAddress": "", "Networks": {"host": {"Aliases": null, "DNSNames": null, "DriverOpts": null, "EndpointID": "b6eb6afe4f65950d35e566fa84213210288ae8cda9d8d9d8b1b776aa11281d14", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "GwPriority": 0, "IPAMConfig": null, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "Links": null, "MacAddress": "", "NetworkID": "08942515bd33d690388bcee97cc5b6a4ea027bcdf50469e8d8b1c7df2afd7835"}}, "Ports": {}, "SandboxID": "8d74bd24aa60d22e9b58148ce449b78107b63c3e5174e4437b6ea409ebaa7b64", "SandboxKey": "/run/snap.docker/netns/default", "SecondaryIPAddresses": null, "SecondaryIPv6Addresses": null}, "Path": "/bin/node_exporter", "Platform": "linux", "ProcessLabel": "", "ResolvConfPath": "/var/snap/docker/common/var-lib-docker/containers/35590ea5ea6807263ad85053af5a180851692fdcec724b6a0a5cd131ead4976c/resolv.conf", "RestartCount": 0, "State": {"Dead": false, "Error": "", "ExitCode": 0, "FinishedAt": "0001-01-01T00:00:00Z", "OOMKilled": false, "Paused": false, "Pid": 26543, "Restarting": false, "Running": true, "StartedAt": "2025-07-07T13:35:36.654760129Z", "Status": "running"}}}
2025-07-07 09:35:36,843 p=87684 u=gpadmin n=ansible | changed: [G-244] => {"changed": true, "container": {"AppArmorProfile": "docker-default", "Args": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Config": {"AttachStderr": true, "AttachStdin": false, "AttachStdout": true, "Cmd": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Domainname": "", "Entrypoint": ["/bin/node_exporter"], "Env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"], "ExposedPorts": {"9100/tcp": {}}, "Hostname": "g-244", "Image": "prom/node-exporter:v1.6.1", "Labels": {"maintainer": "The Prometheus Authors <prometheus-developers@googlegroups.com>"}, "OnBuild": null, "OpenStdin": false, "StdinOnce": false, "Tty": false, "User": "nobody", "Volumes": null, "WorkingDir": ""}, "Created": "2025-07-07T13:35:36.586801554Z", "Driver": "overlay2", "ExecIDs": null, "GraphDriver": {"Data": {"ID": "54fb99bb27ad20cd8a229195efa6580b906d207f218a765de9f17958f4b76cd1", "LowerDir": "/var/snap/docker/common/var-lib-docker/overlay2/f3d9e5384ee2ec3b39a9e2b3c04612d2af3a0e30b12a6ccd596c974839267c96-init/diff:/var/snap/docker/common/var-lib-docker/overlay2/d37a8afa5afa9bde0eb2a216bb0b72db026c6a0709ce633f680f51239b829ed1/diff:/var/snap/docker/common/var-lib-docker/overlay2/2eb5d23819025c70f4cd67d6788cf988dbb2c0dbec7fff8b6a0226b3b1af7f82/diff:/var/snap/docker/common/var-lib-docker/overlay2/4d4b1ade00b6031249d67a896b117fb4f7484bf8190621211a196f63aed04ea2/diff", "MergedDir": "/var/snap/docker/common/var-lib-docker/overlay2/f3d9e5384ee2ec3b39a9e2b3c04612d2af3a0e30b12a6ccd596c974839267c96/merged", "UpperDir": "/var/snap/docker/common/var-lib-docker/overlay2/f3d9e5384ee2ec3b39a9e2b3c04612d2af3a0e30b12a6ccd596c974839267c96/diff", "WorkDir": "/var/snap/docker/common/var-lib-docker/overlay2/f3d9e5384ee2ec3b39a9e2b3c04612d2af3a0e30b12a6ccd596c974839267c96/work"}, "Name": "overlay2"}, "HostConfig": {"AutoRemove": false, "Binds": ["/proc:/host/proc:ro", "/sys:/host/sys:ro", "/:/rootfs:ro"], "BlkioDeviceReadBps": null, "BlkioDeviceReadIOps": null, "BlkioDeviceWriteBps": null, "BlkioDeviceWriteIOps": null, "BlkioWeight": 0, "BlkioWeightDevice": null, "CapAdd": null, "CapDrop": null, "Cgroup": "", "CgroupParent": "", "CgroupnsMode": "private", "ConsoleSize": [0, 0], "ContainerIDFile": "", "CpuCount": 0, "CpuPercent": 0, "CpuPeriod": 0, "CpuQuota": 0, "CpuRealtimePeriod": 0, "CpuRealtimeRuntime": 0, "CpuShares": 0, "CpusetCpus": "", "CpusetMems": "", "DeviceCgroupRules": null, "DeviceRequests": null, "Devices": null, "Dns": null, "DnsOptions": null, "DnsSearch": null, "ExtraHosts": null, "GroupAdd": null, "IOMaximumBandwidth": 0, "IOMaximumIOps": 0, "IpcMode": "private", "Isolation": "", "Links": null, "LogConfig": {"Config": {}, "Type": "json-file"}, "MaskedPaths": ["/proc/asound", "/proc/acpi", "/proc/interrupts", "/proc/kcore", "/proc/keys", "/proc/latency_stats", "/proc/timer_list", "/proc/timer_stats", "/proc/sched_debug", "/proc/scsi", "/sys/firmware", "/sys/devices/virtual/powercap", "/sys/devices/system/cpu/cpu0/thermal_throttle", "/sys/devices/system/cpu/cpu1/thermal_throttle", "/sys/devices/system/cpu/cpu2/thermal_throttle", "/sys/devices/system/cpu/cpu3/thermal_throttle", "/sys/devices/system/cpu/cpu4/thermal_throttle", "/sys/devices/system/cpu/cpu5/thermal_throttle", "/sys/devices/system/cpu/cpu6/thermal_throttle", "/sys/devices/system/cpu/cpu7/thermal_throttle", "/sys/devices/system/cpu/cpu8/thermal_throttle", "/sys/devices/system/cpu/cpu9/thermal_throttle", "/sys/devices/system/cpu/cpu10/thermal_throttle", "/sys/devices/system/cpu/cpu11/thermal_throttle", "/sys/devices/system/cpu/cpu12/thermal_throttle", "/sys/devices/system/cpu/cpu13/thermal_throttle", "/sys/devices/system/cpu/cpu14/thermal_throttle", "/sys/devices/system/cpu/cpu15/thermal_throttle"], "Memory": 0, "MemoryReservation": 0, "MemorySwap": 0, "MemorySwappiness": null, "NanoCpus": 0, "NetworkMode": "host", "OomKillDisable": null, "OomScoreAdj": 0, "PidMode": "", "PidsLimit": null, "PortBindings": null, "Privileged": false, "PublishAllPorts": false, "ReadonlyPaths": ["/proc/bus", "/proc/fs", "/proc/irq", "/proc/sys", "/proc/sysrq-trigger"], "ReadonlyRootfs": false, "RestartPolicy": {"MaximumRetryCount": 0, "Name": "unless-stopped"}, "Runtime": "runc", "SecurityOpt": null, "ShmSize": 67108864, "UTSMode": "", "Ulimits": null, "UsernsMode": "", "VolumeDriver": "", "VolumesFrom": null}, "HostnamePath": "/var/snap/docker/common/var-lib-docker/containers/54fb99bb27ad20cd8a229195efa6580b906d207f218a765de9f17958f4b76cd1/hostname", "HostsPath": "/var/snap/docker/common/var-lib-docker/containers/54fb99bb27ad20cd8a229195efa6580b906d207f218a765de9f17958f4b76cd1/hosts", "Id": "54fb99bb27ad20cd8a229195efa6580b906d207f218a765de9f17958f4b76cd1", "Image": "sha256:458e026e6aa62a8da4522cb09766da69d7365ebeb456d5a43a214fc6bd232a3c", "LogPath": "/var/snap/docker/common/var-lib-docker/containers/54fb99bb27ad20cd8a229195efa6580b906d207f218a765de9f17958f4b76cd1/54fb99bb27ad20cd8a229195efa6580b906d207f218a765de9f17958f4b76cd1-json.log", "MountLabel": "", "Mounts": [{"Destination": "/host/proc", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/proc", "Type": "bind"}, {"Destination": "/host/sys", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/sys", "Type": "bind"}, {"Destination": "/rootfs", "Mode": "ro", "Propagation": "rslave", "RW": false, "Source": "/", "Type": "bind"}], "Name": "/node-exporter", "NetworkSettings": {"Bridge": "", "EndpointID": "", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "HairpinMode": false, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "LinkLocalIPv6Address": "", "LinkLocalIPv6PrefixLen": 0, "MacAddress": "", "Networks": {"host": {"Aliases": null, "DNSNames": null, "DriverOpts": null, "EndpointID": "885e179a26cb11781e90c0cc2460321d2ac055c6fc58c93f7412c757b78d4bf9", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "GwPriority": 0, "IPAMConfig": null, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "Links": null, "MacAddress": "", "NetworkID": "5d96122e262cf1ec764846a437b033348d3f336a9e4556edca067907ca50b2a2"}}, "Ports": {}, "SandboxID": "0bfd61c7dcb4960a67a438a471d628e0b3da589be0fd0821dc10c17aa5873796", "SandboxKey": "/run/snap.docker/netns/default", "SecondaryIPAddresses": null, "SecondaryIPv6Addresses": null}, "Path": "/bin/node_exporter", "Platform": "linux", "ProcessLabel": "", "ResolvConfPath": "/var/snap/docker/common/var-lib-docker/containers/54fb99bb27ad20cd8a229195efa6580b906d207f218a765de9f17958f4b76cd1/resolv.conf", "RestartCount": 0, "State": {"Dead": false, "Error": "", "ExitCode": 0, "FinishedAt": "0001-01-01T00:00:00Z", "OOMKilled": false, "Paused": false, "Pid": 26424, "Restarting": false, "Running": true, "StartedAt": "2025-07-07T13:35:36.740449231Z", "Status": "running"}}}
2025-07-07 09:35:36,861 p=87684 u=gpadmin n=ansible | changed: [G-241] => {"changed": true, "container": {"AppArmorProfile": "docker-default", "Args": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Config": {"AttachStderr": true, "AttachStdin": false, "AttachStdout": true, "Cmd": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Domainname": "", "Entrypoint": ["/bin/node_exporter"], "Env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"], "ExposedPorts": {"9100/tcp": {}}, "Hostname": "g-241", "Image": "prom/node-exporter:v1.6.1", "Labels": {"maintainer": "The Prometheus Authors <prometheus-developers@googlegroups.com>"}, "OnBuild": null, "OpenStdin": false, "StdinOnce": false, "Tty": false, "User": "nobody", "Volumes": null, "WorkingDir": ""}, "Created": "2025-07-07T13:35:36.615425486Z", "Driver": "overlay2", "ExecIDs": null, "GraphDriver": {"Data": {"ID": "9b79793063ead7116357e2a6b987ddef302c4067c5df91863532078534abefb4", "LowerDir": "/var/snap/docker/common/var-lib-docker/overlay2/ff26b8e309bd4997a490495147565ed787d90ff4f035ce4e18f131b290441141-init/diff:/var/snap/docker/common/var-lib-docker/overlay2/fe33a44ba16a9145affe7672e726dee5aacb652c3d8fd5f05bca2b6f0dc2967b/diff:/var/snap/docker/common/var-lib-docker/overlay2/87a9e01e421e108201467fa1f79ae55bd1cacb52b2cb85fb54519b86485d0a07/diff:/var/snap/docker/common/var-lib-docker/overlay2/f0a0713b364f30f941d8e182c915e726d41c7217bf27efb96fe4e72d572ba758/diff", "MergedDir": "/var/snap/docker/common/var-lib-docker/overlay2/ff26b8e309bd4997a490495147565ed787d90ff4f035ce4e18f131b290441141/merged", "UpperDir": "/var/snap/docker/common/var-lib-docker/overlay2/ff26b8e309bd4997a490495147565ed787d90ff4f035ce4e18f131b290441141/diff", "WorkDir": "/var/snap/docker/common/var-lib-docker/overlay2/ff26b8e309bd4997a490495147565ed787d90ff4f035ce4e18f131b290441141/work"}, "Name": "overlay2"}, "HostConfig": {"AutoRemove": false, "Binds": ["/proc:/host/proc:ro", "/sys:/host/sys:ro", "/:/rootfs:ro"], "BlkioDeviceReadBps": null, "BlkioDeviceReadIOps": null, "BlkioDeviceWriteBps": null, "BlkioDeviceWriteIOps": null, "BlkioWeight": 0, "BlkioWeightDevice": null, "CapAdd": null, "CapDrop": null, "Cgroup": "", "CgroupParent": "", "CgroupnsMode": "private", "ConsoleSize": [0, 0], "ContainerIDFile": "", "CpuCount": 0, "CpuPercent": 0, "CpuPeriod": 0, "CpuQuota": 0, "CpuRealtimePeriod": 0, "CpuRealtimeRuntime": 0, "CpuShares": 0, "CpusetCpus": "", "CpusetMems": "", "DeviceCgroupRules": null, "DeviceRequests": null, "Devices": null, "Dns": null, "DnsOptions": null, "DnsSearch": null, "ExtraHosts": null, "GroupAdd": null, "IOMaximumBandwidth": 0, "IOMaximumIOps": 0, "IpcMode": "private", "Isolation": "", "Links": null, "LogConfig": {"Config": {}, "Type": "json-file"}, "MaskedPaths": ["/proc/asound", "/proc/acpi", "/proc/interrupts", "/proc/kcore", "/proc/keys", "/proc/latency_stats", "/proc/timer_list", "/proc/timer_stats", "/proc/sched_debug", "/proc/scsi", "/sys/firmware", "/sys/devices/virtual/powercap", "/sys/devices/system/cpu/cpu0/thermal_throttle", "/sys/devices/system/cpu/cpu1/thermal_throttle", "/sys/devices/system/cpu/cpu2/thermal_throttle", "/sys/devices/system/cpu/cpu3/thermal_throttle", "/sys/devices/system/cpu/cpu4/thermal_throttle", "/sys/devices/system/cpu/cpu5/thermal_throttle", "/sys/devices/system/cpu/cpu6/thermal_throttle", "/sys/devices/system/cpu/cpu7/thermal_throttle", "/sys/devices/system/cpu/cpu8/thermal_throttle", "/sys/devices/system/cpu/cpu9/thermal_throttle", "/sys/devices/system/cpu/cpu10/thermal_throttle", "/sys/devices/system/cpu/cpu11/thermal_throttle", "/sys/devices/system/cpu/cpu12/thermal_throttle", "/sys/devices/system/cpu/cpu13/thermal_throttle", "/sys/devices/system/cpu/cpu14/thermal_throttle", "/sys/devices/system/cpu/cpu15/thermal_throttle"], "Memory": 0, "MemoryReservation": 0, "MemorySwap": 0, "MemorySwappiness": null, "NanoCpus": 0, "NetworkMode": "host", "OomKillDisable": null, "OomScoreAdj": 0, "PidMode": "", "PidsLimit": null, "PortBindings": null, "Privileged": false, "PublishAllPorts": false, "ReadonlyPaths": ["/proc/bus", "/proc/fs", "/proc/irq", "/proc/sys", "/proc/sysrq-trigger"], "ReadonlyRootfs": false, "RestartPolicy": {"MaximumRetryCount": 0, "Name": "unless-stopped"}, "Runtime": "runc", "SecurityOpt": null, "ShmSize": 67108864, "UTSMode": "", "Ulimits": null, "UsernsMode": "", "VolumeDriver": "", "VolumesFrom": null}, "HostnamePath": "/var/snap/docker/common/var-lib-docker/containers/9b79793063ead7116357e2a6b987ddef302c4067c5df91863532078534abefb4/hostname", "HostsPath": "/var/snap/docker/common/var-lib-docker/containers/9b79793063ead7116357e2a6b987ddef302c4067c5df91863532078534abefb4/hosts", "Id": "9b79793063ead7116357e2a6b987ddef302c4067c5df91863532078534abefb4", "Image": "sha256:458e026e6aa62a8da4522cb09766da69d7365ebeb456d5a43a214fc6bd232a3c", "LogPath": "/var/snap/docker/common/var-lib-docker/containers/9b79793063ead7116357e2a6b987ddef302c4067c5df91863532078534abefb4/9b79793063ead7116357e2a6b987ddef302c4067c5df91863532078534abefb4-json.log", "MountLabel": "", "Mounts": [{"Destination": "/host/proc", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/proc", "Type": "bind"}, {"Destination": "/host/sys", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/sys", "Type": "bind"}, {"Destination": "/rootfs", "Mode": "ro", "Propagation": "rslave", "RW": false, "Source": "/", "Type": "bind"}], "Name": "/node-exporter", "NetworkSettings": {"Bridge": "", "EndpointID": "", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "HairpinMode": false, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "LinkLocalIPv6Address": "", "LinkLocalIPv6PrefixLen": 0, "MacAddress": "", "Networks": {"host": {"Aliases": null, "DNSNames": null, "DriverOpts": null, "EndpointID": "0060b4972b54f1b67783f255155f5adf4decf3bb9aee0aca0d8f4a14645d82ab", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "GwPriority": 0, "IPAMConfig": null, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "Links": null, "MacAddress": "", "NetworkID": "8cecfccbd5549f17327be430b864641aa1ac55d73cad72c3a9aba84c615d7f79"}}, "Ports": {}, "SandboxID": "7aa2fb872b40b3737df73285253f06692ae9151016fc52b89e4b0720aba8b96b", "SandboxKey": "/run/snap.docker/netns/default", "SecondaryIPAddresses": null, "SecondaryIPv6Addresses": null}, "Path": "/bin/node_exporter", "Platform": "linux", "ProcessLabel": "", "ResolvConfPath": "/var/snap/docker/common/var-lib-docker/containers/9b79793063ead7116357e2a6b987ddef302c4067c5df91863532078534abefb4/resolv.conf", "RestartCount": 0, "State": {"Dead": false, "Error": "", "ExitCode": 0, "FinishedAt": "0001-01-01T00:00:00Z", "OOMKilled": false, "Paused": false, "Pid": 15104, "Restarting": false, "Running": true, "StartedAt": "2025-07-07T13:35:36.755180325Z", "Status": "running"}}}
2025-07-07 09:35:36,991 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "container": {"AppArmorProfile": "docker-default", "Args": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Config": {"AttachStderr": true, "AttachStdin": false, "AttachStdout": true, "Cmd": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Domainname": "", "Entrypoint": ["/bin/node_exporter"], "Env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"], "ExposedPorts": {"9100/tcp": {}}, "Hostname": "G-K3S-Master", "Image": "prom/node-exporter:v1.6.1", "Labels": {"maintainer": "The Prometheus Authors <prometheus-developers@googlegroups.com>"}, "OnBuild": null, "OpenStdin": false, "StdinOnce": false, "Tty": false, "User": "nobody", "Volumes": null, "WorkingDir": ""}, "Created": "2025-07-07T13:35:36.725794975Z", "Driver": "overlay2", "ExecIDs": null, "GraphDriver": {"Data": {"ID": "bd67311143320a4bd5c445f0c18c9839e6da17c9dadbbe526f4390faab8c8f55", "LowerDir": "/var/lib/docker/overlay2/2198fcf483ab5d90d14060ea806ae29bfb77630187940544be6065c1a09227ed-init/diff:/var/lib/docker/overlay2/8af842d98d0a2cb3e2e2798e113754883ed0a054eb815c1b619dc9b76166758d/diff:/var/lib/docker/overlay2/e8909c2c1a6f393357e0123864392e8ef4e82bac695968bfb63064bb251897ce/diff:/var/lib/docker/overlay2/bd10e72442062f9751b8ff22cb9c75f181a7e40a8364c1b0f34769dc742aa9f4/diff", "MergedDir": "/var/lib/docker/overlay2/2198fcf483ab5d90d14060ea806ae29bfb77630187940544be6065c1a09227ed/merged", "UpperDir": "/var/lib/docker/overlay2/2198fcf483ab5d90d14060ea806ae29bfb77630187940544be6065c1a09227ed/diff", "WorkDir": "/var/lib/docker/overlay2/2198fcf483ab5d90d14060ea806ae29bfb77630187940544be6065c1a09227ed/work"}, "Name": "overlay2"}, "HostConfig": {"AutoRemove": false, "Binds": ["/proc:/host/proc:ro", "/sys:/host/sys:ro", "/:/rootfs:ro"], "BlkioDeviceReadBps": null, "BlkioDeviceReadIOps": null, "BlkioDeviceWriteBps": null, "BlkioDeviceWriteIOps": null, "BlkioWeight": 0, "BlkioWeightDevice": null, "CapAdd": null, "CapDrop": null, "Cgroup": "", "CgroupParent": "", "CgroupnsMode": "private", "ConsoleSize": [0, 0], "ContainerIDFile": "", "CpuCount": 0, "CpuPercent": 0, "CpuPeriod": 0, "CpuQuota": 0, "CpuRealtimePeriod": 0, "CpuRealtimeRuntime": 0, "CpuShares": 0, "CpusetCpus": "", "CpusetMems": "", "DeviceCgroupRules": null, "DeviceRequests": null, "Devices": null, "Dns": null, "DnsOptions": null, "DnsSearch": null, "ExtraHosts": null, "GroupAdd": null, "IOMaximumBandwidth": 0, "IOMaximumIOps": 0, "IpcMode": "private", "Isolation": "", "Links": null, "LogConfig": {"Config": {}, "Type": "json-file"}, "MaskedPaths": ["/proc/asound", "/proc/acpi", "/proc/interrupts", "/proc/kcore", "/proc/keys", "/proc/latency_stats", "/proc/timer_list", "/proc/timer_stats", "/proc/sched_debug", "/proc/scsi", "/sys/firmware", "/sys/devices/virtual/powercap"], "Memory": 0, "MemoryReservation": 0, "MemorySwap": 0, "MemorySwappiness": null, "NanoCpus": 0, "NetworkMode": "host", "OomKillDisable": null, "OomScoreAdj": 0, "PidMode": "", "PidsLimit": null, "PortBindings": null, "Privileged": false, "PublishAllPorts": false, "ReadonlyPaths": ["/proc/bus", "/proc/fs", "/proc/irq", "/proc/sys", "/proc/sysrq-trigger"], "ReadonlyRootfs": false, "RestartPolicy": {"MaximumRetryCount": 0, "Name": "unless-stopped"}, "Runtime": "runc", "SecurityOpt": null, "ShmSize": 67108864, "UTSMode": "", "Ulimits": null, "UsernsMode": "", "VolumeDriver": "", "VolumesFrom": null}, "HostnamePath": "/var/lib/docker/containers/bd67311143320a4bd5c445f0c18c9839e6da17c9dadbbe526f4390faab8c8f55/hostname", "HostsPath": "/var/lib/docker/containers/bd67311143320a4bd5c445f0c18c9839e6da17c9dadbbe526f4390faab8c8f55/hosts", "Id": "bd67311143320a4bd5c445f0c18c9839e6da17c9dadbbe526f4390faab8c8f55", "Image": "sha256:458e026e6aa62a8da4522cb09766da69d7365ebeb456d5a43a214fc6bd232a3c", "LogPath": "/var/lib/docker/containers/bd67311143320a4bd5c445f0c18c9839e6da17c9dadbbe526f4390faab8c8f55/bd67311143320a4bd5c445f0c18c9839e6da17c9dadbbe526f4390faab8c8f55-json.log", "MountLabel": "", "Mounts": [{"Destination": "/host/proc", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/proc", "Type": "bind"}, {"Destination": "/host/sys", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/sys", "Type": "bind"}, {"Destination": "/rootfs", "Mode": "ro", "Propagation": "rslave", "RW": false, "Source": "/", "Type": "bind"}], "Name": "/node-exporter", "NetworkSettings": {"Bridge": "", "EndpointID": "", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "HairpinMode": false, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "LinkLocalIPv6Address": "", "LinkLocalIPv6PrefixLen": 0, "MacAddress": "", "Networks": {"host": {"Aliases": null, "DNSNames": null, "DriverOpts": null, "EndpointID": "7b3556d02fa751a3cb356299fb3e741e99184a5b2a448b274cdbbe7be5f98a6a", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "GwPriority": 0, "IPAMConfig": null, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "Links": null, "MacAddress": "", "NetworkID": "268de73ef511b2a43769cd935946989dc6b40e46e052a834cd7d3cb969014641"}}, "Ports": {}, "SandboxID": "bdb0742a43eddf3878e2765acf6f8d2f3e06244d28b3edd66ae7cdaaacb384fd", "SandboxKey": "/var/run/docker/netns/default", "SecondaryIPAddresses": null, "SecondaryIPv6Addresses": null}, "Path": "/bin/node_exporter", "Platform": "linux", "ProcessLabel": "", "ResolvConfPath": "/var/lib/docker/containers/bd67311143320a4bd5c445f0c18c9839e6da17c9dadbbe526f4390faab8c8f55/resolv.conf", "RestartCount": 0, "State": {"Dead": false, "Error": "", "ExitCode": 0, "FinishedAt": "0001-01-01T00:00:00Z", "OOMKilled": false, "Paused": false, "Pid": 90527, "Restarting": false, "Running": true, "StartedAt": "2025-07-07T13:35:36.803312619Z", "Status": "running"}}}
2025-07-07 09:35:37,740 p=87684 u=gpadmin n=ansible | changed: [G-242] => {"changed": true, "container": {"AppArmorProfile": "docker-default", "Args": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Config": {"AttachStderr": true, "AttachStdin": false, "AttachStdout": true, "Cmd": ["--path.procfs=/host/proc", "--path.sysfs=/host/sys", "--path.rootfs=/rootfs", "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)", "--web.listen-address=0.0.0.0:9100"], "Domainname": "", "Entrypoint": ["/bin/node_exporter"], "Env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"], "ExposedPorts": {"9100/tcp": {}}, "Hostname": "g-242", "Image": "prom/node-exporter:v1.6.1", "Labels": {"maintainer": "The Prometheus Authors <prometheus-developers@googlegroups.com>"}, "OnBuild": null, "OpenStdin": false, "StdinOnce": false, "Tty": false, "User": "nobody", "Volumes": null, "WorkingDir": ""}, "Created": "2025-07-07T13:35:37.489841808Z", "Driver": "overlay2", "ExecIDs": null, "GraphDriver": {"Data": {"ID": "c04598c908e57bfff47b793c13e9d467030d5145d52c8f1878668ae6e444ca4b", "LowerDir": "/var/snap/docker/common/var-lib-docker/overlay2/db601580b9bb19f33f6d48bb0d63e5907df17bcce80863a66efbe630194ef400-init/diff:/var/snap/docker/common/var-lib-docker/overlay2/f4d1504100ba1d73f39ffb996b3062039f317c1a08ab6460b8a9cb5d83888108/diff:/var/snap/docker/common/var-lib-docker/overlay2/f1c62109c72e0cd873b94fc7e718c8e9c7b5e465c761e9ec9a7acc881aa239b4/diff:/var/snap/docker/common/var-lib-docker/overlay2/5d7a1f73deb71855a191659f4ce5fdf17c1bda9f22085737718b956785cf42c8/diff", "MergedDir": "/var/snap/docker/common/var-lib-docker/overlay2/db601580b9bb19f33f6d48bb0d63e5907df17bcce80863a66efbe630194ef400/merged", "UpperDir": "/var/snap/docker/common/var-lib-docker/overlay2/db601580b9bb19f33f6d48bb0d63e5907df17bcce80863a66efbe630194ef400/diff", "WorkDir": "/var/snap/docker/common/var-lib-docker/overlay2/db601580b9bb19f33f6d48bb0d63e5907df17bcce80863a66efbe630194ef400/work"}, "Name": "overlay2"}, "HostConfig": {"AutoRemove": false, "Binds": ["/proc:/host/proc:ro", "/sys:/host/sys:ro", "/:/rootfs:ro"], "BlkioDeviceReadBps": null, "BlkioDeviceReadIOps": null, "BlkioDeviceWriteBps": null, "BlkioDeviceWriteIOps": null, "BlkioWeight": 0, "BlkioWeightDevice": null, "CapAdd": null, "CapDrop": null, "Cgroup": "", "CgroupParent": "", "CgroupnsMode": "private", "ConsoleSize": [0, 0], "ContainerIDFile": "", "CpuCount": 0, "CpuPercent": 0, "CpuPeriod": 0, "CpuQuota": 0, "CpuRealtimePeriod": 0, "CpuRealtimeRuntime": 0, "CpuShares": 0, "CpusetCpus": "", "CpusetMems": "", "DeviceCgroupRules": null, "DeviceRequests": null, "Devices": null, "Dns": null, "DnsOptions": null, "DnsSearch": null, "ExtraHosts": null, "GroupAdd": null, "IOMaximumBandwidth": 0, "IOMaximumIOps": 0, "IpcMode": "private", "Isolation": "", "Links": null, "LogConfig": {"Config": {}, "Type": "json-file"}, "MaskedPaths": ["/proc/asound", "/proc/acpi", "/proc/interrupts", "/proc/kcore", "/proc/keys", "/proc/latency_stats", "/proc/timer_list", "/proc/timer_stats", "/proc/sched_debug", "/proc/scsi", "/sys/firmware", "/sys/devices/virtual/powercap", "/sys/devices/system/cpu/cpu0/thermal_throttle", "/sys/devices/system/cpu/cpu1/thermal_throttle", "/sys/devices/system/cpu/cpu2/thermal_throttle", "/sys/devices/system/cpu/cpu3/thermal_throttle", "/sys/devices/system/cpu/cpu4/thermal_throttle", "/sys/devices/system/cpu/cpu5/thermal_throttle", "/sys/devices/system/cpu/cpu6/thermal_throttle", "/sys/devices/system/cpu/cpu7/thermal_throttle", "/sys/devices/system/cpu/cpu8/thermal_throttle", "/sys/devices/system/cpu/cpu9/thermal_throttle", "/sys/devices/system/cpu/cpu10/thermal_throttle", "/sys/devices/system/cpu/cpu11/thermal_throttle", "/sys/devices/system/cpu/cpu12/thermal_throttle", "/sys/devices/system/cpu/cpu13/thermal_throttle", "/sys/devices/system/cpu/cpu14/thermal_throttle", "/sys/devices/system/cpu/cpu15/thermal_throttle"], "Memory": 0, "MemoryReservation": 0, "MemorySwap": 0, "MemorySwappiness": null, "NanoCpus": 0, "NetworkMode": "host", "OomKillDisable": null, "OomScoreAdj": 0, "PidMode": "", "PidsLimit": null, "PortBindings": null, "Privileged": false, "PublishAllPorts": false, "ReadonlyPaths": ["/proc/bus", "/proc/fs", "/proc/irq", "/proc/sys", "/proc/sysrq-trigger"], "ReadonlyRootfs": false, "RestartPolicy": {"MaximumRetryCount": 0, "Name": "unless-stopped"}, "Runtime": "runc", "SecurityOpt": null, "ShmSize": 67108864, "UTSMode": "", "Ulimits": null, "UsernsMode": "", "VolumeDriver": "", "VolumesFrom": null}, "HostnamePath": "/var/snap/docker/common/var-lib-docker/containers/c04598c908e57bfff47b793c13e9d467030d5145d52c8f1878668ae6e444ca4b/hostname", "HostsPath": "/var/snap/docker/common/var-lib-docker/containers/c04598c908e57bfff47b793c13e9d467030d5145d52c8f1878668ae6e444ca4b/hosts", "Id": "c04598c908e57bfff47b793c13e9d467030d5145d52c8f1878668ae6e444ca4b", "Image": "sha256:458e026e6aa62a8da4522cb09766da69d7365ebeb456d5a43a214fc6bd232a3c", "LogPath": "/var/snap/docker/common/var-lib-docker/containers/c04598c908e57bfff47b793c13e9d467030d5145d52c8f1878668ae6e444ca4b/c04598c908e57bfff47b793c13e9d467030d5145d52c8f1878668ae6e444ca4b-json.log", "MountLabel": "", "Mounts": [{"Destination": "/host/proc", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/proc", "Type": "bind"}, {"Destination": "/host/sys", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/sys", "Type": "bind"}, {"Destination": "/rootfs", "Mode": "ro", "Propagation": "rslave", "RW": false, "Source": "/", "Type": "bind"}], "Name": "/node-exporter", "NetworkSettings": {"Bridge": "", "EndpointID": "", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "HairpinMode": false, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "LinkLocalIPv6Address": "", "LinkLocalIPv6PrefixLen": 0, "MacAddress": "", "Networks": {"host": {"Aliases": null, "DNSNames": null, "DriverOpts": null, "EndpointID": "6432bb9e93609d1cbbcd824561771add2155bb52cab2b6a1831c0b2b7f46e437", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "GwPriority": 0, "IPAMConfig": null, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "Links": null, "MacAddress": "", "NetworkID": "4344c50ff342c397162b0b5e0b1b235b2c99773c584620f9c3741f098fec875a"}}, "Ports": {}, "SandboxID": "618cf53480a87ec6140c55d0d31e52657e84e45b840e100e45b5d945a37cb6d2", "SandboxKey": "/run/snap.docker/netns/default", "SecondaryIPAddresses": null, "SecondaryIPv6Addresses": null}, "Path": "/bin/node_exporter", "Platform": "linux", "ProcessLabel": "", "ResolvConfPath": "/var/snap/docker/common/var-lib-docker/containers/c04598c908e57bfff47b793c13e9d467030d5145d52c8f1878668ae6e444ca4b/resolv.conf", "RestartCount": 0, "State": {"Dead": false, "Error": "", "ExitCode": 0, "FinishedAt": "0001-01-01T00:00:00Z", "OOMKilled": false, "Paused": false, "Pid": 24346, "Restarting": false, "Running": true, "StartedAt": "2025-07-07T13:35:37.633071158Z", "Status": "running"}}}
2025-07-07 09:35:37,754 p=87684 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing cAdvisor container (idempotency)] ***************
2025-07-07 09:35:38,032 p=87684 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:38,032 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:38,061 p=87684 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:38,061 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:38,068 p=87684 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:38,068 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:38,087 p=87684 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:38,088 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:38,254 p=87684 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:38,255 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:38,268 p=87684 u=gpadmin n=ansible | TASK [monitoring : Start cAdvisor container] ************************************************
2025-07-07 09:35:42,536 p=87684 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "msg": "Error starting container 8514c0b79f1cc76121424008f90713f53d9ad925337a9cfd85bff986549c6c3d: 500 Server Error for http+docker://localhost/v1.49/containers/8514c0b79f1cc76121424008f90713f53d9ad925337a9cfd85bff986549c6c3d/start: Internal Server Error (\"error while creating mount source path '/var/lib/docker': mkdir /var/lib/docker: read-only file system\")"}
2025-07-07 09:35:42,642 p=87684 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "msg": "Error starting container 578af5eb61cbefd4de0e6da9e537f8499e05797d26b5120e762d6e605a336e26: 500 Server Error for http+docker://localhost/v1.49/containers/578af5eb61cbefd4de0e6da9e537f8499e05797d26b5120e762d6e605a336e26/start: Internal Server Error (\"error while creating mount source path '/var/lib/docker': mkdir /var/lib/docker: read-only file system\")"}
2025-07-07 09:35:42,894 p=87684 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "msg": "Error starting container a65e974292adf5978a7a6ae102ec60009435bc3ddad3fe52e44f323b802e7bbb: 500 Server Error for http+docker://localhost/v1.49/containers/a65e974292adf5978a7a6ae102ec60009435bc3ddad3fe52e44f323b802e7bbb/start: Internal Server Error (\"error while creating mount source path '/var/lib/docker': mkdir /var/lib/docker: read-only file system\")"}
2025-07-07 09:35:43,324 p=87684 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "msg": "Error starting container 2e50b1058a6328d87c4ea1811d4acc36d38270b4b93492695c3246e3686f2181: 500 Server Error for http+docker://localhost/v1.49/containers/2e50b1058a6328d87c4ea1811d4acc36d38270b4b93492695c3246e3686f2181/start: Internal Server Error (\"error while creating mount source path '/var/lib/docker': mkdir /var/lib/docker: read-only file system\")"}
2025-07-07 09:35:43,550 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "container": {"AppArmorProfile": "unconfined", "Args": ["-logtostderr", "--port=8081", "--housekeeping_interval=10s", "--docker_only=true"], "Config": {"AttachStderr": true, "AttachStdin": false, "AttachStdout": true, "Cmd": ["--port=8081", "--housekeeping_interval=10s", "--docker_only=true"], "Domainname": "", "Entrypoint": ["/usr/bin/cadvisor", "-logtostderr"], "Env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "CADVISOR_HEALTHCHECK_URL=http://localhost:8080/healthz"], "ExposedPorts": {"8080/tcp": {}}, "Healthcheck": {"Interval": 30000000000, "Test": ["CMD-SHELL", "wget --quiet --tries=1 --spider $CADVISOR_HEALTHCHECK_URL || exit 1"], "Timeout": 3000000000}, "Hostname": "G-K3S-Master", "Image": "gcr.io/cadvisor/cadvisor:v0.47.2", "Labels": {}, "OnBuild": null, "OpenStdin": false, "StdinOnce": false, "Tty": false, "User": "", "Volumes": null, "WorkingDir": ""}, "Created": "2025-07-07T13:35:43.255878415Z", "Driver": "overlay2", "ExecIDs": null, "GraphDriver": {"Data": {"ID": "2d12943bbe8b7f23a1855bbf212d55eb160a7c9c08f95b3589cbb7b4f0ee3b4e", "LowerDir": "/var/lib/docker/overlay2/169f8ba631b1382527a7a19c02a89879dad33c651384a4921dec893d36a55472-init/diff:/var/lib/docker/overlay2/ac4792ea7ad941e2b71ba5e92efc7e8466206e4aaeb339017905526845030872/diff:/var/lib/docker/overlay2/97aa822f886798d46089ad932d9487775d6c23d7b91b208e0bd9b9639e73d3dc/diff:/var/lib/docker/overlay2/dadfda306de3ca54dcc99e2cb040c0f8aece56ec59492821e565c5830ac1d653/diff:/var/lib/docker/overlay2/7fe4d9f6687db9dcffe7d065ba709508582f9a34ceed1c8ec55285eb6b6ffb20/diff:/var/lib/docker/overlay2/b512d3d732e49136a0b760084416de6bded7b3848fdbaafdb2d4dd7f007ebc77/diff", "MergedDir": "/var/lib/docker/overlay2/169f8ba631b1382527a7a19c02a89879dad33c651384a4921dec893d36a55472/merged", "UpperDir": "/var/lib/docker/overlay2/169f8ba631b1382527a7a19c02a89879dad33c651384a4921dec893d36a55472/diff", "WorkDir": "/var/lib/docker/overlay2/169f8ba631b1382527a7a19c02a89879dad33c651384a4921dec893d36a55472/work"}, "Name": "overlay2"}, "HostConfig": {"AutoRemove": false, "Binds": ["/:/rootfs:ro", "/var/run:/var/run:ro", "/sys:/sys:ro", "/var/lib/docker/:/var/lib/docker:ro", "/dev/disk/:/dev/disk:ro"], "BlkioDeviceReadBps": null, "BlkioDeviceReadIOps": null, "BlkioDeviceWriteBps": null, "BlkioDeviceWriteIOps": null, "BlkioWeight": 0, "BlkioWeightDevice": null, "CapAdd": null, "CapDrop": null, "Cgroup": "", "CgroupParent": "", "CgroupnsMode": "private", "ConsoleSize": [0, 0], "ContainerIDFile": "", "CpuCount": 0, "CpuPercent": 0, "CpuPeriod": 0, "CpuQuota": 0, "CpuRealtimePeriod": 0, "CpuRealtimeRuntime": 0, "CpuShares": 0, "CpusetCpus": "", "CpusetMems": "", "DeviceCgroupRules": null, "DeviceRequests": null, "Devices": null, "Dns": null, "DnsOptions": null, "DnsSearch": null, "ExtraHosts": null, "GroupAdd": null, "IOMaximumBandwidth": 0, "IOMaximumIOps": 0, "IpcMode": "private", "Isolation": "", "Links": null, "LogConfig": {"Config": {}, "Type": "json-file"}, "MaskedPaths": null, "Memory": 0, "MemoryReservation": 0, "MemorySwap": 0, "MemorySwappiness": null, "NanoCpus": 0, "NetworkMode": "host", "OomKillDisable": null, "OomScoreAdj": 0, "PidMode": "", "PidsLimit": null, "PortBindings": null, "Privileged": true, "PublishAllPorts": false, "ReadonlyPaths": null, "ReadonlyRootfs": false, "RestartPolicy": {"MaximumRetryCount": 0, "Name": "unless-stopped"}, "Runtime": "runc", "SecurityOpt": ["label=disable"], "ShmSize": 67108864, "UTSMode": "", "Ulimits": null, "UsernsMode": "", "VolumeDriver": "", "VolumesFrom": null}, "HostnamePath": "/var/lib/docker/containers/2d12943bbe8b7f23a1855bbf212d55eb160a7c9c08f95b3589cbb7b4f0ee3b4e/hostname", "HostsPath": "/var/lib/docker/containers/2d12943bbe8b7f23a1855bbf212d55eb160a7c9c08f95b3589cbb7b4f0ee3b4e/hosts", "Id": "2d12943bbe8b7f23a1855bbf212d55eb160a7c9c08f95b3589cbb7b4f0ee3b4e", "Image": "sha256:69c7eeee9744e45394bf0eb5f1c726fd59aee5ec84297029af453fbc6de4fa98", "LogPath": "/var/lib/docker/containers/2d12943bbe8b7f23a1855bbf212d55eb160a7c9c08f95b3589cbb7b4f0ee3b4e/2d12943bbe8b7f23a1855bbf212d55eb160a7c9c08f95b3589cbb7b4f0ee3b4e-json.log", "MountLabel": "", "Mounts": [{"Destination": "/rootfs", "Mode": "ro", "Propagation": "rslave", "RW": false, "Source": "/", "Type": "bind"}, {"Destination": "/var/run", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/var/run", "Type": "bind"}, {"Destination": "/sys", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/sys", "Type": "bind"}, {"Destination": "/var/lib/docker", "Mode": "ro", "Propagation": "rslave", "RW": false, "Source": "/var/lib/docker", "Type": "bind"}, {"Destination": "/dev/disk", "Mode": "ro", "Propagation": "rprivate", "RW": false, "Source": "/dev/disk", "Type": "bind"}], "Name": "/cadvisor", "NetworkSettings": {"Bridge": "", "EndpointID": "", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "HairpinMode": false, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "LinkLocalIPv6Address": "", "LinkLocalIPv6PrefixLen": 0, "MacAddress": "", "Networks": {"host": {"Aliases": null, "DNSNames": null, "DriverOpts": null, "EndpointID": "c501881cd70e45634dce5fe1161f0fa3ee93df67699916c5aee61ae92924747d", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "GwPriority": 0, "IPAMConfig": null, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "Links": null, "MacAddress": "", "NetworkID": "268de73ef511b2a43769cd935946989dc6b40e46e052a834cd7d3cb969014641"}}, "Ports": {}, "SandboxID": "0630201c99967772b617233102dda578393b9b631e435f06e28358ff41d85a44", "SandboxKey": "/var/run/docker/netns/default", "SecondaryIPAddresses": null, "SecondaryIPv6Addresses": null}, "Path": "/usr/bin/cadvisor", "Platform": "linux", "ProcessLabel": "", "ResolvConfPath": "/var/lib/docker/containers/2d12943bbe8b7f23a1855bbf212d55eb160a7c9c08f95b3589cbb7b4f0ee3b4e/resolv.conf", "RestartCount": 0, "State": {"Dead": false, "Error": "", "ExitCode": 0, "FinishedAt": "0001-01-01T00:00:00Z", "Health": {"FailingStreak": 0, "Log": [], "Status": "starting"}, "OOMKilled": false, "Paused": false, "Pid": 90827, "Restarting": false, "Running": true, "StartedAt": "2025-07-07T13:35:43.357683271Z", "Status": "running"}}}
2025-07-07 09:35:43,563 p=87684 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Prometheus container (idempotency)] *************
2025-07-07 09:35:44,040 p=87684 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:44,041 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:44,053 p=87684 u=gpadmin n=ansible | TASK [monitoring : Create Prometheus configuration] *****************************************
2025-07-07 09:35:44,664 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "checksum": "de8739e5810d4faa8dc979cf39733369c004be59", "dest": "/home/gpadmin/prometheus_data/prometheus.yml", "gid": 1000, "group": "gpadmin", "md5sum": "5a66b6b8be7624374b718d41caf0e5d4", "mode": "0644", "owner": "gpadmin", "size": 1174, "src": "/home/gpadmin/.ansible/tmp/ansible-tmp-1751895344.086496-90961-162674673733447/source", "state": "file", "uid": 1000}
2025-07-07 09:35:44,679 p=87684 u=gpadmin n=ansible | TASK [monitoring : Start Prometheus container] **********************************************
2025-07-07 09:35:50,320 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "container": {"AppArmorProfile": "docker-default", "Args": ["--config.file=/etc/prometheus/prometheus.yml", "--storage.tsdb.path=/prometheus", "--web.console.libraries=/usr/share/prometheus/console_libraries", "--web.console.templates=/usr/share/prometheus/consoles", "--web.listen-address=0.0.0.0:9090"], "Config": {"AttachStderr": true, "AttachStdin": false, "AttachStdout": true, "Cmd": ["--config.file=/etc/prometheus/prometheus.yml", "--storage.tsdb.path=/prometheus", "--web.console.libraries=/usr/share/prometheus/console_libraries", "--web.console.templates=/usr/share/prometheus/consoles", "--web.listen-address=0.0.0.0:9090"], "Domainname": "", "Entrypoint": ["/bin/prometheus"], "Env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"], "ExposedPorts": {"9090/tcp": {}}, "Hostname": "G-K3S-Master", "Image": "prom/prometheus:v2.45.0", "Labels": {"maintainer": "The Prometheus Authors <prometheus-developers@googlegroups.com>"}, "OnBuild": null, "OpenStdin": false, "StdinOnce": false, "Tty": false, "User": "nobody", "Volumes": {"/prometheus": {}}, "WorkingDir": "/prometheus"}, "Created": "2025-07-07T13:35:49.906082576Z", "Driver": "overlay2", "ExecIDs": null, "GraphDriver": {"Data": {"ID": "335acfbb607384d0e37ad40e811f606747f9f8749e727307829f1164697fb634", "LowerDir": "/var/lib/docker/overlay2/53c02454e8badef7a3dc30547a96c5074b56c9867ab1cec5dce8169707bcdb71-init/diff:/var/lib/docker/overlay2/8451a45171c644f12c7a1ac18496ae0a09f2d629adf38bb7b2cd8b0068661265/diff:/var/lib/docker/overlay2/2182c3c93d556e074f76fa5856e3cba991c25e41b9d405376503523399e1ccef/diff:/var/lib/docker/overlay2/bbe6a7185993d26e669de13aff7e7216dd0a40e6fdb2c438114b86a7f55602b0/diff:/var/lib/docker/overlay2/08b725874d0af6b34c1181e953db6c6e862da9d6e8015218101cb0e02bc859b1/diff:/var/lib/docker/overlay2/ddf44b888773a931069d6346b6651db4f5a6ecf441fd57295fe48c989201c951/diff:/var/lib/docker/overlay2/4d48cfc24b97211279956d8c5a464d3bed5299df2dc42c7e93a0ab4ec4950796/diff:/var/lib/docker/overlay2/ebe22bfe95e736075a35bb6c1cadd27bbb292415d585e8c3cc1764a44c016d5c/diff:/var/lib/docker/overlay2/aa1da3a8a575a79681262993df1474b4440f6e32fa53994af7512785f77ab3aa/diff:/var/lib/docker/overlay2/258dde30e12d2ffffd8d1b4f588b76850af3d996609fd2ff3c77e9a41f8b8ca4/diff:/var/lib/docker/overlay2/7dca87ba3eaf0bf0445e53bb81d9ffaa7b4f41fb4f1b379cbfed2df152958006/diff:/var/lib/docker/overlay2/ce48a2c9342792fe3b218db0817b645989e46c2f4bd873febd9bf6cc884a693e/diff:/var/lib/docker/overlay2/e46680c5a6c73440ae7c042a9a00d16450b50148d51c4bd490b91757a2697b8a/diff", "MergedDir": "/var/lib/docker/overlay2/53c02454e8badef7a3dc30547a96c5074b56c9867ab1cec5dce8169707bcdb71/merged", "UpperDir": "/var/lib/docker/overlay2/53c02454e8badef7a3dc30547a96c5074b56c9867ab1cec5dce8169707bcdb71/diff", "WorkDir": "/var/lib/docker/overlay2/53c02454e8badef7a3dc30547a96c5074b56c9867ab1cec5dce8169707bcdb71/work"}, "Name": "overlay2"}, "HostConfig": {"AutoRemove": false, "Binds": ["/home/gpadmin/prometheus_data/prometheus.yml:/etc/prometheus/prometheus.yml:rw", "/home/gpadmin/prometheus_data:/prometheus:rw"], "BlkioDeviceReadBps": null, "BlkioDeviceReadIOps": null, "BlkioDeviceWriteBps": null, "BlkioDeviceWriteIOps": null, "BlkioWeight": 0, "BlkioWeightDevice": null, "CapAdd": null, "CapDrop": null, "Cgroup": "", "CgroupParent": "", "CgroupnsMode": "private", "ConsoleSize": [0, 0], "ContainerIDFile": "", "CpuCount": 0, "CpuPercent": 0, "CpuPeriod": 0, "CpuQuota": 0, "CpuRealtimePeriod": 0, "CpuRealtimeRuntime": 0, "CpuShares": 0, "CpusetCpus": "", "CpusetMems": "", "DeviceCgroupRules": null, "DeviceRequests": null, "Devices": null, "Dns": null, "DnsOptions": null, "DnsSearch": null, "ExtraHosts": null, "GroupAdd": null, "IOMaximumBandwidth": 0, "IOMaximumIOps": 0, "IpcMode": "private", "Isolation": "", "Links": null, "LogConfig": {"Config": {}, "Type": "json-file"}, "MaskedPaths": ["/proc/asound", "/proc/acpi", "/proc/interrupts", "/proc/kcore", "/proc/keys", "/proc/latency_stats", "/proc/timer_list", "/proc/timer_stats", "/proc/sched_debug", "/proc/scsi", "/sys/firmware", "/sys/devices/virtual/powercap"], "Memory": 0, "MemoryReservation": 0, "MemorySwap": 0, "MemorySwappiness": null, "NanoCpus": 0, "NetworkMode": "host", "OomKillDisable": null, "OomScoreAdj": 0, "PidMode": "", "PidsLimit": null, "PortBindings": null, "Privileged": false, "PublishAllPorts": false, "ReadonlyPaths": ["/proc/bus", "/proc/fs", "/proc/irq", "/proc/sys", "/proc/sysrq-trigger"], "ReadonlyRootfs": false, "RestartPolicy": {"MaximumRetryCount": 0, "Name": "unless-stopped"}, "Runtime": "runc", "SecurityOpt": null, "ShmSize": 67108864, "UTSMode": "", "Ulimits": null, "UsernsMode": "", "VolumeDriver": "", "VolumesFrom": null}, "HostnamePath": "/var/lib/docker/containers/335acfbb607384d0e37ad40e811f606747f9f8749e727307829f1164697fb634/hostname", "HostsPath": "/var/lib/docker/containers/335acfbb607384d0e37ad40e811f606747f9f8749e727307829f1164697fb634/hosts", "Id": "335acfbb607384d0e37ad40e811f606747f9f8749e727307829f1164697fb634", "Image": "sha256:e1fbd49323c628ccc8c11aea113eddc294c4bd1887dc627d175331c325df10fd", "LogPath": "/var/lib/docker/containers/335acfbb607384d0e37ad40e811f606747f9f8749e727307829f1164697fb634/335acfbb607384d0e37ad40e811f606747f9f8749e727307829f1164697fb634-json.log", "MountLabel": "", "Mounts": [{"Destination": "/etc/prometheus/prometheus.yml", "Mode": "rw", "Propagation": "rprivate", "RW": true, "Source": "/home/gpadmin/prometheus_data/prometheus.yml", "Type": "bind"}, {"Destination": "/prometheus", "Mode": "rw", "Propagation": "rprivate", "RW": true, "Source": "/home/gpadmin/prometheus_data", "Type": "bind"}], "Name": "/prometheus", "NetworkSettings": {"Bridge": "", "EndpointID": "", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "HairpinMode": false, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "LinkLocalIPv6Address": "", "LinkLocalIPv6PrefixLen": 0, "MacAddress": "", "Networks": {"host": {"Aliases": null, "DNSNames": null, "DriverOpts": null, "EndpointID": "afcc208f89c94de52eef0572667e726b6af0b2c010bce17cf5389344d714df6a", "Gateway": "", "GlobalIPv6Address": "", "GlobalIPv6PrefixLen": 0, "GwPriority": 0, "IPAMConfig": null, "IPAddress": "", "IPPrefixLen": 0, "IPv6Gateway": "", "Links": null, "MacAddress": "", "NetworkID": "268de73ef511b2a43769cd935946989dc6b40e46e052a834cd7d3cb969014641"}}, "Ports": {}, "SandboxID": "eebc1eabef9a40ae0033cb4479dffa446dbc6b58299d71376a192d6ac2d20977", "SandboxKey": "/var/run/docker/netns/default", "SecondaryIPAddresses": null, "SecondaryIPv6Addresses": null}, "Path": "/bin/prometheus", "Platform": "linux", "ProcessLabel": "", "ResolvConfPath": "/var/lib/docker/containers/335acfbb607384d0e37ad40e811f606747f9f8749e727307829f1164697fb634/resolv.conf", "RestartCount": 0, "State": {"Dead": false, "Error": "", "ExitCode": 0, "FinishedAt": "0001-01-01T00:00:00Z", "OOMKilled": false, "Paused": false, "Pid": 91228, "Restarting": false, "Running": true, "StartedAt": "2025-07-07T13:35:50.12405555Z", "Status": "running"}}}
2025-07-07 09:35:50,329 p=87684 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Grafana container (idempotency)] ****************
2025-07-07 09:35:50,826 p=87684 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:35:50,826 p=87684 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:35:50,840 p=87684 u=gpadmin n=ansible | TASK [monitoring : Create Grafana provisioning directories] *********************************
2025-07-07 09:35:51,139 p=87684 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/provisioning/datasources) => {"ansible_loop_var": "item", "changed": true, "gid": 472, "group": "472", "item": "/home/gpadmin/grafana_data/provisioning/datasources", "mode": "0755", "owner": "472", "path": "/home/gpadmin/grafana_data/provisioning/datasources", "size": 4096, "state": "directory", "uid": 472}
2025-07-07 09:35:51,423 p=87684 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/provisioning/dashboards) => {"ansible_loop_var": "item", "changed": true, "gid": 472, "group": "472", "item": "/home/gpadmin/grafana_data/provisioning/dashboards", "mode": "0755", "owner": "472", "path": "/home/gpadmin/grafana_data/provisioning/dashboards", "size": 4096, "state": "directory", "uid": 472}
2025-07-07 09:35:51,731 p=87684 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/dashboards) => {"ansible_loop_var": "item", "changed": true, "gid": 472, "group": "472", "item": "/home/gpadmin/grafana_data/dashboards", "mode": "0755", "owner": "472", "path": "/home/gpadmin/grafana_data/dashboards", "size": 4096, "state": "directory", "uid": 472}
2025-07-07 09:35:51,746 p=87684 u=gpadmin n=ansible | TASK [monitoring : Create Grafana datasource configuration] *********************************
2025-07-07 09:35:52,266 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "checksum": "cbc017b8085b7a05ad5acb8002bcc32b9defd608", "dest": "/home/gpadmin/grafana_data/provisioning/datasources/datasource.yml", "gid": 472, "group": "472", "md5sum": "4101ad7f2e415b1f02de9b1322f48c74", "mode": "0644", "owner": "472", "size": 158, "src": "/home/gpadmin/.ansible/tmp/ansible-tmp-1751895351.7829616-91659-177041756117763/source", "state": "file", "uid": 472}
2025-07-07 09:35:52,281 p=87684 u=gpadmin n=ansible | TASK [monitoring : Create Grafana dashboard provider configuration] *************************
2025-07-07 09:35:52,811 p=87684 u=gpadmin n=ansible | changed: [MASTER] => {"changed": true, "checksum": "937090cb704688e1cfaecb332ce8ec1c1e0a21a5", "dest": "/home/gpadmin/grafana_data/provisioning/dashboards/provider.yml", "gid": 472, "group": "472", "md5sum": "271e720b420040ec7f70e29f0725cac3", "mode": "0644", "owner": "472", "size": 242, "src": "/home/gpadmin/.ansible/tmp/ansible-tmp-1751895352.3175917-91709-198623402914050/source", "state": "file", "uid": 472}
2025-07-07 09:35:52,825 p=87684 u=gpadmin n=ansible | TASK [monitoring : Copy Grafana dashboards] *************************************************
2025-07-07 09:35:52,906 p=87684 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'instance' is undefined. 'instance' is undefined
2025-07-07 09:35:52,906 p=87684 u=gpadmin n=ansible | failed: [MASTER] (item=node-exporter-dashboard.json) => {"ansible_loop_var": "item", "changed": false, "item": "node-exporter-dashboard.json", "msg": "AnsibleUndefinedVariable: 'instance' is undefined. 'instance' is undefined"}
2025-07-07 09:35:52,955 p=87684 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'name' is undefined. 'name' is undefined
2025-07-07 09:35:52,955 p=87684 u=gpadmin n=ansible | failed: [MASTER] (item=docker-container-dashboard.json) => {"ansible_loop_var": "item", "changed": false, "item": "docker-container-dashboard.json", "msg": "AnsibleUndefinedVariable: 'name' is undefined. 'name' is undefined"}
2025-07-07 09:35:53,006 p=87684 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'name' is undefined. 'name' is undefined
2025-07-07 09:35:53,006 p=87684 u=gpadmin n=ansible | failed: [MASTER] (item=ray-cluster-dashboard.json) => {"ansible_loop_var": "item", "changed": false, "item": "ray-cluster-dashboard.json", "msg": "AnsibleUndefinedVariable: 'name' is undefined. 'name' is undefined"}
2025-07-07 09:35:53,009 p=87684 u=gpadmin n=ansible | PLAY RECAP **********************************************************************************
2025-07-07 09:35:53,009 p=87684 u=gpadmin n=ansible | G-241                      : ok=27   changed=8    unreachable=0    failed=1    skipped=5    rescued=0    ignored=4   
2025-07-07 09:35:53,009 p=87684 u=gpadmin n=ansible | G-242                      : ok=26   changed=8    unreachable=0    failed=1    skipped=5    rescued=0    ignored=4   
2025-07-07 09:35:53,010 p=87684 u=gpadmin n=ansible | G-243                      : ok=26   changed=8    unreachable=0    failed=1    skipped=5    rescued=0    ignored=4   
2025-07-07 09:35:53,010 p=87684 u=gpadmin n=ansible | G-244                      : ok=26   changed=8    unreachable=0    failed=1    skipped=5    rescued=0    ignored=4   
2025-07-07 09:35:53,010 p=87684 u=gpadmin n=ansible | MASTER                     : ok=36   changed=13   unreachable=0    failed=1    skipped=7    rescued=0    ignored=6   
2025-07-07 09:36:04,276 p=92188 u=gpadmin n=ansible | Using /home/gpadmin/cursor-projects/02-Ray-Deploy/ansible.cfg as config file
2025-07-07 09:36:04,561 p=92188 u=gpadmin n=ansible | PLAY [Test Docker Installation] ************************************************
2025-07-07 09:36:04,571 p=92188 u=gpadmin n=ansible | TASK [Gathering Facts] *********************************************************
2025-07-07 09:36:05,644 p=92188 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:36:05,684 p=92188 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:36:05,704 p=92188 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:36:05,724 p=92188 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:36:06,033 p=92188 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:36:06,112 p=92188 u=gpadmin n=ansible | TASK [docker : Check if Docker is available via which command] *****************
2025-07-07 09:36:06,389 p=92188 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "cmd": ["which", "docker"], "delta": "0:00:00.001331", "end": "2025-07-07 13:36:06.378430", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:06.377099", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:36:06,391 p=92188 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "cmd": ["which", "docker"], "delta": "0:00:00.001495", "end": "2025-07-07 13:36:06.378554", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:06.377059", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:36:06,392 p=92188 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "cmd": ["which", "docker"], "delta": "0:00:00.001393", "end": "2025-07-07 13:36:06.377780", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:06.376387", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:36:06,397 p=92188 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "cmd": ["which", "docker"], "delta": "0:00:00.001595", "end": "2025-07-07 13:36:06.385045", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:06.383450", "stderr": "", "stderr_lines": [], "stdout": "/snap/bin/docker", "stdout_lines": ["/snap/bin/docker"]}
2025-07-07 09:36:06,509 p=92188 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": ["which", "docker"], "delta": "0:00:00.005763", "end": "2025-07-07 09:36:06.467045", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 09:36:06.461282", "stderr": "", "stderr_lines": [], "stdout": "/usr/local/bin/docker", "stdout_lines": ["/usr/local/bin/docker"]}
2025-07-07 09:36:06,517 p=92188 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed via apt] ***************************
2025-07-07 09:36:06,706 p=92188 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "cmd": ["dpkg", "-l", "docker-ce"], "delta": "0:00:00.005675", "end": "2025-07-07 13:36:06.690392", "failed_when_result": false, "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:36:06.684717", "stderr": "dpkg-query: no packages found matching docker-ce", "stderr_lines": ["dpkg-query: no packages found matching docker-ce"], "stdout": "", "stdout_lines": []}
2025-07-07 09:36:06,715 p=92188 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "cmd": ["dpkg", "-l", "docker-ce"], "delta": "0:00:00.005398", "end": "2025-07-07 13:36:06.703556", "failed_when_result": false, "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:36:06.698158", "stderr": "dpkg-query: no packages found matching docker-ce", "stderr_lines": ["dpkg-query: no packages found matching docker-ce"], "stdout": "", "stdout_lines": []}
2025-07-07 09:36:06,721 p=92188 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "cmd": ["dpkg", "-l", "docker-ce"], "delta": "0:00:00.005232", "end": "2025-07-07 13:36:06.711604", "failed_when_result": false, "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:36:06.706372", "stderr": "dpkg-query: no packages found matching docker-ce", "stderr_lines": ["dpkg-query: no packages found matching docker-ce"], "stdout": "", "stdout_lines": []}
2025-07-07 09:36:06,755 p=92188 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "cmd": ["dpkg", "-l", "docker-ce"], "delta": "0:00:00.005085", "end": "2025-07-07 13:36:06.742977", "failed_when_result": false, "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 13:36:06.737892", "stderr": "dpkg-query: no packages found matching docker-ce", "stderr_lines": ["dpkg-query: no packages found matching docker-ce"], "stdout": "", "stdout_lines": []}
2025-07-07 09:36:06,841 p=92188 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": ["dpkg", "-l", "docker-ce"], "delta": "0:00:00.033474", "end": "2025-07-07 09:36:06.797697", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 09:36:06.764223", "stderr": "dpkg-query: warning: parsing file '/var/lib/dpkg/status' near line 8100 package 'goose':\n missing 'Maintainer' field", "stderr_lines": ["dpkg-query: warning: parsing file '/var/lib/dpkg/status' near line 8100 package 'goose':", " missing 'Maintainer' field"], "stdout": "Desired=Unknown/Install/Remove/Purge/Hold\n| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend\n|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)\n||/ Name           Version                       Architecture Description\n+++-==============-=============================-============-====================================================\nii  docker-ce      5:28.3.1-1~ubuntu.24.04~noble amd64        Docker: the open-source application container engine", "stdout_lines": ["Desired=Unknown/Install/Remove/Purge/Hold", "| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend", "|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)", "||/ Name           Version                       Architecture Description", "+++-==============-=============================-============-====================================================", "ii  docker-ce      5:28.3.1-1~ubuntu.24.04~noble amd64        Docker: the open-source application container engine"]}
2025-07-07 09:36:06,854 p=92188 u=gpadmin n=ansible | TASK [docker : Check if Docker is installed via snap] **************************
2025-07-07 09:36:07,054 p=92188 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "cmd": ["snap", "list", "docker"], "delta": "0:00:00.019819", "end": "2025-07-07 13:36:07.038306", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:07.018487", "stderr": "", "stderr_lines": [], "stdout": "Name    Version   Rev   Tracking       Publisher    Notes\ndocker  28.1.1+1  3265  latest/stable  canonical**  -", "stdout_lines": ["Name    Version   Rev   Tracking       Publisher    Notes", "docker  28.1.1+1  3265  latest/stable  canonical**  -"]}
2025-07-07 09:36:07,082 p=92188 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "cmd": ["snap", "list", "docker"], "delta": "0:00:00.020526", "end": "2025-07-07 13:36:07.069793", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:07.049267", "stderr": "", "stderr_lines": [], "stdout": "Name    Version   Rev   Tracking       Publisher    Notes\ndocker  28.1.1+1  3265  latest/stable  canonical**  -", "stdout_lines": ["Name    Version   Rev   Tracking       Publisher    Notes", "docker  28.1.1+1  3265  latest/stable  canonical**  -"]}
2025-07-07 09:36:07,092 p=92188 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "cmd": ["snap", "list", "docker"], "delta": "0:00:00.020219", "end": "2025-07-07 13:36:07.078090", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:07.057871", "stderr": "", "stderr_lines": [], "stdout": "Name    Version   Rev   Tracking       Publisher    Notes\ndocker  28.1.1+1  3265  latest/stable  canonical**  -", "stdout_lines": ["Name    Version   Rev   Tracking       Publisher    Notes", "docker  28.1.1+1  3265  latest/stable  canonical**  -"]}
2025-07-07 09:36:07,101 p=92188 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "cmd": ["snap", "list", "docker"], "delta": "0:00:00.020275", "end": "2025-07-07 13:36:07.090546", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:07.070271", "stderr": "", "stderr_lines": [], "stdout": "Name    Version   Rev   Tracking       Publisher    Notes\ndocker  28.1.1+1  3265  latest/stable  canonical**  -", "stdout_lines": ["Name    Version   Rev   Tracking       Publisher    Notes", "docker  28.1.1+1  3265  latest/stable  canonical**  -"]}
2025-07-07 09:36:07,190 p=92188 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": ["snap", "list", "docker"], "delta": "0:00:00.049066", "end": "2025-07-07 09:36:07.153351", "failed_when_result": false, "msg": "non-zero return code", "rc": 1, "start": "2025-07-07 09:36:07.104285", "stderr": "error: no matching snaps installed", "stderr_lines": ["error: no matching snaps installed"], "stdout": "", "stdout_lines": []}
2025-07-07 09:36:07,208 p=92188 u=gpadmin n=ansible | TASK [docker : Set Docker installation status facts] ***************************
2025-07-07 09:36:07,243 p=92188 u=gpadmin n=ansible | ok: [MASTER] => {"ansible_facts": {"docker_available": true, "docker_via_apt": true, "docker_via_snap": false}, "changed": false}
2025-07-07 09:36:07,257 p=92188 u=gpadmin n=ansible | ok: [G-241] => {"ansible_facts": {"docker_available": true, "docker_via_apt": false, "docker_via_snap": true}, "changed": false}
2025-07-07 09:36:07,273 p=92188 u=gpadmin n=ansible | ok: [G-242] => {"ansible_facts": {"docker_available": true, "docker_via_apt": false, "docker_via_snap": true}, "changed": false}
2025-07-07 09:36:07,276 p=92188 u=gpadmin n=ansible | ok: [G-243] => {"ansible_facts": {"docker_available": true, "docker_via_apt": false, "docker_via_snap": true}, "changed": false}
2025-07-07 09:36:07,287 p=92188 u=gpadmin n=ansible | ok: [G-244] => {"ansible_facts": {"docker_available": true, "docker_via_apt": false, "docker_via_snap": true}, "changed": false}
2025-07-07 09:36:07,298 p=92188 u=gpadmin n=ansible | TASK [docker : Display Docker installation status] *****************************
2025-07-07 09:36:07,333 p=92188 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": [
        "Docker available via which: True",
        "Docker installed via apt: True",
        "Docker installed via snap: False"
    ]
}
2025-07-07 09:36:07,349 p=92188 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": [
        "Docker available via which: True",
        "Docker installed via apt: False",
        "Docker installed via snap: True"
    ]
}
2025-07-07 09:36:07,365 p=92188 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": [
        "Docker available via which: True",
        "Docker installed via apt: False",
        "Docker installed via snap: True"
    ]
}
2025-07-07 09:36:07,367 p=92188 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": [
        "Docker available via which: True",
        "Docker installed via apt: False",
        "Docker installed via snap: True"
    ]
}
2025-07-07 09:36:07,384 p=92188 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": [
        "Docker available via which: True",
        "Docker installed via apt: False",
        "Docker installed via snap: True"
    ]
}
2025-07-07 09:36:07,393 p=92188 u=gpadmin n=ansible | TASK [docker : Add Docker GPG key] *********************************************
2025-07-07 09:36:07,427 p=92188 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,443 p=92188 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,457 p=92188 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,459 p=92188 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,467 p=92188 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,476 p=92188 u=gpadmin n=ansible | TASK [docker : Add Docker APT repository] **************************************
2025-07-07 09:36:07,514 p=92188 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,529 p=92188 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,546 p=92188 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,547 p=92188 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,559 p=92188 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,568 p=92188 u=gpadmin n=ansible | TASK [docker : Update apt cache after adding Docker repository] ****************
2025-07-07 09:36:07,602 p=92188 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,617 p=92188 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,632 p=92188 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,632 p=92188 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,643 p=92188 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,652 p=92188 u=gpadmin n=ansible | TASK [docker : Install Docker Engine via APT] **********************************
2025-07-07 09:36:07,686 p=92188 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,703 p=92188 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,723 p=92188 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,723 p=92188 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,736 p=92188 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "not docker_available and not docker_via_snap", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:07,745 p=92188 u=gpadmin n=ansible | TASK [docker : Check Docker service status (systemd)] **************************
2025-07-07 09:36:07,917 p=92188 u=gpadmin n=ansible | ok: [G-241] => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003183", "end": "2025-07-07 13:36:07.902067", "failed_when_result": false, "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:36:07.898884", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:36:07,944 p=92188 u=gpadmin n=ansible | ok: [G-243] => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003090", "end": "2025-07-07 13:36:07.935145", "failed_when_result": false, "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:36:07.932055", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:36:07,945 p=92188 u=gpadmin n=ansible | ok: [G-242] => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003227", "end": "2025-07-07 13:36:07.933690", "failed_when_result": false, "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:36:07.930463", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:36:07,959 p=92188 u=gpadmin n=ansible | ok: [G-244] => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.003178", "end": "2025-07-07 13:36:07.946843", "failed_when_result": false, "msg": "non-zero return code", "rc": 4, "start": "2025-07-07 13:36:07.943665", "stderr": "", "stderr_lines": [], "stdout": "inactive", "stdout_lines": ["inactive"]}
2025-07-07 09:36:08,059 p=92188 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "cmd": ["systemctl", "is-active", "docker"], "delta": "0:00:00.011250", "end": "2025-07-07 09:36:08.015223", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 09:36:08.003973", "stderr": "", "stderr_lines": [], "stdout": "active", "stdout_lines": ["active"]}
2025-07-07 09:36:08,071 p=92188 u=gpadmin n=ansible | TASK [docker : Start Docker service (systemd)] *********************************
2025-07-07 09:36:08,129 p=92188 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "docker_via_apt or (docker_apt_install is defined and docker_apt_install.changed)", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,144 p=92188 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "docker_via_apt or (docker_apt_install is defined and docker_apt_install.changed)", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,148 p=92188 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "docker_via_apt or (docker_apt_install is defined and docker_apt_install.changed)", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,157 p=92188 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "docker_via_apt or (docker_apt_install is defined and docker_apt_install.changed)", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,791 p=92188 u=gpadmin n=ansible | ok: [MASTER] => {"changed": false, "enabled": true, "name": "docker", "state": "started", "status": {"ActiveEnterTimestamp": "Sat 2025-07-05 12:10:24 EDT", "ActiveEnterTimestampMonotonic": "14500501", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "time-set.target network-online.target system.slice basic.target nss-lookup.target docker.socket firewalld.service systemd-journald.socket containerd.service sysinit.target", "AllowIsolate": "no", "AssertResult": "yes", "AssertTimestamp": "Sat 2025-07-05 12:10:23 EDT", "AssertTimestampMonotonic": "13516583", "Before": "shutdown.target multi-user.target", "BlockIOAccounting": "no", "BlockIOWeight": "[not set]", "CPUAccounting": "yes", "CPUAffinityFromNUMA": "no", "CPUQuotaPerSecUSec": "infinity", "CPUQuotaPeriodUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "[not set]", "CPUUsageNSec": "100987328000", "CPUWeight": "[not set]", "CacheDirectoryMode": "0755", "CanFreeze": "yes", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore", "CleanResult": "success", "CollectMode": "inactive", "ConditionResult": "yes", "ConditionTimestamp": "Sat 2025-07-05 12:10:23 EDT", "ConditionTimestampMonotonic": "13516581", "ConfigurationDirectoryMode": "0755", "Conflicts": "shutdown.target", "ControlGroup": "/system.slice/docker.service", "ControlGroupId": "7651", "ControlPID": "0", "CoredumpFilter": "0x33", "CoredumpReceive": "no", "DefaultDependencies": "yes", "DefaultMemoryLow": "0", "DefaultMemoryMin": "0", "DefaultStartupMemoryLow": "0", "Delegate": "yes", "DelegateControllers": "cpu cpuset io memory pids", "Description": "Docker Application Container Engine", "DevicePolicy": "auto", "Documentation": "https://docs.docker.com", "DynamicUser": "no", "EffectiveCPUs": "0-31", "EffectiveMemoryNodes": "0", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "2018", "ExecMainStartTimestamp": "Sat 2025-07-05 12:10:23 EDT", "ExecMainStartTimestampMonotonic": "13518391", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecReloadEx": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/bin/dockerd ; argv[]=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStartEx": "{ path=/usr/bin/dockerd ; argv[]=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExitType": "main", "ExtensionImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FileDescriptorStorePreserve": "restart", "FinalKillSignal": "9", "FragmentPath": "/usr/lib/systemd/system/docker.service", "FreezerState": "running", "GID": "[not set]", "GuessMainPID": "yes", "IOAccounting": "no", "IOReadBytes": "[not set]", "IOReadOperations": "[not set]", "IOSchedulingClass": "2", "IOSchedulingPriority": "4", "IOWeight": "[not set]", "IOWriteBytes": "[not set]", "IOWriteOperations": "[not set]", "IPAccounting": "no", "IPEgressBytes": "[no data]", "IPEgressPackets": "[no data]", "IPIngressBytes": "[no data]", "IPIngressPackets": "[no data]", "Id": "docker.service", "IgnoreOnIsolate": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Sat 2025-07-05 12:10:23 EDT", "InactiveExitTimestampMonotonic": "13518558", "InvocationID": "efe8e95911d1408482a24e5be07cc2d7", "JobRunningTimeoutUSec": "infinity", "JobTimeoutAction": "none", "JobTimeoutUSec": "infinity", "KeyringMode": "private", "KillMode": "process", "KillSignal": "15", "LimitAS": "infinity", "LimitASSoft": "infinity", "LimitCORE": "infinity", "LimitCORESoft": "infinity", "LimitCPU": "infinity", "LimitCPUSoft": "infinity", "LimitDATA": "infinity", "LimitDATASoft": "infinity", "LimitFSIZE": "infinity", "LimitFSIZESoft": "infinity", "LimitLOCKS": "infinity", "LimitLOCKSSoft": "infinity", "LimitMEMLOCK": "8388608", "LimitMEMLOCKSoft": "8388608", "LimitMSGQUEUE": "819200", "LimitMSGQUEUESoft": "819200", "LimitNICE": "0", "LimitNICESoft": "0", "LimitNOFILE": "524288", "LimitNOFILESoft": "1024", "LimitNPROC": "infinity", "LimitNPROCSoft": "infinity", "LimitRSS": "infinity", "LimitRSSSoft": "infinity", "LimitRTPRIO": "0", "LimitRTPRIOSoft": "0", "LimitRTTIME": "infinity", "LimitRTTIMESoft": "infinity", "LimitSIGPENDING": "514099", "LimitSIGPENDINGSoft": "514099", "LimitSTACK": "infinity", "LimitSTACKSoft": "8388608", "LoadState": "loaded", "LockPersonality": "no", "LogLevelMax": "-1", "LogRateLimitBurst": "0", "LogRateLimitIntervalUSec": "0", "LogsDirectoryMode": "0755", "MainPID": "2018", "ManagedOOMMemoryPressure": "auto", "ManagedOOMMemoryPressureLimit": "0", "ManagedOOMPreference": "none", "ManagedOOMSwap": "auto", "MemoryAccounting": "yes", "MemoryAvailable": "125916033024", "MemoryCurrent": "3118706688", "MemoryDenyWriteExecute": "no", "MemoryHigh": "infinity", "MemoryKSM": "no", "MemoryLimit": "infinity", "MemoryLow": "0", "MemoryMax": "infinity", "MemoryMin": "0", "MemoryPeak": "3166384128", "MemoryPressureThresholdUSec": "200ms", "MemoryPressureWatch": "auto", "MemorySwapCurrent": "0", "MemorySwapMax": "infinity", "MemorySwapPeak": "0", "MemoryZSwapCurrent": "0", "MemoryZSwapMax": "infinity", "MountAPIVFS": "no", "MountImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "NFileDescriptorStore": "0", "NRestarts": "0", "NUMAPolicy": "n/a", "Names": "docker.service", "NeedDaemonReload": "yes", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMPolicy": "continue", "OOMScoreAdjust": "-500", "OnFailureJobMode": "replace", "OnSuccessJobMode": "fail", "Perpetual": "no", "PrivateDevices": "no", "PrivateIPC": "no", "PrivateMounts": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "PrivateUsers": "no", "ProcSubset": "all", "ProtectClock": "no", "ProtectControlGroups": "no", "ProtectHome": "no", "ProtectHostname": "no", "ProtectKernelLogs": "no", "ProtectKernelModules": "no", "ProtectKernelTunables": "no", "ProtectProc": "default", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "ReloadResult": "success", "ReloadSignal": "1", "RemainAfterExit": "no", "RemoveIPC": "no", "Requires": "sysinit.target docker.socket system.slice", "Restart": "always", "RestartKillSignal": "15", "RestartMaxDelayUSec": "infinity", "RestartMode": "normal", "RestartSteps": "0", "RestartUSec": "2s", "RestartUSecNext": "2s", "RestrictNamespaces": "no", "RestrictRealtime": "no", "RestrictSUIDSGID": "no", "Result": "success", "RootDirectoryStartOnly": "no", "RootEphemeral": "no", "RootImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent", "RuntimeDirectoryMode": "0755", "RuntimeDirectoryPreserve": "no", "RuntimeMaxUSec": "infinity", "RuntimeRandomizedExtraUSec": "0", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "SetLoginEnvironment": "no", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "3", "StartLimitIntervalUSec": "1min", "StartupBlockIOWeight": "[not set]", "StartupCPUShares": "[not set]", "StartupCPUWeight": "[not set]", "StartupIOWeight": "[not set]", "StartupMemoryHigh": "infinity", "StartupMemoryLow": "0", "StartupMemoryMax": "infinity", "StartupMemorySwapMax": "infinity", "StartupMemoryZSwapMax": "infinity", "StateChangeTimestamp": "Sat 2025-07-05 12:10:24 EDT", "StateChangeTimestampMonotonic": "14500501", "StateDirectoryMode": "0755", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SuccessAction": "none", "SurviveFinalKillSignal": "no", "SyslogFacility": "3", "SyslogLevel": "6", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "2147483646", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "yes", "TasksCurrent": "34", "TasksMax": "infinity", "TimeoutAbortUSec": "1min 30s", "TimeoutCleanUSec": "infinity", "TimeoutStartFailureMode": "terminate", "TimeoutStartUSec": "infinity", "TimeoutStopFailureMode": "terminate", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "TriggeredBy": "docker.socket", "Type": "notify", "UID": "[not set]", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "UtmpMode": "init", "WantedBy": "multi-user.target", "Wants": "containerd.service network-online.target", "WatchdogSignal": "6", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2025-07-07 09:36:08,808 p=92188 u=gpadmin n=ansible | TASK [docker : Install Docker via snap if not installed via apt] ***************
2025-07-07 09:36:08,836 p=92188 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "not docker_available and not docker_via_apt", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,852 p=92188 u=gpadmin n=ansible | skipping: [G-241] => {"changed": false, "false_condition": "not docker_available and not docker_via_apt", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,884 p=92188 u=gpadmin n=ansible | skipping: [G-242] => {"changed": false, "false_condition": "not docker_available and not docker_via_apt", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,884 p=92188 u=gpadmin n=ansible | skipping: [G-243] => {"changed": false, "false_condition": "not docker_available and not docker_via_apt", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,896 p=92188 u=gpadmin n=ansible | skipping: [G-244] => {"changed": false, "false_condition": "not docker_available and not docker_via_apt", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,906 p=92188 u=gpadmin n=ansible | TASK [docker : Wait for snap Docker installation to complete] ******************
2025-07-07 09:36:08,925 p=92188 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_snap_install is defined and docker_snap_install.changed", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:08,934 p=92188 u=gpadmin n=ansible | TASK [docker : Wait for any in-progress snap operations to complete] ***********
2025-07-07 09:36:08,968 p=92188 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_via_snap or (docker_snap_install is defined and docker_snap_install.changed)", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:09,128 p=92188 u=gpadmin n=ansible | ok: [G-241] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.013732", "end": "2025-07-07 13:36:09.110927", "msg": "", "rc": 0, "start": "2025-07-07 13:36:09.097195", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:36:09,149 p=92188 u=gpadmin n=ansible | ok: [G-242] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.014286", "end": "2025-07-07 13:36:09.136122", "msg": "", "rc": 0, "start": "2025-07-07 13:36:09.121836", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:36:09,153 p=92188 u=gpadmin n=ansible | ok: [G-243] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.013834", "end": "2025-07-07 13:36:09.141738", "msg": "", "rc": 0, "start": "2025-07-07 13:36:09.127904", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:36:09,178 p=92188 u=gpadmin n=ansible | ok: [G-244] => {"attempts": 1, "changed": false, "cmd": "snap changes | grep -q 'Doing.*docker' && sleep 5 || echo 'No in-progress changes'", "delta": "0:00:00.013917", "end": "2025-07-07 13:36:09.163961", "msg": "", "rc": 0, "start": "2025-07-07 13:36:09.150044", "stderr": "", "stderr_lines": [], "stdout": "No in-progress changes", "stdout_lines": ["No in-progress changes"]}
2025-07-07 09:36:09,192 p=92188 u=gpadmin n=ansible | TASK [docker : Start Docker service (snap)] ************************************
2025-07-07 09:36:09,227 p=92188 u=gpadmin n=ansible | skipping: [MASTER] => {"changed": false, "false_condition": "docker_via_snap or (docker_snap_install is defined and docker_snap_install.changed)", "skip_reason": "Conditional result was False"}
2025-07-07 09:36:09,550 p=92188 u=gpadmin n=ansible | changed: [G-241] => {"changed": true, "cmd": ["snap", "start", "docker"], "delta": "0:00:00.154072", "end": "2025-07-07 13:36:09.534312", "failed_when_result": false, "msg": "", "rc": 0, "start": "2025-07-07 13:36:09.380240", "stderr": "", "stderr_lines": [], "stdout": "Started.", "stdout_lines": ["Started."]}
2025-07-07 09:36:30,596 p=92188 u=gpadmin n=ansible |  [ERROR]: User interrupted execution

2025-07-07 09:37:00,640 p=93542 u=gpadmin n=ansible | G-241 | CHANGED | rc=0 >>
Docker version 28.1.1+1, build 068a01e

2025-07-07 09:37:00,642 p=93542 u=gpadmin n=ansible | G-243 | CHANGED | rc=0 >>
Docker version 28.1.1+1, build 068a01e

2025-07-07 09:37:00,655 p=93542 u=gpadmin n=ansible | G-244 | CHANGED | rc=0 >>
Docker version 28.1.1+1, build 068a01e

2025-07-07 09:37:00,672 p=93542 u=gpadmin n=ansible | G-242 | CHANGED | rc=0 >>
Docker version 28.1.1+1, build 068a01e

2025-07-07 09:37:00,720 p=93542 u=gpadmin n=ansible | MASTER | CHANGED | rc=0 >>
Docker version 28.3.1, build 38b7060

2025-07-07 09:37:06,151 p=93676 u=gpadmin n=ansible | MASTER | CHANGED | rc=0 >>
Client: Docker Engine - Community
 Version:    28.3.1
 Context:    default
 Debug Mode: false
 Plugins:
  ai: Docker AI Agent - Ask Gordon (Docker Inc.)
    Version:  v1.6.0
    Path:     /usr/lib/docker/cli-plugins/docker-ai
  buildx: Docker Buildx (Docker Inc.)
    Version:  v0.25.0-desktop.1
    Path:     /usr/lib/docker/cli-plugins/docker-buildx
  cloud: Docker Cloud (Docker Inc.)
    Version:  v0.4.2
    Path:     /usr/lib/docker/cli-plugins/docker-cloud
  compose: Docker Compose (Docker Inc.)
    Version:  v2.38.1-desktop.1
    Path:     /usr/lib/docker/cli-plugins/docker-compose
  debug: Get a shell into any image or container (Docker Inc.)
    Version:  0.0.41
    Path:     /usr/lib/docker/cli-plugins/docker-debug
  desktop: Docker Desktop commands (Docker Inc.)
    Version:  v0.1.11
    Path:     /usr/lib/docker/cli-plugins/docker-desktop
  extension: Manages Docker extensions (Docker Inc.)
    Version:  v0.2.29
    Path:     /usr/lib/docker/cli-plugins/docker-extension
  init: Creates Docker-related starter files for your project (Docker Inc.)
    Version:  v1.4.0
    Path:     /usr/lib/docker/cli-plugins/docker-init
  mcp: Docker MCP Plugin (Docker Inc.)
    Version:  v0.9.3
    Path:     /usr/lib/docker/cli-plugins/docker-mcp
  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc.)
    Version:  0.6.0
    Path:     /usr/lib/docker/cli-plugins/docker-sbom
  scout: Docker Scout (Docker Inc.)
    Version:  v1.18.1
    Path:     /usr/lib/docker/cli-plugins/docker-scout

Server:
 Containers: 4
  Running: 3
  Paused: 0
  Stopped: 1
 Images: 5
 Server Version: 28.3.1
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Using metacopy: false
  Native Overlay Diff: true
  userxattr: false
 Logging Driver: json-file
 Cgroup Driver: systemd
 Cgroup Version: 2
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local splunk syslog
 CDI spec directories:
  /etc/cdi
  /var/run/cdi
 Swarm: inactive
 Runtimes: nvidia runc io.containerd.runc.v2
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 05044ec0a9a75232cad458027ca83437aae3f4da
 runc version: v1.2.5-0-g59923ef
 init version: de40ad0
 Security Options:
  apparmor
  seccomp
   Profile: builtin
  cgroupns
 Kernel Version: 6.11.0-29-generic
 Operating System: Ubuntu 24.04.2 LTS
 OSType: linux
 Architecture: x86_64
 CPUs: 32
 Total Memory: 125.7GiB
 Name: G-K3S-Master
 ID: af7f080b-452c-4cde-ba9f-5a831e784149
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Experimental: false
 Insecure Registries:
  ::1/128
  127.0.0.0/8
 Live Restore Enabled: false

2025-07-07 09:37:07,302 p=93676 u=gpadmin n=ansible | G-244 | CHANGED | rc=0 >>
Client:
 Version:    28.1.1+1
 Context:    default
 Debug Mode: false
 Plugins:
  buildx: Docker Buildx (Docker Inc.)
    Version:  v0.20.1
    Path:     /usr/libexec/docker/cli-plugins/docker-buildx
  compose: Docker Compose (Docker Inc.)
    Version:  v2.33.1
    Path:     /usr/libexec/docker/cli-plugins/docker-compose

Server:
 Containers: 3
  Running: 2
  Paused: 0
  Stopped: 1
 Images: 3
 Server Version: 28.1.1+1
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Using metacopy: false
  Native Overlay Diff: true
  userxattr: false
 Logging Driver: json-file
 Cgroup Driver: systemd
 Cgroup Version: 2
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local splunk syslog
 Swarm: inactive
 Runtimes: io.containerd.runc.v2 runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 05044ec0a9a75232cad458027ca83437aae3f4da
 runc version: 
 init version: de40ad0
 Security Options:
  apparmor
  seccomp
   Profile: builtin
  cgroupns
 Kernel Version: 6.8.0-63-generic
 Operating System: Ubuntu Core 22
 OSType: linux
 Architecture: x86_64
 CPUs: 16
 Total Memory: 125.6GiB
 Name: g-244
 ID: 1848662b-1893-4835-914c-845e72adb198
 Docker Root Dir: /var/snap/docker/common/var-lib-docker
 Debug Mode: false
 Experimental: false
 Insecure Registries:
  ::1/128
  127.0.0.0/8
 Live Restore Enabled: false

2025-07-07 09:37:07,303 p=93676 u=gpadmin n=ansible | G-243 | CHANGED | rc=0 >>
Client:
 Version:    28.1.1+1
 Context:    default
 Debug Mode: false
 Plugins:
  buildx: Docker Buildx (Docker Inc.)
    Version:  v0.20.1
    Path:     /usr/libexec/docker/cli-plugins/docker-buildx
  compose: Docker Compose (Docker Inc.)
    Version:  v2.33.1
    Path:     /usr/libexec/docker/cli-plugins/docker-compose

Server:
 Containers: 3
  Running: 2
  Paused: 0
  Stopped: 1
 Images: 3
 Server Version: 28.1.1+1
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Using metacopy: false
  Native Overlay Diff: true
  userxattr: false
 Logging Driver: json-file
 Cgroup Driver: systemd
 Cgroup Version: 2
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local splunk syslog
 Swarm: inactive
 Runtimes: io.containerd.runc.v2 runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 05044ec0a9a75232cad458027ca83437aae3f4da
 runc version: 
 init version: de40ad0
 Security Options:
  apparmor
  seccomp
   Profile: builtin
  cgroupns
 Kernel Version: 6.8.0-63-generic
 Operating System: Ubuntu Core 22
 OSType: linux
 Architecture: x86_64
 CPUs: 16
 Total Memory: 125.6GiB
 Name: g-243
 ID: 02b692aa-98e9-472a-939b-51124f2e78b0
 Docker Root Dir: /var/snap/docker/common/var-lib-docker
 Debug Mode: false
 Experimental: false
 Insecure Registries:
  ::1/128
  127.0.0.0/8
 Live Restore Enabled: false

2025-07-07 09:37:07,304 p=93676 u=gpadmin n=ansible | G-241 | CHANGED | rc=0 >>
Client:
 Version:    28.1.1+1
 Context:    default
 Debug Mode: false
 Plugins:
  buildx: Docker Buildx (Docker Inc.)
    Version:  v0.20.1
    Path:     /usr/libexec/docker/cli-plugins/docker-buildx
  compose: Docker Compose (Docker Inc.)
    Version:  v2.33.1
    Path:     /usr/libexec/docker/cli-plugins/docker-compose

Server:
 Containers: 3
  Running: 2
  Paused: 0
  Stopped: 1
 Images: 3
 Server Version: 28.1.1+1
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Using metacopy: false
  Native Overlay Diff: true
  userxattr: false
 Logging Driver: json-file
 Cgroup Driver: systemd
 Cgroup Version: 2
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local splunk syslog
 Swarm: inactive
 Runtimes: runc io.containerd.runc.v2 nvidia
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 05044ec0a9a75232cad458027ca83437aae3f4da
 runc version: 
 init version: de40ad0
 Security Options:
  apparmor
  seccomp
   Profile: builtin
  cgroupns
 Kernel Version: 6.8.0-63-generic
 Operating System: Ubuntu Core 22
 OSType: linux
 Architecture: x86_64
 CPUs: 16
 Total Memory: 125.6GiB
 Name: g-241
 ID: 33a898e7-6247-45e3-8105-8fc4cb4c9a8d
 Docker Root Dir: /var/snap/docker/common/var-lib-docker
 Debug Mode: false
 Experimental: false
 Insecure Registries:
  ::1/128
  127.0.0.0/8
 Live Restore Enabled: false

2025-07-07 09:37:07,314 p=93676 u=gpadmin n=ansible | G-242 | CHANGED | rc=0 >>
Client:
 Version:    28.1.1+1
 Context:    default
 Debug Mode: false
 Plugins:
  buildx: Docker Buildx (Docker Inc.)
    Version:  v0.20.1
    Path:     /usr/libexec/docker/cli-plugins/docker-buildx
  compose: Docker Compose (Docker Inc.)
    Version:  v2.33.1
    Path:     /usr/libexec/docker/cli-plugins/docker-compose

Server:
 Containers: 3
  Running: 2
  Paused: 0
  Stopped: 1
 Images: 3
 Server Version: 28.1.1+1
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Using metacopy: false
  Native Overlay Diff: true
  userxattr: false
 Logging Driver: json-file
 Cgroup Driver: systemd
 Cgroup Version: 2
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local splunk syslog
 Swarm: inactive
 Runtimes: io.containerd.runc.v2 runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 05044ec0a9a75232cad458027ca83437aae3f4da
 runc version: 
 init version: de40ad0
 Security Options:
  apparmor
  seccomp
   Profile: builtin
  cgroupns
 Kernel Version: 6.8.0-63-generic
 Operating System: Ubuntu Core 22
 OSType: linux
 Architecture: x86_64
 CPUs: 16
 Total Memory: 125.6GiB
 Name: g-242
 ID: 8e4ab29c-4a92-464b-a056-1f2f03739d0a
 Docker Root Dir: /var/snap/docker/common/var-lib-docker
 Debug Mode: false
 Experimental: false
 Insecure Registries:
  ::1/128
  127.0.0.0/8
 Live Restore Enabled: false

2025-07-07 09:37:16,034 p=94080 u=gpadmin n=ansible | G-242 | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                       COMMAND                  CREATED              STATUS              PORTS     NAMES
c04598c908e5   prom/node-exporter:v1.6.1   "/bin/node_exporter …"   About a minute ago   Up About a minute             node-exporter
7fbaa9e64aad   rayproject/ray:2.9.0        "/home/gpadmin/ray_t…"   About a minute ago   Up About a minute             ray_worker

2025-07-07 09:37:16,038 p=94080 u=gpadmin n=ansible | G-241 | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                       COMMAND                  CREATED              STATUS              PORTS     NAMES
9b79793063ea   prom/node-exporter:v1.6.1   "/bin/node_exporter …"   About a minute ago   Up About a minute             node-exporter
ae21478cc53a   rayproject/ray:2.9.0        "/home/gpadmin/ray_t…"   About a minute ago   Up About a minute             ray_worker

2025-07-07 09:37:16,039 p=94080 u=gpadmin n=ansible | G-243 | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                       COMMAND                  CREATED              STATUS              PORTS     NAMES
35590ea5ea68   prom/node-exporter:v1.6.1   "/bin/node_exporter …"   About a minute ago   Up About a minute             node-exporter
28d337ef57bd   rayproject/ray:2.9.0        "/home/gpadmin/ray_t…"   About a minute ago   Up About a minute             ray_worker

2025-07-07 09:37:16,063 p=94080 u=gpadmin n=ansible | G-244 | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                       COMMAND                  CREATED              STATUS              PORTS     NAMES
54fb99bb27ad   prom/node-exporter:v1.6.1   "/bin/node_exporter …"   About a minute ago   Up About a minute             node-exporter
56ce0f34b799   rayproject/ray:2.9.0        "/home/gpadmin/ray_t…"   About a minute ago   Up About a minute             ray_worker

2025-07-07 09:37:16,112 p=94080 u=gpadmin n=ansible | MASTER | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                              COMMAND                  CREATED              STATUS                          PORTS     NAMES
335acfbb6073   prom/prometheus:v2.45.0            "/bin/prometheus --c…"   About a minute ago   Restarting (2) 32 seconds ago             prometheus
2d12943bbe8b   gcr.io/cadvisor/cadvisor:v0.47.2   "/usr/bin/cadvisor -…"   About a minute ago   Up About a minute (unhealthy)             cadvisor
bd6731114332   prom/node-exporter:v1.6.1          "/bin/node_exporter …"   About a minute ago   Up About a minute                         node-exporter
a30361101b64   rayproject/ray:2.9.0               "/home/gpadmin/ray_t…"   2 minutes ago        Up 2 minutes                              ray_head

2025-07-07 09:37:27,894 p=94310 u=gpadmin n=ansible | MASTER | CHANGED | rc=0 >>
ts=2025-07-07T13:35:50.264Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:35:50.264Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:35:50.264Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:35:50.264Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:35:50.264Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:35:50.264Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:35:50.265Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7ffe15f63ee0, 0xb}, 0x14, {0x3d0af20, 0xc000c83270})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:35:50.580Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:35:50.580Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:35:50.580Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:35:50.580Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:35:50.581Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:35:50.581Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:35:50.581Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7ffea3a6fee0, 0xb}, 0x14, {0x3d0af20, 0xc000d8f3b0})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:35:50.977Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:35:50.977Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:35:50.977Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:35:50.977Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:35:50.977Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:35:50.977Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:35:50.978Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7fff91dfeee0, 0xb}, 0x14, {0x3d0af20, 0xc000a82dc0})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:35:51.575Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:35:51.575Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:35:51.575Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:35:51.575Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:35:51.575Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:35:51.575Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:35:51.575Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7fff543abee0, 0xb}, 0x14, {0x3d0af20, 0xc0005b06e0})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:35:52.572Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:35:52.572Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:35:52.572Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:35:52.572Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:35:52.572Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:35:52.572Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:35:52.572Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7ffca8f62ee0, 0xb}, 0x14, {0x3d0af20, 0xc000c9b040})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:35:54.362Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:35:54.362Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:35:54.362Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:35:54.362Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:35:54.362Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:35:54.362Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:35:54.362Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7ffe128cbee0, 0xb}, 0x14, {0x3d0af20, 0xc000da3310})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:35:57.784Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:35:57.784Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:35:57.784Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:35:57.784Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:35:57.784Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:35:57.784Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:35:57.784Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7ffef24c3ee0, 0xb}, 0x14, {0x3d0af20, 0xc000532870})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:36:04.389Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:36:04.389Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:36:04.389Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:36:04.389Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:36:04.389Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:36:04.389Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:36:04.389Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7ffd329daee0, 0xb}, 0x14, {0x3d0af20, 0xc000286870})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:36:17.397Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:36:17.397Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:36:17.397Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:36:17.397Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:36:17.397Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:36:17.397Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:36:17.397Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7fff7b03aee0, 0xb}, 0x14, {0x3d0af20, 0xc000e0d360})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013
ts=2025-07-07T13:36:43.204Z caller=main.go:534 level=info msg="No time or size retention was set so using the default time retention" duration=15d
ts=2025-07-07T13:36:43.204Z caller=main.go:578 level=info msg="Starting Prometheus Server" mode=server version="(version=2.45.0, branch=HEAD, revision=8ef767e396bf8445f009f945b0162fd71827f445)"
ts=2025-07-07T13:36:43.204Z caller=main.go:583 level=info build_context="(go=go1.20.5, platform=linux/amd64, user=root@920118f645b7, date=20230623-15:09:49, tags=netgo,builtinassets,stringlabels)"
ts=2025-07-07T13:36:43.205Z caller=main.go:584 level=info host_details="(Linux 6.11.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jun 26 14:16:59 UTC 2 x86_64 G-K3S-Master (none))"
ts=2025-07-07T13:36:43.205Z caller=main.go:585 level=info fd_limits="(soft=1048576, hard=1048576)"
ts=2025-07-07T13:36:43.205Z caller=main.go:586 level=info vm_limits="(soft=unlimited, hard=unlimited)"
ts=2025-07-07T13:36:43.205Z caller=query_logger.go:91 level=error component=activeQueryTracker msg="Error opening query log file" file=/prometheus/queries.active err="open /prometheus/queries.active: permission denied"
panic: Unable to create mmap-ed active query log

goroutine 1 [running]:
github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0x7ffd39d34ee0, 0xb}, 0x14, {0x3d0af20, 0xc00073f770})
	/app/promql/query_logger.go:121 +0x3cd
main.main()
	/app/cmd/prometheus/main.go:640 +0x7013

2025-07-07 09:38:12,571 p=94823 u=gpadmin n=ansible | ERROR! 'ansible.builtin.file' is not a valid attribute for a Play

The error appears to be in '/home/gpadmin/cursor-projects/02-Ray-Deploy/roles/monitoring/tasks/main.yml': line 4, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: Create Prometheus data directory
  ^ here

2025-07-07 09:39:46,138 p=95771 u=gpadmin n=ansible | PLAY [Fix Monitoring Permissions] *********************************************************
2025-07-07 09:39:46,147 p=95771 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:39:47,617 p=95771 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:39:47,653 p=95771 u=gpadmin n=ansible | TASK [Stop all monitoring containers] *****************************************************
2025-07-07 09:39:48,305 p=95771 u=gpadmin n=ansible | failed: [MASTER] (item=prometheus) => {"ansible_loop_var": "item", "changed": false, "item": "prometheus", "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:39:48,749 p=95771 u=gpadmin n=ansible | failed: [MASTER] (item=grafana) => {"ansible_loop_var": "item", "changed": false, "item": "grafana", "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:39:48,751 p=95771 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:39:48,765 p=95771 u=gpadmin n=ansible | TASK [Fix Prometheus data directory permissions] ******************************************
2025-07-07 09:39:49,200 p=95771 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:39:49,208 p=95771 u=gpadmin n=ansible | TASK [Fix Grafana data directory permissions] *********************************************
2025-07-07 09:39:49,485 p=95771 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:39:49,499 p=95771 u=gpadmin n=ansible | TASK [Restart monitoring containers] ******************************************************
2025-07-07 09:39:49,560 p=95771 u=gpadmin n=ansible | TASK [monitoring : Create Prometheus data directory] **************************************
2025-07-07 09:39:49,881 p=95771 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:39:49,895 p=95771 u=gpadmin n=ansible | TASK [monitoring : Create Grafana data directory] *****************************************
2025-07-07 09:39:50,206 p=95771 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:39:50,220 p=95771 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Node Exporter container (idempotency)] ********
2025-07-07 09:39:50,667 p=95771 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:39:50,667 p=95771 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:39:50,681 p=95771 u=gpadmin n=ansible | TASK [monitoring : Start Node Exporter container] *****************************************
2025-07-07 09:39:51,188 p=95771 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:39:51,201 p=95771 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing cAdvisor container (idempotency)] *************
2025-07-07 09:39:51,698 p=95771 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:39:51,699 p=95771 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:39:51,712 p=95771 u=gpadmin n=ansible | TASK [monitoring : Start cAdvisor container] **********************************************
2025-07-07 09:39:52,240 p=95771 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:39:52,257 p=95771 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Prometheus container (idempotency)] ***********
2025-07-07 09:39:52,736 p=95771 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:39:52,736 p=95771 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:39:52,750 p=95771 u=gpadmin n=ansible | TASK [monitoring : Create Prometheus configuration] ***************************************
2025-07-07 09:39:53,407 p=95771 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:39:53,422 p=95771 u=gpadmin n=ansible | TASK [monitoring : Start Prometheus container] ********************************************
2025-07-07 09:39:53,941 p=95771 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:39:53,952 p=95771 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Grafana container (idempotency)] **************
2025-07-07 09:39:54,440 p=95771 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:39:54,440 p=95771 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:39:54,455 p=95771 u=gpadmin n=ansible | TASK [monitoring : Create Grafana provisioning directories] *******************************
2025-07-07 09:39:54,749 p=95771 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/provisioning/datasources)
2025-07-07 09:39:55,013 p=95771 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/provisioning/dashboards)
2025-07-07 09:39:55,302 p=95771 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/dashboards)
2025-07-07 09:39:55,317 p=95771 u=gpadmin n=ansible | TASK [monitoring : Create Grafana datasource configuration] *******************************
2025-07-07 09:39:55,877 p=95771 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:39:55,892 p=95771 u=gpadmin n=ansible | TASK [monitoring : Create Grafana dashboard provider configuration] ***********************
2025-07-07 09:39:56,423 p=95771 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:39:56,436 p=95771 u=gpadmin n=ansible | TASK [monitoring : Copy Grafana dashboards] ***********************************************
2025-07-07 09:39:56,511 p=95771 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'instance' is undefined. 'instance' is undefined
2025-07-07 09:39:56,512 p=95771 u=gpadmin n=ansible | failed: [MASTER] (item=node-exporter-dashboard.json) => {"ansible_loop_var": "item", "changed": false, "item": "node-exporter-dashboard.json", "msg": "AnsibleUndefinedVariable: 'instance' is undefined. 'instance' is undefined"}
2025-07-07 09:39:56,556 p=95771 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'name' is undefined. 'name' is undefined
2025-07-07 09:39:56,556 p=95771 u=gpadmin n=ansible | failed: [MASTER] (item=docker-container-dashboard.json) => {"ansible_loop_var": "item", "changed": false, "item": "docker-container-dashboard.json", "msg": "AnsibleUndefinedVariable: 'name' is undefined. 'name' is undefined"}
2025-07-07 09:39:56,600 p=95771 u=gpadmin n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'name' is undefined. 'name' is undefined
2025-07-07 09:39:56,601 p=95771 u=gpadmin n=ansible | failed: [MASTER] (item=ray-cluster-dashboard.json) => {"ansible_loop_var": "item", "changed": false, "item": "ray-cluster-dashboard.json", "msg": "AnsibleUndefinedVariable: 'name' is undefined. 'name' is undefined"}
2025-07-07 09:39:56,604 p=95771 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:39:56,604 p=95771 u=gpadmin n=ansible | MASTER                     : ok=17   changed=7    unreachable=0    failed=1    skipped=0    rescued=0    ignored=5   
2025-07-07 09:41:43,233 p=97667 u=gpadmin n=ansible | PLAY [Fix Dashboard Templates] ************************************************************
2025-07-07 09:41:43,241 p=97667 u=gpadmin n=ansible | TASK [Fix Prometheus template variables in dashboards] ************************************
2025-07-07 09:41:43,260 p=97667 u=gpadmin n=ansible | fatal: [localhost]: FAILED! => {"msg": "template error while templating string: unexpected char '^' at 4. String: {{([^}]+)}}. unexpected char '^' at 4"}
2025-07-07 09:41:43,260 p=97667 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:41:43,261 p=97667 u=gpadmin n=ansible | localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 09:45:08,504 p=99441 u=gpadmin n=ansible | PLAY [Fix Monitoring Permissions] *********************************************************
2025-07-07 09:45:08,511 p=99441 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:45:10,003 p=99441 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:45:10,035 p=99441 u=gpadmin n=ansible | TASK [Stop all monitoring containers] *****************************************************
2025-07-07 09:45:10,772 p=99441 u=gpadmin n=ansible | failed: [MASTER] (item=prometheus) => {"ansible_loop_var": "item", "changed": false, "item": "prometheus", "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:45:11,223 p=99441 u=gpadmin n=ansible | failed: [MASTER] (item=grafana) => {"ansible_loop_var": "item", "changed": false, "item": "grafana", "msg": "Unsupported parameters for (community.docker.docker_container) module: force_delete. Supported parameters include: api_version, auto_remove, blkio_weight, ca_path, cap_drop, capabilities, cgroup_parent, cgroupns_mode, cleanup, client_cert, client_key, command, command_handling, comparisons, container_default_behavior, cpu_period, cpu_quota, cpu_shares, cpus, cpuset_cpus, cpuset_mems, debug, default_host_ip, detach, device_read_bps, device_read_iops, device_requests, device_write_bps, device_write_iops, devices, dns_opts, dns_search_domains, dns_servers, docker_host, domainname, entrypoint, env, env_file, etc_hosts, exposed_ports, force_kill, groups, healthcheck, hostname, ignore_image, image, image_comparison, image_label_mismatch, image_name_mismatch, init, interactive, ipc_mode, keep_volumes, kernel_memory, kill_signal, labels, links, log_driver, log_options, mac_address, memory, memory_reservation, memory_swap, memory_swappiness, mounts, name, network_mode, networks, networks_cli_compatible, oom_killer, oom_score_adj, output_logs, paused, pid_mode, pids_limit, platform, privileged, publish_all_ports, published_ports, pull, purge_networks, read_only, recreate, removal_wait_timeout, restart, restart_policy, restart_retries, runtime, security_opts, shm_size, ssl_version, state, stop_signal, stop_timeout, storage_opts, sysctls, timeout, tls, tls_hostname, tmpfs, tty, ulimits, use_ssh_client, user, userns_mode, uts, validate_certs, volume_driver, volumes, volumes_from, working_dir (ca_cert, cacert_path, cert_path, docker_api_version, docker_url, expose, exposed, forcekill, key_path, log_opt, ports, tls_ca_cert, tls_client_cert, tls_client_key, tls_verify)."}
2025-07-07 09:45:11,224 p=99441 u=gpadmin n=ansible | ...ignoring
2025-07-07 09:45:11,237 p=99441 u=gpadmin n=ansible | TASK [Fix Prometheus data directory permissions] ******************************************
2025-07-07 09:45:11,649 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:11,662 p=99441 u=gpadmin n=ansible | TASK [Fix Grafana data directory permissions] *********************************************
2025-07-07 09:45:11,964 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:11,977 p=99441 u=gpadmin n=ansible | TASK [Restart monitoring containers] ******************************************************
2025-07-07 09:45:12,038 p=99441 u=gpadmin n=ansible | TASK [monitoring : Create Prometheus data directory] **************************************
2025-07-07 09:45:12,316 p=99441 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:45:12,329 p=99441 u=gpadmin n=ansible | TASK [monitoring : Create Grafana data directory] *****************************************
2025-07-07 09:45:12,633 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:12,646 p=99441 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Node Exporter container (idempotency)] ********
2025-07-07 09:45:13,215 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:13,229 p=99441 u=gpadmin n=ansible | TASK [monitoring : Start Node Exporter container] *****************************************
2025-07-07 09:45:13,897 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:13,910 p=99441 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing cAdvisor container (idempotency)] *************
2025-07-07 09:45:14,499 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:14,512 p=99441 u=gpadmin n=ansible | TASK [monitoring : Start cAdvisor container] **********************************************
2025-07-07 09:45:15,201 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:15,213 p=99441 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Prometheus container (idempotency)] ***********
2025-07-07 09:45:15,805 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:15,819 p=99441 u=gpadmin n=ansible | TASK [monitoring : Create Prometheus configuration] ***************************************
2025-07-07 09:45:16,475 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:16,488 p=99441 u=gpadmin n=ansible | TASK [monitoring : Start Prometheus container] ********************************************
2025-07-07 09:45:17,178 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:17,192 p=99441 u=gpadmin n=ansible | TASK [monitoring : Stop and remove existing Grafana container (idempotency)] **************
2025-07-07 09:45:17,715 p=99441 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:45:17,729 p=99441 u=gpadmin n=ansible | TASK [monitoring : Create Grafana provisioning directories] *******************************
2025-07-07 09:45:18,042 p=99441 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/provisioning/datasources)
2025-07-07 09:45:18,321 p=99441 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/provisioning/dashboards)
2025-07-07 09:45:18,614 p=99441 u=gpadmin n=ansible | changed: [MASTER] => (item=/home/gpadmin/grafana_data/dashboards)
2025-07-07 09:45:18,629 p=99441 u=gpadmin n=ansible | TASK [monitoring : Create Grafana datasource configuration] *******************************
2025-07-07 09:45:19,237 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:19,251 p=99441 u=gpadmin n=ansible | TASK [monitoring : Create Grafana dashboard provider configuration] ***********************
2025-07-07 09:45:19,832 p=99441 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:45:19,845 p=99441 u=gpadmin n=ansible | TASK [monitoring : Copy Grafana dashboards] ***********************************************
2025-07-07 09:45:20,532 p=99441 u=gpadmin n=ansible | changed: [MASTER] => (item=node-exporter-dashboard.json)
2025-07-07 09:45:21,038 p=99441 u=gpadmin n=ansible | changed: [MASTER] => (item=docker-container-dashboard.json)
2025-07-07 09:45:21,566 p=99441 u=gpadmin n=ansible | changed: [MASTER] => (item=ray-cluster-dashboard.json)
2025-07-07 09:45:21,581 p=99441 u=gpadmin n=ansible | TASK [monitoring : Start Grafana container] ***********************************************
2025-07-07 09:45:22,079 p=99441 u=gpadmin n=ansible | fatal: [MASTER]: FAILED! => {"changed": false, "msg": "Non-string value found for env option. Ambiguous env options must be wrapped in quotes to avoid them being interpreted. Key: GF_SERVER_HTTP_PORT"}
2025-07-07 09:45:22,081 p=99441 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:45:22,081 p=99441 u=gpadmin n=ansible | MASTER                     : ok=18   changed=14   unreachable=0    failed=1    skipped=0    rescued=0    ignored=1   
2025-07-07 09:45:52,318 p=101173 u=gpadmin n=ansible | MASTER | FAILED | rc=1 >>
Error response from daemon: No such container: grafananon-zero return code

2025-07-07 09:46:08,327 p=101289 u=gpadmin n=ansible | MASTER | CHANGED | rc=0 >>
d8cf16192cbac3fe1e91550662566cb4c775b33ee5e3ec85fd6185f82ae663a5Unable to find image 'grafana/grafana:latest' locally
latest: Pulling from grafana/grafana
f18232174bc9: Pulling fs layer
9183b65e90ee: Pulling fs layer
3f8d5c908dcc: Pulling fs layer
30bb92ff0608: Pulling fs layer
807a2e881ecd: Pulling fs layer
4a4d0948b0bf: Pulling fs layer
04f6155c873d: Pulling fs layer
85dde7dceb0a: Pulling fs layer
7009d5001b77: Pulling fs layer
538deb30e80c: Pulling fs layer
4a4d0948b0bf: Waiting
04f6155c873d: Waiting
85dde7dceb0a: Waiting
538deb30e80c: Waiting
30bb92ff0608: Waiting
7009d5001b77: Waiting
807a2e881ecd: Waiting
9183b65e90ee: Verifying Checksum
9183b65e90ee: Download complete
3f8d5c908dcc: Download complete
f18232174bc9: Verifying Checksum
f18232174bc9: Download complete
f18232174bc9: Pull complete
9183b65e90ee: Pull complete
807a2e881ecd: Download complete
4a4d0948b0bf: Download complete
30bb92ff0608: Verifying Checksum
30bb92ff0608: Download complete
3f8d5c908dcc: Pull complete
7009d5001b77: Verifying Checksum
7009d5001b77: Download complete
30bb92ff0608: Pull complete
807a2e881ecd: Pull complete
4a4d0948b0bf: Pull complete
538deb30e80c: Verifying Checksum
538deb30e80c: Download complete
85dde7dceb0a: Verifying Checksum
85dde7dceb0a: Download complete
04f6155c873d: Verifying Checksum
04f6155c873d: Download complete
04f6155c873d: Pull complete
85dde7dceb0a: Pull complete
7009d5001b77: Pull complete
538deb30e80c: Pull complete
Digest: sha256:b5b59bfc7561634c2d7b136c4543d702ebcc94a3da477f21ff26f89ffd4214fa
Status: Downloaded newer image for grafana/grafana:latest

2025-07-07 09:46:13,762 p=101700 u=gpadmin n=ansible | MASTER | FAILED | rc=-1 >>
template error while templating string: unexpected '.'. String: docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'. unexpected '.'

2025-07-07 09:46:13,768 p=101700 u=gpadmin n=ansible | G-241 | FAILED | rc=-1 >>
template error while templating string: unexpected '.'. String: docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'. unexpected '.'

2025-07-07 09:46:13,768 p=101700 u=gpadmin n=ansible | G-242 | FAILED | rc=-1 >>
template error while templating string: unexpected '.'. String: docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'. unexpected '.'

2025-07-07 09:46:13,771 p=101700 u=gpadmin n=ansible | G-243 | FAILED | rc=-1 >>
template error while templating string: unexpected '.'. String: docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'. unexpected '.'

2025-07-07 09:46:13,775 p=101700 u=gpadmin n=ansible | G-244 | FAILED | rc=-1 >>
template error while templating string: unexpected '.'. String: docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'. unexpected '.'

2025-07-07 09:46:20,408 p=101796 u=gpadmin n=ansible | MASTER | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                              COMMAND                  CREATED              STATUS                                 PORTS     NAMES
d8cf16192cba   grafana/grafana:latest             "/run.sh"                13 seconds ago       Up 12 seconds                                    grafana
ccaf50521155   prom/prometheus:v2.45.0            "/bin/prometheus --c…"   About a minute ago   Up About a minute                                prometheus
15250f98d68a   gcr.io/cadvisor/cadvisor:v0.47.2   "/usr/bin/cadvisor -…"   About a minute ago   Up About a minute (health: starting)             cadvisor
b467d7b01dd5   prom/node-exporter:v1.6.1          "/bin/node_exporter …"   About a minute ago   Up About a minute                                node-exporter
a30361101b64   rayproject/ray:2.9.0               "/home/gpadmin/ray_t…"   11 minutes ago       Up 11 minutes                                    ray_head

2025-07-07 09:46:20,890 p=101796 u=gpadmin n=ansible | G-244 | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                       COMMAND                  CREATED          STATUS          PORTS     NAMES
54fb99bb27ad   prom/node-exporter:v1.6.1   "/bin/node_exporter …"   10 minutes ago   Up 10 minutes             node-exporter
56ce0f34b799   rayproject/ray:2.9.0        "/home/gpadmin/ray_t…"   11 minutes ago   Up 11 minutes             ray_worker

2025-07-07 09:46:20,905 p=101796 u=gpadmin n=ansible | G-242 | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                       COMMAND                  CREATED          STATUS          PORTS     NAMES
c04598c908e5   prom/node-exporter:v1.6.1   "/bin/node_exporter …"   10 minutes ago   Up 10 minutes             node-exporter
7fbaa9e64aad   rayproject/ray:2.9.0        "/home/gpadmin/ray_t…"   11 minutes ago   Up 11 minutes             ray_worker

2025-07-07 09:46:20,915 p=101796 u=gpadmin n=ansible | G-241 | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                       COMMAND                  CREATED          STATUS          PORTS     NAMES
9b79793063ea   prom/node-exporter:v1.6.1   "/bin/node_exporter …"   10 minutes ago   Up 10 minutes             node-exporter
ae21478cc53a   rayproject/ray:2.9.0        "/home/gpadmin/ray_t…"   11 minutes ago   Up 11 minutes             ray_worker

2025-07-07 09:46:20,925 p=101796 u=gpadmin n=ansible | G-243 | CHANGED | rc=0 >>
CONTAINER ID   IMAGE                       COMMAND                  CREATED          STATUS          PORTS     NAMES
35590ea5ea68   prom/node-exporter:v1.6.1   "/bin/node_exporter …"   10 minutes ago   Up 10 minutes             node-exporter
28d337ef57bd   rayproject/ray:2.9.0        "/home/gpadmin/ray_t…"   11 minutes ago   Up 11 minutes             ray_worker

2025-07-07 09:46:28,698 p=101992 u=gpadmin n=ansible | MASTER | FAILED | rc=1 >>
Traceback (most recent call last):
  File "/home/ray/anaconda3/bin/ray", line 8, in <module>
    sys.exit(main())
  File "/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py", line 2498, in main
    return cli()
  File "/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ray/anaconda3/lib/python3.8/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/home/ray/anaconda3/lib/python3.8/site-packages/ray/scripts/scripts.py", line 1973, in status
    address = services.canonicalize_bootstrap_address_or_die(address)
  File "/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/services.py", line 566, in canonicalize_bootstrap_address_or_die
    raise ConnectionError(
ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.non-zero return code

2025-07-07 09:46:36,206 p=102206 u=gpadmin n=ansible | MASTER | FAILED | rc=1 >>
Ray cluster is not found at 192.168.40.240:6379Traceback (most recent call last):
  File "python/ray/_raylet.pyx", line 3168, in ray._raylet.check_health
  File "python/ray/_raylet.pyx", line 580, in ray._raylet.check_status
ray.exceptions.RpcError: failed to connect to all addresses; last error: UNKNOWN: ipv4:192.168.40.240:6379: Failed to connect to remote host: Connection refusednon-zero return code

2025-07-07 09:46:42,830 p=102440 u=gpadmin n=ansible | MASTER | CHANGED | rc=0 >>
Usage: ray start [OPTIONS]
Try 'ray start --help' for help.

Error: Invalid value for '--memory': '102945MiB' is not a valid integer.

2025-07-07 09:47:07,854 p=102726 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 09:47:07,865 p=102726 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:47:09,338 p=102726 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:09,408 p=102726 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] ************************************************************
2025-07-07 09:47:09,418 p=102726 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:47:10,612 p=102726 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:10,676 p=102726 u=gpadmin n=ansible | PLAY [Configure Ray Worker Nodes] *********************************************************
2025-07-07 09:47:10,676 p=102726 u=gpadmin n=ansible | skipping: no hosts matched
2025-07-07 09:47:10,680 p=102726 u=gpadmin n=ansible | PLAY [Verify Ray Cluster Deployment] ******************************************************
2025-07-07 09:47:10,717 p=102726 u=gpadmin n=ansible | PLAY [Deploy Monitoring Stack] ************************************************************
2025-07-07 09:47:10,726 p=102726 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:47:11,955 p=102726 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:12,019 p=102726 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:47:12,019 p=102726 u=gpadmin n=ansible | MASTER                     : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 09:47:17,466 p=103303 u=gpadmin n=ansible | PLAY [Deploy Ray Cluster - Common Setup] **************************************************
2025-07-07 09:47:17,477 p=103303 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:47:18,861 p=103303 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:18,932 p=103303 u=gpadmin n=ansible | PLAY [Configure Ray Head Node] ************************************************************
2025-07-07 09:47:18,942 p=103303 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:47:20,140 p=103303 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:20,206 p=103303 u=gpadmin n=ansible | PLAY [Configure Ray Worker Nodes] *********************************************************
2025-07-07 09:47:20,206 p=103303 u=gpadmin n=ansible | skipping: no hosts matched
2025-07-07 09:47:20,210 p=103303 u=gpadmin n=ansible | PLAY [Verify Ray Cluster Deployment] ******************************************************
2025-07-07 09:47:20,248 p=103303 u=gpadmin n=ansible | PLAY [Deploy Monitoring Stack] ************************************************************
2025-07-07 09:47:20,257 p=103303 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:47:21,433 p=103303 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:21,495 p=103303 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:47:21,495 p=103303 u=gpadmin n=ansible | MASTER                     : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-07 09:47:40,653 p=103944 u=gpadmin n=ansible | PLAY [Restart Ray Cluster] ****************************************************************
2025-07-07 09:47:40,677 p=103944 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 09:47:42,214 p=103944 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:42,258 p=103944 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:47:42,388 p=103944 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:47:42,418 p=103944 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:47:42,425 p=103944 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:47:42,505 p=103944 u=gpadmin n=ansible | TASK [Stop Ray containers] ****************************************************************
2025-07-07 09:47:43,061 p=103944 u=gpadmin n=ansible | ok: [G-242] => (item=ray_head)
2025-07-07 09:47:43,071 p=103944 u=gpadmin n=ansible | ok: [G-243] => (item=ray_head)
2025-07-07 09:47:43,072 p=103944 u=gpadmin n=ansible | ok: [G-244] => (item=ray_head)
2025-07-07 09:47:43,073 p=103944 u=gpadmin n=ansible | ok: [G-241] => (item=ray_head)
2025-07-07 09:47:53,351 p=103944 u=gpadmin n=ansible | changed: [MASTER] => (item=ray_head)
2025-07-07 09:47:53,446 p=103944 u=gpadmin n=ansible | changed: [G-243] => (item=ray_worker)
2025-07-07 09:47:53,454 p=103944 u=gpadmin n=ansible | changed: [G-242] => (item=ray_worker)
2025-07-07 09:47:53,472 p=103944 u=gpadmin n=ansible | changed: [G-244] => (item=ray_worker)
2025-07-07 09:47:53,480 p=103944 u=gpadmin n=ansible | changed: [G-241] => (item=ray_worker)
2025-07-07 09:47:53,848 p=103944 u=gpadmin n=ansible | ok: [MASTER] => (item=ray_worker)
2025-07-07 09:47:53,862 p=103944 u=gpadmin n=ansible | TASK [Include ray_head role] **************************************************************
2025-07-07 09:47:53,908 p=103944 u=gpadmin n=ansible | skipping: [G-241]
2025-07-07 09:47:53,940 p=103944 u=gpadmin n=ansible | skipping: [G-242]
2025-07-07 09:47:53,941 p=103944 u=gpadmin n=ansible | skipping: [G-243]
2025-07-07 09:47:53,953 p=103944 u=gpadmin n=ansible | skipping: [G-244]
2025-07-07 09:47:53,982 p=103944 u=gpadmin n=ansible | TASK [ray_head : Ensure Ray temporary directory exists on head node] **********************
2025-07-07 09:47:54,389 p=103944 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:54,402 p=103944 u=gpadmin n=ansible | TASK [ray_head : Stop and remove existing Ray head container (idempotency)] ***************
2025-07-07 09:47:54,890 p=103944 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:54,903 p=103944 u=gpadmin n=ansible | TASK [ray_head : Remove old Ray head start script (idempotency)] **************************
2025-07-07 09:47:55,196 p=103944 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:47:55,210 p=103944 u=gpadmin n=ansible | TASK [ray_head : Copy Ray head start script to head node] *********************************
2025-07-07 09:47:55,934 p=103944 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:47:55,951 p=103944 u=gpadmin n=ansible | TASK [ray_head : Start Ray head container] ************************************************
2025-07-07 09:47:56,608 p=103944 u=gpadmin n=ansible | changed: [MASTER]
2025-07-07 09:47:56,621 p=103944 u=gpadmin n=ansible | TASK [ray_head : Display Ray head container status] ***************************************
2025-07-07 09:47:56,952 p=103944 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:47:56,965 p=103944 u=gpadmin n=ansible | TASK [ray_head : Print Ray head container status] *****************************************
2025-07-07 09:47:56,998 p=103944 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n82b0e5d0e68c   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_head"
}
2025-07-07 09:47:57,016 p=103944 u=gpadmin n=ansible | TASK [ray_head : Wait for a moment to let Ray head node initialize] ***********************
2025-07-07 09:47:57,036 p=103944 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:47:57,037 p=103944 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:48:07,041 p=103944 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:48:07,055 p=103944 u=gpadmin n=ansible | TASK [ray_head : Check Ray head node status] **********************************************
2025-07-07 09:48:09,257 p=103944 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 09:48:09,269 p=103944 u=gpadmin n=ansible | TASK [ray_head : Print Ray head node status] **********************************************
2025-07-07 09:48:09,320 p=103944 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": [
        "======== Autoscaler status: 2025-07-07 06:48:04.483340 ========",
        "Node status",
        "---------------------------------------------------------------",
        "Active:",
        " 1 node_ba06a623ab31fc102bc772dba3216bec4e899553327947f90d90158c",
        "Pending:",
        " (no pending nodes)",
        "Recent failures:",
        " (no failures)",
        "",
        "Resources",
        "---------------------------------------------------------------",
        "Usage:",
        " 0.0/32.0 CPU",
        " 0B/100.53KiB memory",
        " 0B/9.31GiB object_store_memory",
        "",
        "Demands:",
        " (no resource demands)"
    ]
}
2025-07-07 09:48:09,350 p=103944 u=gpadmin n=ansible | TASK [Include ray_worker role] ************************************************************
2025-07-07 09:48:09,386 p=103944 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 09:48:09,474 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Ensure Ray temporary directory exists on worker node] ******************
2025-07-07 09:48:09,634 p=103944 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:48:09,649 p=103944 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:48:09,671 p=103944 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:48:09,671 p=103944 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:48:09,730 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Stop and remove existing Ray worker container (idempotency)] ***********
2025-07-07 09:48:10,016 p=103944 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:48:10,038 p=103944 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:48:10,049 p=103944 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:48:10,060 p=103944 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:48:10,081 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Remove old Ray worker start script (idempotency)] **********************
2025-07-07 09:48:10,270 p=103944 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:48:10,272 p=103944 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:48:10,278 p=103944 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:48:10,287 p=103944 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:48:10,308 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Copy Ray worker start script to worker node] ***************************
2025-07-07 09:48:10,777 p=103944 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:48:10,790 p=103944 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:48:10,816 p=103944 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:48:10,819 p=103944 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:48:10,840 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Start Ray worker container] ********************************************
2025-07-07 09:48:11,349 p=103944 u=gpadmin n=ansible | changed: [G-241]
2025-07-07 09:48:11,357 p=103944 u=gpadmin n=ansible | changed: [G-242]
2025-07-07 09:48:11,362 p=103944 u=gpadmin n=ansible | changed: [G-244]
2025-07-07 09:48:11,410 p=103944 u=gpadmin n=ansible | changed: [G-243]
2025-07-07 09:48:11,432 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Display Ray worker container status] ***********************************
2025-07-07 09:48:11,622 p=103944 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:48:11,636 p=103944 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:48:11,652 p=103944 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:48:11,661 p=103944 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:48:11,684 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Print Ray worker container status] *************************************
2025-07-07 09:48:11,730 p=103944 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n12edbae5ce9a   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:48:11,744 p=103944 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n6573f9d02cf4   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:48:11,746 p=103944 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n222535faf4c7   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:48:11,757 p=103944 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": "CONTAINER ID   IMAGE                  COMMAND                  CREATED                  STATUS                  PORTS     NAMES\naabf8684aa8a   rayproject/ray:2.9.0   \"/home/gpadmin/ray_t…\"   Less than a second ago   Up Less than a second             ray_worker"
}
2025-07-07 09:48:11,771 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Wait for a moment to let Ray worker node initialize] *******************
2025-07-07 09:48:11,791 p=103944 u=gpadmin n=ansible | Pausing for 10 seconds
2025-07-07 09:48:11,792 p=103944 u=gpadmin n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-07 09:48:21,797 p=103944 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:48:21,818 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Check Ray worker node status] ******************************************
2025-07-07 09:48:22,894 p=103944 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 09:48:22,916 p=103944 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 09:48:22,935 p=103944 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 09:48:22,943 p=103944 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 09:48:22,956 p=103944 u=gpadmin n=ansible | TASK [ray_worker : Print Ray worker node status] ******************************************
2025-07-07 09:48:23,007 p=103944 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": [
        "======== Autoscaler status: 2025-07-07 06:48:19.517043 ========",
        "Node status",
        "---------------------------------------------------------------",
        "Active:",
        " 1 node_9d19e0e61343fc414d34246fec58a21bb22008cd5182dc658b029988",
        " 1 node_ba06a623ab31fc102bc772dba3216bec4e899553327947f90d90158c",
        " 1 node_c8994f0c41dbdb3c6bbaf320ecd33477a65570e55d26251efe122b6b",
        " 1 node_1e0cab87130f010639bb1a4dd812c382477b80e09104400e0ba9bb0f",
        " 1 node_d888f7b4d4836e6d89c49695ea8d48220091308680732d7e24977026",
        "Pending:",
        " (no pending nodes)",
        "Recent failures:",
        " (no failures)",
        "",
        "Resources",
        "---------------------------------------------------------------",
        "Usage:",
        " 0.0/96.0 CPU",
        " 0B/502.56KiB memory",
        " 0B/46.57GiB object_store_memory",
        "",
        "Demands:",
        " (no resource demands)"
    ]
}
2025-07-07 09:48:23,010 p=103944 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": [
        "======== Autoscaler status: 2025-07-07 06:48:19.517043 ========",
        "Node status",
        "---------------------------------------------------------------",
        "Active:",
        " 1 node_9d19e0e61343fc414d34246fec58a21bb22008cd5182dc658b029988",
        " 1 node_ba06a623ab31fc102bc772dba3216bec4e899553327947f90d90158c",
        " 1 node_c8994f0c41dbdb3c6bbaf320ecd33477a65570e55d26251efe122b6b",
        " 1 node_1e0cab87130f010639bb1a4dd812c382477b80e09104400e0ba9bb0f",
        " 1 node_d888f7b4d4836e6d89c49695ea8d48220091308680732d7e24977026",
        "Pending:",
        " (no pending nodes)",
        "Recent failures:",
        " (no failures)",
        "",
        "Resources",
        "---------------------------------------------------------------",
        "Usage:",
        " 0.0/96.0 CPU",
        " 0B/502.56KiB memory",
        " 0B/46.57GiB object_store_memory",
        "",
        "Demands:",
        " (no resource demands)"
    ]
}
2025-07-07 09:48:23,031 p=103944 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": [
        "======== Autoscaler status: 2025-07-07 06:48:19.517043 ========",
        "Node status",
        "---------------------------------------------------------------",
        "Active:",
        " 1 node_9d19e0e61343fc414d34246fec58a21bb22008cd5182dc658b029988",
        " 1 node_ba06a623ab31fc102bc772dba3216bec4e899553327947f90d90158c",
        " 1 node_c8994f0c41dbdb3c6bbaf320ecd33477a65570e55d26251efe122b6b",
        " 1 node_1e0cab87130f010639bb1a4dd812c382477b80e09104400e0ba9bb0f",
        " 1 node_d888f7b4d4836e6d89c49695ea8d48220091308680732d7e24977026",
        "Pending:",
        " (no pending nodes)",
        "Recent failures:",
        " (no failures)",
        "",
        "Resources",
        "---------------------------------------------------------------",
        "Usage:",
        " 0.0/96.0 CPU",
        " 0B/502.56KiB memory",
        " 0B/46.57GiB object_store_memory",
        "",
        "Demands:",
        " (no resource demands)"
    ]
}
2025-07-07 09:48:23,038 p=103944 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": [
        "======== Autoscaler status: 2025-07-07 06:48:19.517043 ========",
        "Node status",
        "---------------------------------------------------------------",
        "Active:",
        " 1 node_9d19e0e61343fc414d34246fec58a21bb22008cd5182dc658b029988",
        " 1 node_ba06a623ab31fc102bc772dba3216bec4e899553327947f90d90158c",
        " 1 node_c8994f0c41dbdb3c6bbaf320ecd33477a65570e55d26251efe122b6b",
        " 1 node_1e0cab87130f010639bb1a4dd812c382477b80e09104400e0ba9bb0f",
        " 1 node_d888f7b4d4836e6d89c49695ea8d48220091308680732d7e24977026",
        "Pending:",
        " (no pending nodes)",
        "Recent failures:",
        " (no failures)",
        "",
        "Resources",
        "---------------------------------------------------------------",
        "Usage:",
        " 0.0/96.0 CPU",
        " 0B/502.56KiB memory",
        " 0B/46.57GiB object_store_memory",
        "",
        "Demands:",
        " (no resource demands)"
    ]
}
2025-07-07 09:48:23,161 p=103944 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 09:48:23,161 p=103944 u=gpadmin n=ansible | G-241                      : ok=12   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-07 09:48:23,161 p=103944 u=gpadmin n=ansible | G-242                      : ok=11   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-07 09:48:23,161 p=103944 u=gpadmin n=ansible | G-243                      : ok=11   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-07 09:48:23,161 p=103944 u=gpadmin n=ansible | G-244                      : ok=11   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-07 09:48:23,161 p=103944 u=gpadmin n=ansible | MASTER                     : ok=12   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-07 10:02:47,082 p=113107 u=gpadmin n=ansible | PLAY [Checkpoint 1: Prerequisites and System Readiness Check] *****************************
2025-07-07 10:02:47,090 p=113107 u=gpadmin n=ansible | TASK [Gathering Facts] ********************************************************************
2025-07-07 10:02:48,502 p=113107 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 10:02:48,608 p=113107 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 10:02:48,615 p=113107 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 10:02:48,621 p=113107 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 10:02:48,714 p=113107 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 10:02:48,785 p=113107 u=gpadmin n=ansible | TASK [Display checkpoint information] *****************************************************
2025-07-07 10:02:48,815 p=113107 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": [
        "=== CHECKPOINT 1: PREREQUISITES CHECK ===",
        "Approval Required: False",
        "Destructive Operation: False",
        "Description: Validate system requirements and network connectivity"
    ]
}
2025-07-07 10:02:48,829 p=113107 u=gpadmin n=ansible | ok: [G-241] => {
    "msg": [
        "=== CHECKPOINT 1: PREREQUISITES CHECK ===",
        "Approval Required: False",
        "Destructive Operation: False",
        "Description: Validate system requirements and network connectivity"
    ]
}
2025-07-07 10:02:48,843 p=113107 u=gpadmin n=ansible | ok: [G-242] => {
    "msg": [
        "=== CHECKPOINT 1: PREREQUISITES CHECK ===",
        "Approval Required: False",
        "Destructive Operation: False",
        "Description: Validate system requirements and network connectivity"
    ]
}
2025-07-07 10:02:48,844 p=113107 u=gpadmin n=ansible | ok: [G-243] => {
    "msg": [
        "=== CHECKPOINT 1: PREREQUISITES CHECK ===",
        "Approval Required: False",
        "Destructive Operation: False",
        "Description: Validate system requirements and network connectivity"
    ]
}
2025-07-07 10:02:48,854 p=113107 u=gpadmin n=ansible | ok: [G-244] => {
    "msg": [
        "=== CHECKPOINT 1: PREREQUISITES CHECK ===",
        "Approval Required: False",
        "Destructive Operation: False",
        "Description: Validate system requirements and network connectivity"
    ]
}
2025-07-07 10:02:48,862 p=113107 u=gpadmin n=ansible | TASK [Check Python installation] **********************************************************
2025-07-07 10:02:49,121 p=113107 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 10:02:49,127 p=113107 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 10:02:49,134 p=113107 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 10:02:49,134 p=113107 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 10:02:49,220 p=113107 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 10:02:49,232 p=113107 u=gpadmin n=ansible | TASK [Check SSH connectivity] *************************************************************
2025-07-07 10:02:49,498 p=113107 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 10:02:49,501 p=113107 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 10:02:49,502 p=113107 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 10:02:49,509 p=113107 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 10:02:49,585 p=113107 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 10:02:49,597 p=113107 u=gpadmin n=ansible | TASK [Check available disk space] *********************************************************
2025-07-07 10:02:49,765 p=113107 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 10:02:49,802 p=113107 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 10:02:49,803 p=113107 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 10:02:49,813 p=113107 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 10:02:49,880 p=113107 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 10:02:49,892 p=113107 u=gpadmin n=ansible | TASK [Check available memory] *************************************************************
2025-07-07 10:02:50,063 p=113107 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 10:02:50,083 p=113107 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 10:02:50,086 p=113107 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 10:02:50,110 p=113107 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 10:02:50,167 p=113107 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 10:02:50,175 p=113107 u=gpadmin n=ansible | TASK [Check CPU cores] ********************************************************************
2025-07-07 10:02:50,339 p=113107 u=gpadmin n=ansible | ok: [G-241]
2025-07-07 10:02:50,373 p=113107 u=gpadmin n=ansible | ok: [G-243]
2025-07-07 10:02:50,376 p=113107 u=gpadmin n=ansible | ok: [G-242]
2025-07-07 10:02:50,382 p=113107 u=gpadmin n=ansible | ok: [G-244]
2025-07-07 10:02:50,461 p=113107 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 10:02:50,473 p=113107 u=gpadmin n=ansible | TASK [Check network connectivity to head node] ********************************************
2025-07-07 10:02:50,497 p=113107 u=gpadmin n=ansible | skipping: [MASTER]
2025-07-07 10:03:00,762 p=113107 u=gpadmin n=ansible | fatal: [G-241]: FAILED! => {"changed": false, "elapsed": 10, "msg": "Timeout when waiting for 192.168.40.240:22"}
2025-07-07 10:03:00,764 p=113107 u=gpadmin n=ansible | fatal: [G-242]: FAILED! => {"changed": false, "elapsed": 10, "msg": "Timeout when waiting for 192.168.40.240:22"}
2025-07-07 10:03:00,775 p=113107 u=gpadmin n=ansible | fatal: [G-243]: FAILED! => {"changed": false, "elapsed": 10, "msg": "Timeout when waiting for 192.168.40.240:22"}
2025-07-07 10:03:00,780 p=113107 u=gpadmin n=ansible | fatal: [G-244]: FAILED! => {"changed": false, "elapsed": 10, "msg": "Timeout when waiting for 192.168.40.240:22"}
2025-07-07 10:03:00,797 p=113107 u=gpadmin n=ansible | TASK [Compile system information] *********************************************************
2025-07-07 10:03:00,825 p=113107 u=gpadmin n=ansible | ok: [MASTER]
2025-07-07 10:03:00,837 p=113107 u=gpadmin n=ansible | TASK [Display system readiness summary] ***************************************************
2025-07-07 10:03:00,859 p=113107 u=gpadmin n=ansible | ok: [MASTER] => {
    "msg": [
        "Node: G-K3S-Master (192.168.40.240)",
        "OS: Debian 24.04",
        "Python: Python 3.13.5",
        "Memory: 125Gi",
        "Free Disk: 820G",
        "CPU Cores: 32",
        "SSH Connectivity: True"
    ]
}
2025-07-07 10:03:00,871 p=113107 u=gpadmin n=ansible | TASK [Save checkpoint results] ************************************************************
2025-07-07 10:03:01,548 p=113107 u=gpadmin n=ansible | changed: [MASTER -> localhost]
2025-07-07 10:03:01,590 p=113107 u=gpadmin n=ansible | PLAY [Generate Prerequisites Check Report] ************************************************
2025-07-07 10:03:01,596 p=113107 u=gpadmin n=ansible | TASK [Compile overall status] *************************************************************
2025-07-07 10:03:01,616 p=113107 u=gpadmin n=ansible | ok: [localhost] => {
    "msg": [
        "=== CHECKPOINT 1 COMPLETED ===",
        "All systems validated successfully",
        "Ready to proceed to Checkpoint 2: Docker Installation"
    ]
}
2025-07-07 10:03:01,619 p=113107 u=gpadmin n=ansible | PLAY RECAP ********************************************************************************
2025-07-07 10:03:01,619 p=113107 u=gpadmin n=ansible | G-241                      : ok=7    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 10:03:01,619 p=113107 u=gpadmin n=ansible | G-242                      : ok=7    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 10:03:01,619 p=113107 u=gpadmin n=ansible | G-243                      : ok=7    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 10:03:01,619 p=113107 u=gpadmin n=ansible | G-244                      : ok=7    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-07 10:03:01,620 p=113107 u=gpadmin n=ansible | MASTER                     : ok=10   changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-07 10:03:01,620 p=113107 u=gpadmin n=ansible | localhost                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
